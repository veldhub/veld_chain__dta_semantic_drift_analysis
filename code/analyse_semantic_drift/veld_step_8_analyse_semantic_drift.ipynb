{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a2e1c5-aa05-466b-be11-b422da4f7c25",
   "metadata": {},
   "source": [
    "# modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b395f2c-139d-4563-9eee-492057582cb8",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535e21a-6c2f-44d9-aa28-faa91de14ad7",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1d90b-4a93-4b63-b22d-a20fa107c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "from typing import TypeAlias\n",
    "\n",
    "import hnswlib\n",
    "import hunspell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import psycopg\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "# from joblib import Memory\n",
    "from pgvector.psycopg import register_vector\n",
    "from psycopg.sql import SQL, Identifier, Placeholder\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d4d4c-74af-408e-90e7-431639f319d9",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f6dec-d63a-4c18-8806-59186587fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = True\n",
    "RESET_DB = True\n",
    "\n",
    "MODELS_WORD2VEC_FOLDER = \"/veld/input/models/word2vec/\"\n",
    "MODELS_FASTTEXT_FOLDER = \"/veld/input/models/fasttext/\"\n",
    "MODELS_GLOVE_FOLDER = \"/veld/input/models/glove/\"\n",
    "TEXTS_FOLDER = \"/veld/input/texts/\"\n",
    "# CACHE_FOLDER = \"/veld/storage/cache/\"\n",
    "\n",
    "INDEX_EF_CONSTRUCTION = 100\n",
    "INDEX_M = 16\n",
    "\n",
    "AVAILABLE_DECADES = [147, 196]\n",
    "\n",
    "PLOT_SLEEP = 2\n",
    "\n",
    "# memory = Memory(location=\"/veld/storage/cache/\", verbose=0)\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "hunspell_check = hunspell.HunSpell(\"/usr/share/hunspell/de_DE.dic\", \"/usr/share/hunspell/de_DE.aff\")\n",
    "random.seed(42)\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "DB_NAME = \"postgres_db\"\n",
    "DB_USER = \"postgres_user\"\n",
    "DB_PASSWORD = \"postgres_password\"\n",
    "DB_HOST = \"veld_step_7_run_embeddings_sql_server\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "COLS_EMBEDDING = [\"lemma\", \"occurrence_count\", \"embedding\"]\n",
    "COLS_DIFF = [\"lemma\", \"occurrence_count\", \"diff\"]\n",
    "\n",
    "TEST_LEMMA_RANGED_LIST = sorted([\"d\", \"und\", \"gehen\", \"wohnen\", \"FÃ¼rst\"], key=str.lower)\n",
    "TEST_LEMMA_CLOSE_LIST = sorted([\"gehen\", \"laufen\", \"wandern\", \"wohnen\", \"trinken\"], key=str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e02a5-9c4c-49c9-a2a3-260a790b2496",
   "metadata": {},
   "source": [
    "## helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520512ab-dc8f-44cc-adf0-ddc4dcf8e5cd",
   "metadata": {},
   "source": [
    "### is_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243c2ea-3957-459e-8f14-c71742bef448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word(word):\n",
    "    try:\n",
    "        _ = int(word)\n",
    "    except:\n",
    "        if len(word) == 1 and word != \"d\":\n",
    "            return False\n",
    "        else:\n",
    "            return hunspell_check.spell(word)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13721081-b7d7-44c9-ab0e-bb2c07f649bd",
   "metadata": {},
   "source": [
    "## data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58044656-cc17-4f9f-8959-2697f02436ee",
   "metadata": {},
   "source": [
    "### create_decades_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc419e9c-6232-421a-9863-fe087ed40e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decades_list(decade_start: int = AVAILABLE_DECADES[0], decade_end: int = AVAILABLE_DECADES[1]):\n",
    "    decade_list = [d for d in range(decade_start, decade_end + 1)]\n",
    "    return decade_list\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_list_test = create_decades_list(183, 187)\n",
    "    print(decade_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc305687-3bc1-4e75-9b65-83220404eaee",
   "metadata": {},
   "source": [
    "### tpye aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80f266-a429-4f85-9d63-f7d2b62cc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lemma: TypeAlias = str\n",
    "Decade: TypeAlias = int\n",
    "LineNumber: TypeAlias = int\n",
    "LemmaNumber: TypeAlias = int\n",
    "OccurrenceCount: TypeAlias = int\n",
    "RelativeDiff: TypeAlias = float\n",
    "Trajectory: TypeAlias = float\n",
    "CosSim: TypeAlias = float\n",
    "Diff: TypeAlias = CosSim | Trajectory | RelativeDiff\n",
    "DecadesStr: TypeAlias = str  # spans decades, e.g. \"183-184\"\n",
    "Embedding: TypeAlias = np.ndarray\n",
    "\n",
    "# lemma data structures\n",
    "LemmaDiffDict: TypeAlias = dict[Lemma, Diff]\n",
    "LineNumberDict: TypeAlias = dict[LineNumber, list[LemmaNumber]]\n",
    "LemmaOccurrencePositionDict: TypeAlias = dict[Lemma, LineNumberDict]\n",
    "LemmaOccurrenceCountDict: TypeAlias = dict[Lemma, OccurrenceCount]\n",
    "\n",
    "# index data structure\n",
    "IdToLemmaDict: TypeAlias = dict[int, Lemma]\n",
    "LemmaToIdDict: TypeAlias = dict[Lemma, int]\n",
    "Index: TypeAlias = tuple[hnswlib.Index, LemmaToIdDict, IdToLemmaDict]\n",
    "Word2VecIndex: TypeAlias = Index\n",
    "FastTextIndex: TypeAlias = Index\n",
    "GloVeIndex: TypeAlias = Index\n",
    "\n",
    "# Decade data\n",
    "DecadeList: TypeAlias = list[Decade]\n",
    "DecadeData: TypeAlias = list[Word2VecIndex, FastTextIndex, GloVeIndex, LemmaOccurrenceCountDict, LemmaOccurrencePositionDict]\n",
    "DecadeDict: TypeAlias = dict[Decade, DecadeData]\n",
    "DecadeLemmaDiffDict: TypeAlias = dict[DecadesStr, LemmaDiffDict]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744e237-c5e4-4e89-aa23-97bc1c9fedb8",
   "metadata": {},
   "source": [
    "### create_occurrence_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cce9fe-b5c7-46f9-af1e-249438285932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_occurrence_dicts(decade) -> dict:\n",
    "    print(\"create_occurrence_dicts: start: decade:\", decade)\n",
    "    # lemma_occurrence_position_dict = {}\n",
    "    lemma_occurrence_count_dict = {}\n",
    "    total_occurrence_count = 0\n",
    "    with open(TEXTS_FOLDER + str(decade) + \".txt\", \"r\") as f:\n",
    "        for line_number, line in enumerate(f):\n",
    "            for lemma_number, lemma in enumerate(line.rstrip(\"\\n\").split()):\n",
    "                occurrence_count = lemma_occurrence_count_dict.get(lemma, 0)\n",
    "                lemma_occurrence_count_dict[lemma] = occurrence_count + 1\n",
    "                total_occurrence_count += 1\n",
    "    lemma_count = len(lemma_occurrence_count_dict)\n",
    "    occurrence_avg = total_occurrence_count / lemma_count\n",
    "    median_pos = int(lemma_count / 2)\n",
    "    occurrence_median = list(lemma_occurrence_count_dict.values())[median_pos]\n",
    "    print(\"create_occurrence_dicts: uniqe lemma_count:\", lemma_count)\n",
    "    print(\"create_occurrence_dicts: total_occurrence_count:\", total_occurrence_count)\n",
    "    print(\"create_occurrence_dicts: occurrence_avg:\", occurrence_avg)\n",
    "    print(\"create_occurrence_dicts: occurrence_median:\", occurrence_median)\n",
    "    return lemma_occurrence_count_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_lemma_occurrence_count_dict = {}\n",
    "    for decade in decade_list_test:\n",
    "        decade_lemma_occurrence_count_dict[decade] = create_occurrence_dicts(decade)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783db00-dc44-4555-9e16-67d9b770d9b6",
   "metadata": {},
   "source": [
    "### sort_dict_by_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8158cc-2e60-4f21-9afe-58f87b23d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict_by_value(key_value_dict: dict, desc=True) -> dict:\n",
    "    if desc:\n",
    "        sort_mod = -1\n",
    "    else:\n",
    "        sort_mod = 1\n",
    "    return dict(sorted(key_value_dict.items(), key=lambda x: sort_mod * x[1]))\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    print(\n",
    "        sort_dict_by_value(\n",
    "            {\n",
    "                \"x\": 3,\n",
    "                \"y\": 2,\n",
    "                \"z\": 4,\n",
    "            },\n",
    "            desc=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a48974-ea44-4e6e-8e2f-e39d0150a009",
   "metadata": {},
   "source": [
    "## DB functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47764fca-c955-4cde-b1c1-d17960722b12",
   "metadata": {},
   "source": [
    "### connect_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9d741-c3b1-48fb-a99e-2e6df98bf98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(create_cursor=True):\n",
    "    conn = psycopg.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cursor = None\n",
    "    if create_cursor:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT version();\")\n",
    "        print(\"connected to:\", cursor.fetchone())\n",
    "    return conn, cursor\n",
    "\n",
    "\n",
    "conn, cursor = connect_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171613a2-b196-41c6-a26d-f2c7840f631b",
   "metadata": {},
   "source": [
    "### drop_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35a3d7-1113-4551-8b5c-ea25ad3d8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_table(table_name):\n",
    "    print(\"drop_table: table_name:\", table_name)\n",
    "    cursor.execute(f'DROP TABLE IF EXISTS \"{table_name}\" CASCADE;')\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    drop_table(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e184eb-ad71-4f28-8d5a-a0cfb6f14c26",
   "metadata": {},
   "source": [
    "### create_embeddings_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda44a3-9132-4371-8d86-8d7abd0805da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_table(table_name):\n",
    "    print(\"create_embeddings_table: table_name:\", table_name)\n",
    "    cursor.execute(\n",
    "        f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "        f\"lemma TEXT PRIMARY KEY, \"\n",
    "        f\"occurrence_count INTEGER, \"\n",
    "        f\"embedding VECTOR(300) not null\"\n",
    "        f\");\"\n",
    "    )\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    create_embeddings_table(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c17aa9f-2ef5-4d6b-9ad4-8fe898623c82",
   "metadata": {},
   "source": [
    "### create_diff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a108d70-30f5-48f4-b6b9-bb07e6841342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff_table(table_name):\n",
    "    print(\"create_diff_table: table_name:\", table_name)\n",
    "    cursor.execute(\n",
    "        f\"CREATE TABLE IF NOT EXISTS {table_name} (\" f\"lemma TEXT PRIMARY KEY, \" f\"occurrence_count INTEGER, \" f\"diff REAL\" f\");\"\n",
    "    )\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    create_diff_table(\"test_diff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fdd8d-c3d6-4a25-8a74-301ccfb843cc",
   "metadata": {},
   "source": [
    "### insert_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212a339-2fbb-4930-8165-1fd14ac5f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_db(table_name, table_data, cols=COLS_EMBEDDING):\n",
    "    print(\"insert_to_db: table_name:\", table_name, \"len(table_data):\", len(table_data))\n",
    "    query = SQL(\"INSERT INTO {table_name} ({cols}) VALUES ({values}) ON CONFLICT(lemma) DO NOTHING\")\n",
    "    query = query.format(\n",
    "        table_name=Identifier(table_name),\n",
    "        cols=SQL(\", \").join([Identifier(c) for c in cols]),\n",
    "        values=SQL(\", \").join([Placeholder() for _ in cols]),\n",
    "    )\n",
    "    print(query.as_string())\n",
    "    cursor.executemany(query, table_data)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    table_data = [\n",
    "        [\"gehen\", 25, [4.3, 1.2, 0.3] * 100],\n",
    "        [\"laufen\", 17, [3.2, 1.7, 2.5] * 100],\n",
    "    ]\n",
    "    insert_to_db(\"test\", table_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bea8ff-5722-48ca-8493-ce62b0ed86d5",
   "metadata": {},
   "source": [
    "### reset_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648237ca-c546-435d-a7fb-56dd3479c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_db(decade_list):\n",
    "    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    cursor.execute(\"SELECT tablename FROM pg_tables WHERE schemaname = 'public';\")\n",
    "    for table in cursor.fetchall():\n",
    "        drop_table(table[0])\n",
    "    for decade in decade_list:\n",
    "        for model in [\"word2vec\", \"fasttext\", \"glove\"]:\n",
    "            create_embeddings_table(f\"{model}__{decade}\")\n",
    "\n",
    "\n",
    "if RESET_DB:\n",
    "    decade_list_all = create_decades_list()\n",
    "    reset_db(decade_list_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4893c2f-aed1-49ba-9ce7-9cd01bb755f8",
   "metadata": {},
   "source": [
    "### register_vector_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfabafb-f484-4768-9a04-ef107278200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_vector_conn():\n",
    "    global conn\n",
    "    global cursor\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    conn, _ = connect_db(create_cursor=False)\n",
    "    register_vector(conn)\n",
    "    cursor = conn.cursor()\n",
    "    return conn, cursor\n",
    "\n",
    "\n",
    "conn, cursor = register_vector_conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905412c-2cce-42a7-a6d6-848065bdd89c",
   "metadata": {},
   "source": [
    "### load_word2vec_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1255b-3b0b-4ef7-9681-370713a93993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vec_to_db(decade, lemma_occurrence_count_dict):\n",
    "    print(\"create_index: start: decade:\", decade)\n",
    "    model_path = MODELS_WORD2VEC_FOLDER + str(decade) + \".bin\"\n",
    "    model = Word2Vec.load(model_path)\n",
    "    db_insertion_list = []\n",
    "    for lemma in model.wv.index_to_key:\n",
    "        if is_word(lemma):\n",
    "            embedding = model.wv[lemma]\n",
    "            embedding_normalized = embedding / np.linalg.norm(embedding)\n",
    "            db_insertion_list.append((lemma, lemma_occurrence_count_dict[lemma], embedding_normalized))\n",
    "    insert_to_db(f\"word2vec__{decade}\", db_insertion_list)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    for decade, lemma_occurrence_count_dict in decade_lemma_occurrence_count_dict.items():\n",
    "        load_word2vec_to_db(decade, lemma_occurrence_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653aa446-c63d-4544-a0d7-819c1c0324cb",
   "metadata": {},
   "source": [
    "### query_generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e405f-1a61-4c6a-8802-75245f1c6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_generic(table_name, lemma_list=None, select_cols=COLS_EMBEDDING, order_by=None, order_desc=False, print_query=True):\n",
    "    query = SQL(\"SELECT {select_cols} FROM {table_name}\")\n",
    "    query = query.format(select_cols=SQL(\", \").join([Identifier(c) for c in select_cols]), table_name=Identifier(table_name))\n",
    "    if lemma_list:\n",
    "        query_where = SQL(\"WHERE lemma = ANY({lemma_list})\")\n",
    "        query_where = query_where.format(lemma_list=Placeholder(\"lemma_list\"))\n",
    "        query = SQL(\" \").join([query, query_where])\n",
    "        params = {\"lemma_list\": lemma_list}\n",
    "    else:\n",
    "        params = {}\n",
    "    if order_by:\n",
    "        query += SQL(\" ORDER BY {order_col}\").format(order_col=Identifier(order_by))\n",
    "        if order_desc:\n",
    "            query += SQL(\" DESC\")\n",
    "    if print_query:\n",
    "        print(query.as_string())\n",
    "    cursor.execute(query=query, params=params)\n",
    "    result = cursor.fetchall()\n",
    "    if len(select_cols) == 1:\n",
    "        result = [r[0] for r in result]\n",
    "    return result\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    print(len(query_generic(\"word2vec__185\")))\n",
    "    print(len(query_generic(\"word2vec__185\", [\"gehen\"])))\n",
    "    print(len(query_generic(\"word2vec__185\", [\"gehen\", \"laufen\"])))\n",
    "    print(len(query_generic(\"word2vec__185\", [\"gehen\"], [\"lemma\"], \"lemma\", order_desc=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b1ab9-42e9-4949-88b8-07cff06e7bb4",
   "metadata": {},
   "source": [
    "### query_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb4cef-2fdd-40f7-ba41-97f33edf60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_related(table_name, lemma, n=10, select_cols=[\"lemma\", \"cos_sim\"]):\n",
    "    select_cols_sql = \", \".join(select_cols)\n",
    "    cursor.execute(\n",
    "        f\"\"\"\n",
    "        WITH similarities AS (\n",
    "            SELECT a.lemma, a.embedding, 1 - (a.embedding <=> b.embedding) AS cos_sim\n",
    "            FROM {table_name} a\n",
    "            CROSS JOIN (\n",
    "                SELECT embedding FROM {table_name}\n",
    "                WHERE lemma = '{lemma}'\n",
    "            ) AS b\n",
    "            WHERE lemma != '{lemma}'\n",
    "        )\n",
    "        SELECT {select_cols_sql}\n",
    "        FROM similarities\n",
    "        ORDER BY cos_sim DESC\n",
    "        LIMIT {n};\n",
    "    \"\"\"\n",
    "    )\n",
    "    return cursor.fetchall()\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    print(query_related(\"word2vec__185\", \"gehen\"))\n",
    "    print(query_related(\"word2vec__185\", \"Frau\", n=5))\n",
    "    print(query_related(\"word2vec__185\", \"Frau\", n=1, select_cols=[\"embedding\"])[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c4524-a8e3-49a4-8898-b87287d0be1a",
   "metadata": {},
   "source": [
    "### query_mutual_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e8a1b-ae53-4bd3-b338-b9e2efe507f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_mutual_lemmas(table_list, include_count=True, print_query=True):\n",
    "    select_occurrence_part = \"\"\n",
    "    if include_count:\n",
    "        select_occurrence_part = \", \" + \" + \".join([t + \".occurrence_count\" for t in table_list])\n",
    "    join_part = table_list[0]\n",
    "    for table in table_list[1:]:\n",
    "        join_part += \" INNER JOIN \" + table + \" USING (lemma) \"\n",
    "    query = f\"SELECT lemma {select_occurrence_part} FROM {join_part}\"\n",
    "    query += \";\"\n",
    "    if print_query:\n",
    "        print(\"query_mutual_lemmas: query:\", query)\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    if not include_count:\n",
    "        result = [r[0] for r in result]\n",
    "    return result\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    table_list_list = [\n",
    "        [[\"word2vec__183\"], True],\n",
    "        [[\"word2vec__183\", \"word2vec__184\"], True],\n",
    "        [[\"word2vec__183\", \"word2vec__184\", \"word2vec__185\"], False],\n",
    "    ]\n",
    "    for table_list, include_count in table_list_list:\n",
    "        r = query_mutual_lemmas(table_list, include_count)\n",
    "        print(len(r))\n",
    "        print(r[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3cd3c1-3ae1-4a97-b46d-99687bcdcd0a",
   "metadata": {},
   "source": [
    "### query_average_occurrence_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43fb78-c3b4-4fa7-949a-44ceeb7f8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_average_occurrence_count(table_prefix, decade_list):\n",
    "    lemma_count_dict = {}\n",
    "    for decade in decade_list:\n",
    "        for lemma, occurrence_count in query_generic(f\"{table_prefix}__{decade}\", select_cols=[\"lemma\", \"occurrence_count\"]):\n",
    "            occurrence_count_list = lemma_count_dict.get(lemma, [])\n",
    "            occurrence_count_list.append(occurrence_count)\n",
    "            lemma_count_dict[lemma] = occurrence_count_list\n",
    "    lemma_count_average_dict = {l: int(sum(c) / len(c)) for l, c in lemma_count_dict.items()}\n",
    "    lemma_count_average_dict = sort_dict_by_value(lemma_count_average_dict)\n",
    "    return lemma_count_average_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_count_average_dict = query_average_occurrence_count(\"word2vec\", decade_list_test)\n",
    "    print(list(lemma_count_average_dict.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339d3b8-3aa5-4032-9033-4b94bcef99d4",
   "metadata": {},
   "source": [
    "### query_over_mutual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6cb1c-def8-44b5-acef-e6ed27815740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_over_mutual(table_name_list, select_cols=COLS_EMBEDDING):\n",
    "    print(\"query_over_mutual: start: table_name_list:\", table_name_list)\n",
    "    common_lemma = query_mutual_lemmas(table_name_list, include_count=False)\n",
    "    embeddings_table_list = []\n",
    "    for table_name in table_name_list:\n",
    "        embeddings_table_list.append(query_generic(table_name, common_lemma, select_cols=select_cols, order_by=\"lemma\"))\n",
    "    return zip(*embeddings_table_list)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    for count, x in enumerate(query_over_mutual([\"word2vec__183\", \"word2vec__184\"])):\n",
    "        a = x[0]\n",
    "        b = x[1]\n",
    "        print(a[0:2], a[2].shape, b[0:2], b[2].shape)\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560b448f-8ad0-4ddf-9131-5438414f47c3",
   "metadata": {},
   "source": [
    "## difference analysis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797b6e1-33f3-45e0-a711-86d51d547d7c",
   "metadata": {},
   "source": [
    "### calculate_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f02bef-6c1c-47b2-ba0e-ca03eea28722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_sim(embedding_a: np.ndarray, embedding_b: np.ndarray) -> float:\n",
    "    return np.dot(embedding_a, embedding_b) / (np.linalg.norm(embedding_a) * np.linalg.norm(embedding_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d60524-a615-4213-bc2a-d05edfa78180",
   "metadata": {},
   "source": [
    "### calculate_cos_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c26e6-cf9a-4fed-bb75-be68aaa67d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_distance(embedding_a: np.ndarray, embedding_b: np.ndarray) -> float:\n",
    "    return 1 - calculate_cos_sim(embedding_a, embedding_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908ad80-d33c-4bde-a049-e42f89136c02",
   "metadata": {},
   "source": [
    "### calculate_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54291d-0139-468a-9668-6aad14749cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tsne(embeddings, perplexity=None):\n",
    "    if perplexity is None:\n",
    "        if len(embeddings) < 6:\n",
    "            perplexity = len(embeddings) - 1\n",
    "        else:\n",
    "            perplexity = 5\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    embeddings_reduced = tsne.fit_transform(np.array(embeddings))\n",
    "    return embeddings_reduced\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    embeddings_reduced = calculate_tsne(query_generic(\"word2vec__185\", TEST_LEMMA_CLOSE_LIST, select_cols=[\"embedding\"]))\n",
    "    print(embeddings_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67979ca3-07c2-4b15-9bdf-7bf358f49360",
   "metadata": {},
   "source": [
    "### calculate_trajectory_between_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66127113-facd-4cb9-a43d-2a112afa02dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trajectory_between_vectors(vector_a, vector_b, vector_c):\n",
    "    vector_ab = vector_a - vector_b\n",
    "    vector_bc = vector_b - vector_c\n",
    "    return np.dot(vector_ab, vector_bc)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    vector_list_list = [\n",
    "        (np.array([1, 2]), np.array([2, 3]), np.array([2, 5])),\n",
    "        (np.array([1, 2]), np.array([2, 3]), np.array([2, 3])),\n",
    "        (np.array([1, 2]), np.array([2, 3]), np.array([1, 2])),\n",
    "    ]\n",
    "    for vector_list in vector_list_list:\n",
    "        print(calculate_trajectory_between_vectors(*vector_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde629a-b62a-4bfd-8023-51bf0865c671",
   "metadata": {},
   "source": [
    "### calculate_procrustes_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec26a94-baf4-4239-8985-7c865dac662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_procrustes_alignment(table_name_a, table_name_b, table_aligned_name_b):\n",
    "    print(\"calculate_procrustes_alignment: start\")\n",
    "    overlap_matrix_a = []\n",
    "    overlap_matrix_b = []\n",
    "    for lemma_embedding_a, lemma_embedding_b in query_over_mutual([table_name_a, table_name_b]):\n",
    "        occurrence_count_sqrt = np.log1p((lemma_embedding_a[1] + lemma_embedding_b[1]) / 2)\n",
    "        overlap_matrix_a.append(lemma_embedding_a[2] * occurrence_count_sqrt)\n",
    "        overlap_matrix_b.append(lemma_embedding_b[2] * occurrence_count_sqrt)\n",
    "    overlap_matrix_a = np.stack(overlap_matrix_a)\n",
    "    overlap_matrix_b = np.stack(overlap_matrix_b)\n",
    "\n",
    "    # do procrustes transformation\n",
    "    r, _ = orthogonal_procrustes(overlap_matrix_b, overlap_matrix_a)\n",
    "    embeddings_table_all_b = query_generic(table_name_b, select_cols=COLS_EMBEDDING, order_by=\"lemma\")\n",
    "    matrix_b = [e[2] for e in embeddings_table_all_b]\n",
    "    matrix_b = np.stack(matrix_b)\n",
    "    matrix_b_aligned = matrix_b @ r\n",
    "    matrix_b_aligned_normalized = matrix_b_aligned / np.linalg.norm(matrix_b_aligned, axis=1, keepdims=True)\n",
    "    print(\"calculate_procrustes_alignment: matrix_b_aligned.shape:\", matrix_b_aligned.shape)\n",
    "    db_insertion_data = []\n",
    "    for embeddings_table_b_data, embedding_b_aligned in zip(embeddings_table_all_b, matrix_b_aligned_normalized):\n",
    "        db_insertion_data.append([embeddings_table_b_data[0], embeddings_table_b_data[1], embedding_b_aligned])\n",
    "    drop_table(table_aligned_name_b)\n",
    "    create_embeddings_table(table_aligned_name_b)\n",
    "    insert_to_db(table_aligned_name_b, db_insertion_data)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    calculate_procrustes_alignment(\"word2vec__184\", \"word2vec__185\", \"word2vec__185__aligned\")\n",
    "    calculate_procrustes_alignment(\"word2vec__185__aligned\", \"word2vec__186\", \"word2vec__186__aligned\")\n",
    "    embeddings_table_184 = query_generic(\n",
    "        \"word2vec__184\",\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        select_cols=[\"lemma\", \"embedding\"],\n",
    "        order_by=\"lemma\",\n",
    "    )\n",
    "    embeddings_table_185 = query_generic(\n",
    "        \"word2vec__185\",\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        select_cols=[\"lemma\", \"embedding\"],\n",
    "        order_by=\"lemma\",\n",
    "    )\n",
    "    embeddings_table_186 = query_generic(\n",
    "        \"word2vec__186\",\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        select_cols=[\"lemma\", \"embedding\"],\n",
    "        order_by=\"lemma\",\n",
    "    )\n",
    "    embeddings_table_185_aligned = query_generic(\n",
    "        \"word2vec__185__aligned\",\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        select_cols=[\"lemma\", \"embedding\"],\n",
    "        order_by=\"lemma\",\n",
    "    )\n",
    "    embeddings_table_186_aligned = query_generic(\n",
    "        \"word2vec__186__aligned\",\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        select_cols=[\"lemma\", \"embedding\"],\n",
    "        order_by=\"lemma\",\n",
    "    )\n",
    "    for lemma, e_184, e_185, e_186, e_185_aligned, e_186_aligned in zip(\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        embeddings_table_184,\n",
    "        embeddings_table_185,\n",
    "        embeddings_table_186,\n",
    "        embeddings_table_185_aligned,\n",
    "        embeddings_table_186_aligned,\n",
    "    ):\n",
    "        print(lemma)\n",
    "        print(\"184-185:\", calculate_cos_sim(e_184[1], e_185[1]))\n",
    "        print(\"185-186:\", calculate_cos_sim(e_185[1], e_186[1]))\n",
    "        print(\"184-185_aligned:\", calculate_cos_sim(e_184[1], e_185_aligned[1]))\n",
    "        print(\"184_aligned-185_aligned:\", calculate_cos_sim(e_185_aligned[1], e_186_aligned[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66775e-5bcd-46cb-8213-6971496bb6f1",
   "metadata": {},
   "source": [
    "### calculate_cos_sim_between_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb5814-48e1-4ef3-be5a-653f27590f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_sim_between_tables(table_name_a, table_name_b, table_name_diff):\n",
    "    print(\n",
    "        \"calculate_cos_sim_between_tables: start: (table_name_a, table_name_b, table_name_diff)\",\n",
    "        (table_name_a, table_name_b, table_name_diff),\n",
    "    )\n",
    "    db_insertion_data = []\n",
    "    for lemma_embedding_a, lemma_embedding_b in query_over_mutual([table_name_a, table_name_b]):\n",
    "        db_insertion_data.append(\n",
    "            (\n",
    "                lemma_embedding_a[0],\n",
    "                int((lemma_embedding_a[1] + lemma_embedding_b[1]) / 2),\n",
    "                calculate_cos_sim(lemma_embedding_a[2], lemma_embedding_b[2]),\n",
    "            )\n",
    "        )\n",
    "    print(\"calculate_cos_sim_between_tables: len(db_insertion_data):\", len(db_insertion_data))\n",
    "    drop_table(table_name_diff)\n",
    "    create_diff_table(table_name_diff)\n",
    "    insert_to_db(table_name_diff, db_insertion_data, cols=[\"lemma\", \"occurrence_count\", \"diff\"])\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    calculate_cos_sim_between_tables(\"word2vec__184\", \"word2vec__185__aligned\", \"word2vec__diff__cos_sim__184_185\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124d33a-12fa-41ad-9b73-4f400ed27930",
   "metadata": {},
   "source": [
    "### calculate_trajectory_between_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d2d56-898e-4856-9d7a-2d324293bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trajectory_between_tables(table_name_a, table_name_b, table_name_c, table_name_diff):\n",
    "    print(\n",
    "        \"calculate_trajectory_between_tables: start: (table_name_a, table_name_b, table_name_c, table_name_diff):\",\n",
    "        (table_name_a, table_name_b, table_name_c, table_name_diff),\n",
    "    )\n",
    "    db_insertion_data = []\n",
    "    for lemma_embedding_a, lemma_embedding_b, lemma_embedding_c in query_over_mutual([table_name_a, table_name_b, table_name_c]):\n",
    "        db_insertion_data.append(\n",
    "            (\n",
    "                lemma_embedding_a[0],\n",
    "                int((lemma_embedding_a[1] + lemma_embedding_b[1] + lemma_embedding_c[1]) / 3),\n",
    "                calculate_trajectory_between_vectors(lemma_embedding_a[2], lemma_embedding_b[2], lemma_embedding_c[2]),\n",
    "            )\n",
    "        )\n",
    "    print(\"calculate_cos_sim_between_tables: len(db_insertion_data):\", len(db_insertion_data))\n",
    "    drop_table(table_name_diff)\n",
    "    create_diff_table(table_name_diff)\n",
    "    insert_to_db(table_name_diff, db_insertion_data, cols=[\"lemma\", \"occurrence_count\", \"diff\"])\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    calculate_trajectory_between_tables(\n",
    "        \"word2vec__184\", \"word2vec__185__aligned\", \"word2vec__186__aligned\", \"word2vec__diff__trajectory__184_186\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28537d-811a-403d-9210-44c323abbb2e",
   "metadata": {},
   "source": [
    "### calculate_relative_diff_between_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d16d8-8254-4003-a182-5612b6d94a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_diff_between_tables(table_name_a, table_name_b, table_name_diff):\n",
    "    print(\"calculate_relative_diff_between_tables: start: (table_name_a, table_name_b):\", (table_name_a, table_name_b))\n",
    "    db_insertion_data = []\n",
    "    for mutual in query_mutual_lemmas([table_name_a, table_name_b], include_count=True):\n",
    "        lemma = mutual[0]\n",
    "        related_lemma_embedding_a = query_related(table_name_a, lemma, n=100)\n",
    "        related_lemma_embedding_b = query_related(table_name_b, lemma, n=100)\n",
    "        similarity_dict_a = {l: c for l, c in related_lemma_embedding_a}\n",
    "        similarity_dict_b = {l: c for l, c in related_lemma_embedding_b}\n",
    "        common_related_lemma = set(similarity_dict_a.keys()) & set(similarity_dict_b.keys())\n",
    "        diff = 0\n",
    "        for lemma_related in common_related_lemma:\n",
    "            diff += abs(similarity_dict_a[lemma_related] - similarity_dict_b[lemma_related])\n",
    "        db_insertion_data.append((lemma, int(mutual[1] / 2), diff))\n",
    "    print(\"calculate_cos_sim_between_tables: len(db_insertion_data):\", len(db_insertion_data))\n",
    "    drop_table(table_name_diff)\n",
    "    create_diff_table(table_name_diff)\n",
    "    insert_to_db(table_name_diff, db_insertion_data, cols=[\"lemma\", \"occurrence_count\", \"diff\"])\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    calculate_relative_diff_between_tables(\"word2vec__184\", \"word2vec__185\", \"word2vec__diff__relative__184_185\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54063f6-a3eb-4949-9797-852dd9530360",
   "metadata": {},
   "source": [
    "### normalize_diff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0376830f-04c2-443a-bb58-45a0209d0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_diff_table(diff_table_name, diff_table_name_new, invert=False):\n",
    "    print(\"normalize_diff_table: start: table_name_diff:\", diff_table_name)\n",
    "    diff_table = query_generic(diff_table_name, select_cols=COLS_DIFF, order_by=\"diff\")\n",
    "    min_diff = None\n",
    "    max_diff = None\n",
    "    for diff_row in diff_table:\n",
    "        diff_value = diff_row[2]\n",
    "        if min_diff is None and max_diff is None:\n",
    "            min_diff = diff_value\n",
    "            max_diff = diff_value\n",
    "        else:\n",
    "            if diff_value < min_diff:\n",
    "                min_diff = diff_value\n",
    "            if diff_value > max_diff:\n",
    "                max_diff = diff_value\n",
    "    scale = 2 / (max_diff - min_diff)\n",
    "    print(max_diff)\n",
    "    diff_table_new = []\n",
    "    for diff_row in diff_table:\n",
    "        value = ((diff_row[2] - min_diff) * scale) - 1\n",
    "        if invert:\n",
    "            value *= -1\n",
    "        diff_table_new.append((diff_row[0], diff_row[1], value))\n",
    "    print(\"normalize_diff_table: len(diff_table_new):\", len(diff_table_new))\n",
    "    drop_table(diff_table_name_new)\n",
    "    create_diff_table(diff_table_name_new)\n",
    "    insert_to_db(diff_table_name_new, diff_table_new, cols=COLS_DIFF)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    normalize_diff_table(\"word2vec__diff__cos_sim__184_185\", \"word2vec__diff__cos_sim__normalized__184_185\")\n",
    "    normalize_diff_table(\"word2vec__diff__trajectory__184_186\", \"word2vec__diff__trajectory__normalized__184_186\")\n",
    "    normalize_diff_table(\"word2vec__diff__relative__184_185\", \"word2vec__diff__relative__normalized__184_185\", invert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acd79d-0484-47d3-984c-718bc0b8e307",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e523ce57-2502-4fcc-bd36-6bbd87d369a3",
   "metadata": {},
   "source": [
    "### plot_tsne_from_labels_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7e74a-c798-48c8-850c-e61abea2fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_from_labels_embeddings(\n",
    "    label_embedding_list: list[str, Embedding],\n",
    "    title: str = None,\n",
    "    height: int = None,\n",
    "    width: int = None,\n",
    "    rotation_degree: int = None,\n",
    "    perplexity: int = None,\n",
    "):\n",
    "    labels = []\n",
    "    embeddings = []\n",
    "    for l, e in label_embedding_list:\n",
    "        labels.append(l)\n",
    "        embeddings.append(e)\n",
    "    reduced_vectors_tsne = calculate_tsne(embeddings, perplexity)\n",
    "\n",
    "    if rotation_degree:\n",
    "        angle_rad = np.deg2rad(-rotation_degree)\n",
    "        rotation_matrix = np.array([[np.cos(angle_rad), -np.sin(angle_rad)], [np.sin(angle_rad), np.cos(angle_rad)]])\n",
    "        reduced_vectors_tsne = reduced_vectors_tsne @ rotation_matrix.T\n",
    "\n",
    "    if height is None:\n",
    "        height = 800\n",
    "    if width is None:\n",
    "        width = 800\n",
    "    time.sleep(PLOT_SLEEP)\n",
    "    fig = px.scatter(\n",
    "        x=reduced_vectors_tsne[:, 0],\n",
    "        y=reduced_vectors_tsne[:, 1],\n",
    "        text=labels,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        title=title,\n",
    "    )\n",
    "    fig.update_layout(xaxis=dict(title=None, showticklabels=False), yaxis=dict(title=None, showticklabels=False))\n",
    "    fig.update_traces(\n",
    "        marker=dict(size=10),\n",
    "        textposition=\"bottom center\",\n",
    "        textfont=dict(size=12),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_embedding_list = query_generic(\"word2vec__185\", lemma_list=TEST_LEMMA_CLOSE_LIST, select_cols=[\"lemma\", \"embedding\"])\n",
    "    plot_tsne_from_labels_embeddings(lemma_embedding_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef5750-3378-4d81-a89a-4c0b38c16339",
   "metadata": {},
   "source": [
    "### plot_tsne_from_lemma_and_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ab989-c2ac-499d-99f1-de8a7302c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_from_lemma_and_related(\n",
    "    table_name,\n",
    "    lemma: str = None,\n",
    "    n: int = 100,\n",
    "    title: str = None,\n",
    "    height: int = None,\n",
    "    width: int = None,\n",
    "    rotation_degree: int = None,\n",
    "):\n",
    "    plot_tsne_from_labels_embeddings(query_related(table_name, lemma, select_cols=[\"lemma\", \"embedding\"], n=n))\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    plot_tsne_from_lemma_and_related(\"word2vec__185\", lemma=\"gehen\", n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5f43a-bf3e-428d-88bd-09ec9b0b7926",
   "metadata": {},
   "source": [
    "### plot_2d_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94128bff-5d4e-471e-b65f-37ad50dba3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_scatter(data: dict | list[list], title: str = None, draw_line=False):\n",
    "    time.sleep(PLOT_SLEEP)\n",
    "    key_list = []\n",
    "    value_list = []\n",
    "    if type(data) is dict:\n",
    "        for key, value in data.items():\n",
    "            key_list.append(key)\n",
    "            value_list.append(value)\n",
    "    else:\n",
    "        for key, value in data:\n",
    "            key_list.append(key)\n",
    "            value_list.append(value)\n",
    "    fig = px.scatter(x=key_list, y=value_list, title=title)\n",
    "    if draw_line:\n",
    "        fig.update_traces(mode=\"lines+markers\")\n",
    "    fig.update_layout(xaxis_title=None, yaxis_title=None)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "if TEST:\n",
    "\n",
    "    # general lemma occurrence count\n",
    "    # plot_2d_scatter(query_average_occurrence_count(\"word2vec\", decade_list_test), \"lemma occurrence count in 183\")\n",
    "\n",
    "    # base differences\n",
    "    # word2vec__diff__cos_sim__184_185 = query_generic(\n",
    "    #     \"word2vec__diff__cos_sim__184_185\",\n",
    "    #     select_cols=[\"lemma\", \"diff\"],\n",
    "    #     order_by=\"diff\",\n",
    "    #     order_desc=True,\n",
    "    # )\n",
    "    # word2vec__diff__trajectory__184_186 = query_generic(\n",
    "    #     \"word2vec__diff__trajectory__184_186\",\n",
    "    #     select_cols=[\"lemma\", \"diff\"],\n",
    "    #     order_by=\"diff\",\n",
    "    #     order_desc=True,\n",
    "    # )\n",
    "    # word2vec__diff__relative__184_185 = query_generic(\n",
    "    #     \"word2vec__diff__relative__184_185\",\n",
    "    #     select_cols=[\"lemma\", \"diff\"],\n",
    "    #     order_by=\"diff\",\n",
    "    #     order_desc=False,\n",
    "    # )\n",
    "    # plot_2d_scatter(word2vec__diff__cos_sim__184_185, \"word2vec__diff__cos_sim__184_185\")\n",
    "    # plot_2d_scatter(word2vec__diff__trajectory__184_186, \"word2vec__diff__trajectory__184_186\")\n",
    "    # plot_2d_scatter(word2vec__diff__relative__184_185, \"word2vec__diff__relative__184_185\")\n",
    "\n",
    "    # # normalized differences\n",
    "    word2vec__diff__cos_sim__normalized__184_185 = query_generic(\n",
    "        \"word2vec__diff__cos_sim__normalized__184_185\",\n",
    "        select_cols=[\"lemma\", \"diff\"],\n",
    "        order_by=\"diff\",\n",
    "        order_desc=True,\n",
    "    )\n",
    "    word2vec__diff__trajectory__normalized__184_186 = query_generic(\n",
    "        \"word2vec__diff__trajectory__normalized__184_186\",\n",
    "        select_cols=[\"lemma\", \"diff\"],\n",
    "        order_by=\"diff\",\n",
    "        order_desc=True,\n",
    "    )\n",
    "    word2vec__diff__relative__normalized__184_185 = query_generic(\n",
    "        \"word2vec__diff__relative__normalized__184_185\",\n",
    "        select_cols=[\"lemma\", \"diff\"],\n",
    "        order_by=\"diff\",\n",
    "        order_desc=True,\n",
    "    )\n",
    "    plot_2d_scatter(word2vec__diff__cos_sim__normalized__184_185, \"word2vec__diff__cos_sim__normalized__184_185\")\n",
    "    plot_2d_scatter(word2vec__diff__trajectory__normalized__184_186, \"word2vec__diff__trajectory__normalized__184_186\")\n",
    "    plot_2d_scatter(word2vec__diff__relative__normalized__184_185, \"word2vec__diff__relative__normalized__184_185\")\n",
    "\n",
    "    # # differences of differences\n",
    "    # plot_2d_scatter(lemma_diff_cos_sim_trajectory_183_185_dict, \"lemma_diff_cos_sim_trajectory_183_185_dict\")\n",
    "    # plot_2d_scatter(lemma_diff_cos_sim_relative_diff_183_185_dict, \"lemma_diff_cos_sim_relative_diff_183_185_dict\")\n",
    "    # plot_2d_scatter(lemma_diff_trajectory_relative_diff_183_185_dict, \"lemma_diff_trajectory_relative_diff_183_185_dict\")\n",
    "    # plot_2d_scatter(lemma_diff_random_cos_sim_trajectory_dict, \"lemma_diff_random_cos_sim_trajectory_dict\")\n",
    "\n",
    "    # # merged differences of differences\n",
    "    # plot_2d_scatter(lemma_cos_sim_trajectory_183_185_merged_dict, \"lemma_cos_sim_trajectory_183_185_merged_dict\")\n",
    "    # plot_2d_scatter(lemma_cos_sim_relative_diff_183_185_merged_dict, \"lemma_cos_sim_relative_diff_183_185_merged_dict\")\n",
    "    # plot_2d_scatter(lemma_trajectory_relative_diff_183_185_merged_dict, \"lemma_trajectory_relative_diff_183_185_merged_dict\")\n",
    "    # plot_2d_scatter(lemma_merged_random_diff_dict, \"lemma_merged_random_diff_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe0722-f900-4c39-ae9e-66ef7bdc11d3",
   "metadata": {},
   "source": [
    "### plot_lemma_and_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0cf9f-79c9-43a8-a3cd-b1218e3aabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lemma_and_decade(lemma_decade_embdding_dict: dict[Lemma, dict[Decade, Embedding]], perplexity=None, title=None):\n",
    "    time.sleep(PLOT_SLEEP)\n",
    "\n",
    "    # prepare data\n",
    "    global_labels_list = []\n",
    "    global_embeddings_list = []\n",
    "    group_end_position_list = []\n",
    "    position_count = 0\n",
    "    for lemma, decade_embedding_dict in lemma_decade_embdding_dict.items():\n",
    "        for decade, embedding in decade_embedding_dict.items():\n",
    "            global_labels_list.append(str(decade) + \":\" + lemma)\n",
    "            global_embeddings_list.append(embedding)\n",
    "            position_count += 1\n",
    "        group_end_position_list.append(position_count)\n",
    "    if 1 < len(global_embeddings_list) < 6:\n",
    "        perplexity = len(global_embeddings_list) - 1\n",
    "    else:\n",
    "        perplexity = None\n",
    "    lemma_embeddings_reduced_array = calculate_tsne(global_embeddings_list, perplexity=perplexity)\n",
    "\n",
    "    # create plot\n",
    "    fig = go.Figure()\n",
    "    group_start_position = 0\n",
    "    for group_end_position in group_end_position_list:\n",
    "        lemma_respective_embeddings = lemma_embeddings_reduced_array[group_start_position:group_end_position]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=lemma_respective_embeddings[:, 0],\n",
    "                y=lemma_respective_embeddings[:, 1],\n",
    "                mode=\"lines\",\n",
    "            )\n",
    "        )\n",
    "        group_start_position = group_end_position\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=lemma_embeddings_reduced_array[:, 0],\n",
    "            y=lemma_embeddings_reduced_array[:, 1],\n",
    "            mode=\"markers+text\",\n",
    "            text=global_labels_list,\n",
    "            textposition=\"top center\",\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=title if title is not None else \"\",\n",
    "        showlegend=False,\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_decade_embdding_dict = {}\n",
    "    print(\"trajectories:\")\n",
    "    for lemma in [\"d\", \"wohnen\", \"FÃ¼rst\"]:\n",
    "        print(lemma, lemma_trajectory_183_184_185_dict[lemma])\n",
    "        lemma_decade_embdding_dict[lemma] = {\n",
    "            183: query_generic(word2vec_183_index, lemma),\n",
    "            184: query_generic(word2vec_184_index, lemma),\n",
    "            185: query_generic(word2vec_185_index, lemma),\n",
    "        }\n",
    "    plot_lemma_and_decade(lemma_decade_embdding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177a6edd-dde5-4534-b715-8afe108a8b4c",
   "metadata": {},
   "source": [
    "### plot_lemma_and_decade_from_lemma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623aa31-5564-44a1-b56a-531f1e0cd41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lemma_and_decade_from_lemma_list(lemma_list, title=None):\n",
    "    lemma_decade_embdding_dict = load_embeddings_from_persisted_decade_data(decade_list, lemma_list)\n",
    "    plot_lemma_and_decade(lemma_decade_embdding_dict, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e1a24-a962-409f-b37a-fc8d24163d76",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e13dfaa-bd0f-478e-8068-ef51aa3759ae",
   "metadata": {},
   "source": [
    "## OLD: data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf229bb-96cd-432a-9b93-f5558adf263e",
   "metadata": {},
   "source": [
    "### OLD: create_index_from_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a8a67-0e81-4437-b884-73477a6530bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_from_word2vec(decade) -> Word2VecIndex:\n",
    "    print(\"create_index: start: decade:\", decade)\n",
    "    model_path = MODELS_WORD2VEC_FOLDER + str(decade) + \".bin\"\n",
    "    model = Word2Vec.load(model_path)\n",
    "    id_to_lemma_dict: IdToLemmaDict = {}\n",
    "    lemma_to_id_dict: LemmaToIdDict = {}\n",
    "    embedding_list = []\n",
    "    for lemma_id, lemma in enumerate(model.wv.index_to_key):\n",
    "        if is_word(lemma):\n",
    "            embedding = model.wv[lemma]\n",
    "            embedding_normalized = embedding / np.linalg.norm(embedding)\n",
    "            embedding_list.append(embedding_normalized)\n",
    "            id_to_lemma_dict[lemma_id] = lemma\n",
    "            lemma_to_id_dict[lemma] = lemma_id\n",
    "    dim = embedding_list[0].shape[0]\n",
    "    hnsw_index = hnswlib.Index(space=\"cosine\", dim=dim)\n",
    "    hnsw_index.init_index(max_elements=len(embedding_list), ef_construction=INDEX_EF_CONSTRUCTION, M=INDEX_M)\n",
    "    hnsw_index.add_items(embedding_list, ids=list(id_to_lemma_dict.keys()))\n",
    "    index = (hnsw_index, lemma_to_id_dict, id_to_lemma_dict)\n",
    "    print(\"create_lemma_dict_and_index: hnsw_index.get_current_count:\", hnsw_index.get_current_count())\n",
    "    return index\n",
    "\n",
    "\n",
    "# def create_index_test():\n",
    "#     word2vec_183_index = create_index_from_word2vec(183)\n",
    "#     word2vec_184_index = create_index_from_word2vec(184)\n",
    "#     word2vec_185_index = create_index_from_word2vec(185)\n",
    "#     return word2vec_183_index, word2vec_184_index, word2vec_185_index\n",
    "\n",
    "\n",
    "# word2vec_183_index, word2vec_184_index, word2vec_185_index = create_index_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6990ae4-568c-4dcf-a24d-436cf14d0015",
   "metadata": {},
   "source": [
    "### OLD: sort_dict_by_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f66d94-438d-48ef-88a0-b7e97a42a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict_by_value(key_value_dict: dict, desc=True) -> dict:\n",
    "    if desc:\n",
    "        sort_mod = -1\n",
    "    else:\n",
    "        sort_mod = 1\n",
    "    return dict(sorted(key_value_dict.items(), key=lambda x: sort_mod * x[1]))\n",
    "\n",
    "\n",
    "def sort_dict_by_value_test():\n",
    "    global lemma_occurrence_count_183_dict\n",
    "    global lemma_occurrence_count_184_dict\n",
    "    global lemma_occurrence_count_185_dict\n",
    "    lemma_occurrence_count_183_dict = sort_dict_by_value(lemma_occurrence_count_183_dict)\n",
    "    lemma_occurrence_count_184_dict = sort_dict_by_value(lemma_occurrence_count_184_dict)\n",
    "    lemma_occurrence_count_185_dict = sort_dict_by_value(lemma_occurrence_count_185_dict)\n",
    "    return lemma_occurrence_count_183_dict, lemma_occurrence_count_184_dict, lemma_occurrence_count_185_dict\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     lemma_occurrence_count_183_dict, lemma_occurrence_count_184_dict, lemma_occurrence_count_185_dict = load_cache_or_run(\n",
    "#         sort_dict_by_value_test\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bef6a1-10d1-425e-9dd1-9ff8acc78734",
   "metadata": {},
   "source": [
    "### OLD: get_common_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5a1dd-70ac-4a5e-848a-d3dc3d496d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_keys(*lemma_dict_list: list[dict]) -> set:\n",
    "    common_set = set(lemma_dict_list[0])\n",
    "    for lemma_dict in lemma_dict_list[1:]:\n",
    "        common_set &= lemma_dict.keys()\n",
    "    return common_set\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     print(get_common_keys({\"a\": 1, \"b\": 2}, {\"a\": 1, \"c\": 3}, {\"a\": 1, \"b\": 2, \"c\": 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f5031-bf4e-4658-9f0a-6d32e1de8f26",
   "metadata": {},
   "source": [
    "### OLD: merge_count_occurrences_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933136b4-01bd-4148-b3d0-85f773d74eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_count_occurrences_dict(lemma_occurrence_count_a_dict, lemma_occurrence_count_b_dict):\n",
    "    print(\n",
    "        \"merge_count_occurrences_dict: start: \" \"len(lemma_occurrence_count_a_dict):\",\n",
    "        len(lemma_occurrence_count_a_dict),\n",
    "        \"len(lemma_occurrence_count_b_dict):\",\n",
    "        len(lemma_occurrence_count_b_dict),\n",
    "    )\n",
    "    lemma_occurrence_count_dict_merged = {}\n",
    "    for lemma in get_common_keys(lemma_occurrence_count_a_dict, lemma_occurrence_count_b_dict):\n",
    "        lemma_occurrence_count_dict_merged[lemma] = lemma_occurrence_count_a_dict[lemma] + lemma_occurrence_count_b_dict[lemma]\n",
    "    print(\"merge_count_occurrences_dict: len(lemma_occurrence_count_dict_merged):\", len(lemma_occurrence_count_dict_merged))\n",
    "    return lemma_occurrence_count_dict_merged\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     lemma_occurrence_count_merged_183_184_dict = merge_count_occurrences_dict(\n",
    "#         lemma_occurrence_count_183_dict, lemma_occurrence_count_184_dict\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa846d34-4e4a-4000-a3a1-582524cfe7f0",
   "metadata": {},
   "source": [
    "### OLD: filter_on_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec1894-d4d1-4c15-8b55-d36c294e1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_values(key_value_dict: dict, limit_min: float = None, limit_max: float = None):\n",
    "    key_value_dict_new = {}\n",
    "    for lemma, value in key_value_dict.items():\n",
    "        if limit_min and limit_max:\n",
    "            if limit_min <= value <= limit_max:\n",
    "                key_value_dict_new[lemma] = value\n",
    "        elif limit_min:\n",
    "            if limit_min <= value:\n",
    "                key_value_dict_new[lemma] = value\n",
    "        elif limit_max:\n",
    "            if value <= limit_max:\n",
    "                key_value_dict_new[lemma] = value\n",
    "    return key_value_dict_new\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     print(filter_on_values({\"gehen\": 0.9, \"laufen\": 0.5, \"wandern\": 0.7}, limit_min=0.6, limit_max=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4294a-1b34-404e-bfc5-6a2ac3c3971f",
   "metadata": {},
   "source": [
    "## OLD: vector and index functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130c89ec-42ce-4083-bef9-526ac4e0b1fb",
   "metadata": {},
   "source": [
    "### OLD: query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895f1fa-41ed-4b9c-855c-722c1c79bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_generic(index: Index, lemma: Lemma) -> float:\n",
    "    lemma_id = index[1].get(lemma)\n",
    "    if lemma_id is not None:\n",
    "        embedding = index[0].get_items([lemma_id])[0]\n",
    "    else:\n",
    "        embedding = None\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     embedding = query_embedding(word2vec_183_index, \"Haus\")\n",
    "#     print(embedding.shape)\n",
    "#     assert query_embedding(word2vec_183_index, \"kljwklerjas\") is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed2196-185b-45eb-9f3e-e356a4027ab4",
   "metadata": {},
   "source": [
    "### OLD: query_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77994581-272b-48e6-9c75-7a0ff66871e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_related(\n",
    "    index: Index,\n",
    "    lemma: Lemma,\n",
    "    n: int = 10,\n",
    "    return_as_dict: bool = True,\n",
    "    keep_search: bool = False,\n",
    ") -> dict[str, float] | list[str]:\n",
    "    result = None\n",
    "    id_embedding = index[1].get(lemma)\n",
    "    if id_embedding is not None:\n",
    "        if keep_search:\n",
    "            distances_start = 0\n",
    "        else:\n",
    "            n += 1\n",
    "            distances_start = 1\n",
    "        embedding = index[0].get_items([id_embedding])[0]\n",
    "        ids, distances = index[0].knn_query(embedding.reshape(1, -1), k=n)\n",
    "        if return_as_dict:\n",
    "            result = {}\n",
    "        else:\n",
    "            result = []\n",
    "        for id_other, distance in list(zip(ids[0], distances[0]))[distances_start:]:\n",
    "            cos_sim = 1 - distance\n",
    "            lemma_related = index[2][id_other]\n",
    "            if return_as_dict:\n",
    "                result[lemma_related] = cos_sim\n",
    "            else:\n",
    "                result.append(lemma_related)\n",
    "    return result\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     print(query_related(word2vec_184_index, \"gehen\", n=10))\n",
    "#     print(query_related(word2vec_185_index, \"gehen\", n=10, keep_search=True))\n",
    "#     print(query_related(word2vec_185_index, \"gehen\", n=10, return_as_dict=False))\n",
    "#     print(query_related(word2vec_185_index, \"aclkjalkc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9c5f7-d9ca-45c1-b01a-c062c6362f6c",
   "metadata": {},
   "source": [
    "### OLD: calculate_average_sentence_embedding_from_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1293c-30d5-4155-9ae4-91a0bd8c99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_sentence_embedding_from_sentence(\n",
    "    sentence: str,\n",
    "    index: Index,\n",
    "    show_exception: bool = False,\n",
    ") -> np.ndarray:\n",
    "    embedding_list = []\n",
    "    for lemma in sentence.split(\" \"):\n",
    "        try:\n",
    "            embedding = query_generic(index, lemma)\n",
    "            if embedding is not None:\n",
    "                embedding_list.append(embedding)\n",
    "        except Exception as ex:\n",
    "            if show_exception:\n",
    "                print(ex, lemma)\n",
    "    embedding_avg = np.mean(np.array(embedding_list), axis=0)\n",
    "    return embedding_avg\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     v1 = calculate_average_sentence_embedding_from_sentence(\n",
    "#         \"d Mensch sein in d Haus\",\n",
    "#         word2vec_184_index,\n",
    "#         show_exception=True,\n",
    "#     )\n",
    "#     v2 = calculate_average_sentence_embedding_from_sentence(\n",
    "#         \"d Mann sein in d HÃ¼tte\",\n",
    "#         word2vec_184_index,\n",
    "#         show_exception=True,\n",
    "#     )\n",
    "#     v3 = calculate_average_sentence_embedding_from_sentence(\n",
    "#         \"d Ziege sein auf d Feld\",\n",
    "#         word2vec_184_index,\n",
    "#         show_exception=True,\n",
    "#     )\n",
    "#     print(calculate_cos_sim(v1, v2))\n",
    "#     print(calculate_cos_sim(v2, v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa30771-08f7-453e-8f36-d5adb8d399c8",
   "metadata": {},
   "source": [
    "### OLD: get_occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c2eb5-99e0-41ee-9879-54b2b4b11bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurrences(\n",
    "    decade: Decade,\n",
    "    line_number_dict: LineNumberDict,\n",
    "    max_elem: int = None,\n",
    "    highlight_lemma: bool = True,\n",
    "    keep_lemma: bool = True,\n",
    ") -> list[str]:\n",
    "    text_list = []\n",
    "    with open(TEXTS_FOLDER + str(decade) + \".txt\", \"r\") as f:\n",
    "        num_print = 0\n",
    "        for line_number, line in enumerate(f):\n",
    "            word_number_list = line_number_dict.get(line_number)\n",
    "            if word_number_list:\n",
    "                word_number_set = set(word_number_list)\n",
    "                text = \"\"\n",
    "                for word_number, word in enumerate(line.rstrip(\"\\n\").split(\" \")):\n",
    "                    if word_number in word_number_set and highlight_lemma and keep_lemma:\n",
    "                        text += \" ### \" + word + \" ###\"\n",
    "                    elif word_number not in word_number_set or (not highlight_lemma and keep_lemma):\n",
    "                        text += \" \" + word\n",
    "                    else:\n",
    "                        pass\n",
    "                text_list.append(text)\n",
    "                num_print += 1\n",
    "                if max_elem and num_print == max_elem:\n",
    "                    break\n",
    "    return text_list\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     print(get_occurrences(184, lemma_occurrence_position_184_dict[\"Haus\"], max_elem=1))\n",
    "#     print(get_occurrences(184, lemma_occurrence_position_184_dict[\"Haus\"], max_elem=1, highlight_lemma=False))\n",
    "#     print(get_occurrences(184, lemma_occurrence_position_184_dict[\"Haus\"], max_elem=1, keep_lemma=False))\n",
    "#     print(len(get_occurrences(184, lemma_occurrence_position_184_dict[\"Haus\"], max_elem=None, highlight_lemma=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e3151-5932-4f04-ae8a-e39e33eefc55",
   "metadata": {},
   "source": [
    "### OLD: calculate_average_sentence_embedding_from_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2fa6e-5174-4ef8-b72f-5a39696e2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_sentence_embedding_from_lemma(\n",
    "    decade: Decade,\n",
    "    line_number_dict: LineNumberDict,\n",
    "    index: Index,\n",
    "    max_sentences: int = 2,\n",
    ") -> np.ndarray:\n",
    "    sentence_list = get_occurrences(decade, line_number_dict, max_elem=max_sentences, highlight_lemma=False)\n",
    "    sentence_embedding_dict = {}\n",
    "    for sentence in sentence_list:\n",
    "        sentence_embedding_dict[sentence] = calculate_average_sentence_embedding_from_sentence(sentence, index)\n",
    "    return sentence_embedding_dict\n",
    "\n",
    "\n",
    "# if TEST:\n",
    "#     sentence_embedding_dict = calculate_average_sentence_embedding_from_lemma(\n",
    "#         184,\n",
    "#         lemma_occurrence_position_184_dict[\"gehen\"],\n",
    "#         word2vec_184_index,\n",
    "#         max_sentences=1,\n",
    "#     )\n",
    "#     for sentence, embedding in sentence_embedding_dict.items():\n",
    "#         print(sentence)\n",
    "#         print(embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e6a87-dcb9-4f90-831d-192ee2366d19",
   "metadata": {},
   "source": [
    "## difference analysis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8bc7c-b178-4723-a0d9-090faa075350",
   "metadata": {},
   "source": [
    "### DONE: calculate_procrustes_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30da27-a2cf-4826-904c-d80c26ec68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_procrustes_alignment(table_a, table_b):\n",
    "    print(\"calculate_procrustes_alignment: start\")\n",
    "\n",
    "    # create overlap matrices with embeddings weighted by count of occurrence\n",
    "    common_lemma = query_mutual_lemmas([table_a, table_b])\n",
    "    overlap_matrix_a = []\n",
    "    overlap_matrix_b = []\n",
    "    print(\"calculate_procrustes_alignment: len(common_lemma):\", len(common_lemma))\n",
    "    for lemma, occurrence_count in common_lemma:\n",
    "        occurrence_count_sqrt = np.sqrt(occurrence_count / 2)\n",
    "        embedding_a = query_generic(table_a, lemma)\n",
    "        embedding_b = query_generic(table_b, lemma)\n",
    "        if embedding_a is not None and embedding_b is not None:\n",
    "            # print(query_embedding(table_a, lemma))\n",
    "            # print(occurrence_count_sqrt)\n",
    "            embedding_a = query_generic(table_a, lemma) * occurrence_count_sqrt\n",
    "            embedding_b = query_generic(table_b, lemma) * occurrence_count_sqrt\n",
    "            overlap_matrix_a.append(embedding_a)\n",
    "            overlap_matrix_b.append(embedding_b)\n",
    "    overlap_matrix_a = np.stack(overlap_matrix_a)\n",
    "    overlap_matrix_b = np.stack(overlap_matrix_b)\n",
    "\n",
    "    # do procrustes transformation\n",
    "    r, _ = orthogonal_procrustes(overlap_matrix_b, overlap_matrix_a)\n",
    "    matrix_b = query_all(table_b)\n",
    "    # index_b_hnsw, lemma_to_id_b, id_to_lemma_b = index_b\n",
    "    # index_b_id_to_lemma_keys = list(id_to_lemma_b.keys())\n",
    "    # for i in index_b_id_to_lemma_keys:\n",
    "    #     embedding_b = index_b_hnsw.get_items([i])[0]\n",
    "    #     matrix_b.append(embedding_b)\n",
    "    matrix_b = np.stack(matrix_b)\n",
    "    matrix_b_aligned = matrix_b @ r\n",
    "    matrix_b_aligned_normalized = matrix_b_aligned / np.linalg.norm(matrix_b_aligned, axis=1, keepdims=True)\n",
    "    print(\"calculate_procrustes_alignment: matrix_b_aligned.shape:\", matrix_b_aligned.shape)\n",
    "\n",
    "    # create new index data structure\n",
    "    # index_b_aligned = hnswlib.Index(space=\"cosine\", dim=index_b[0].dim)\n",
    "    # index_b_aligned.init_index(max_elements=index_b[0].get_max_elements(), ef_construction=INDEX_EF_CONSTRUCTION, M=INDEX_M)\n",
    "    # index_b_aligned.add_items(matrix_b_aligned_normalized, index_b_id_to_lemma_keys)\n",
    "\n",
    "    # return (index_b_aligned, index_b[1], index_b[2])\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    calculate_procrustes_alignment(\"word2vec__184\", \"word2vec__185\")\n",
    "    # for lemma in [\"d\", \"und\", \"gehen\", \"wohnen\", \"FÃ¼rst\"]:\n",
    "    #     print(\"calculate_procrustes_alignment: lemma:\", lemma)\n",
    "    #     embedding_183 = query_embedding(word2vec_183_index, lemma)\n",
    "    #     embedding_184 = query_embedding(word2vec_184_index, lemma)\n",
    "    #     embedding_185 = query_embedding(word2vec_185_index, lemma)\n",
    "    #     embedding_aligned_184 = query_embedding(word2vec_184_aligned_index, lemma)\n",
    "    #     embedding_aligned_185 = query_embedding(word2vec_185_aligned_index, lemma)\n",
    "    #     cos_sim_183_184 = calculate_cos_sim(embedding_183, embedding_184)\n",
    "    #     cos_sim_184_185 = calculate_cos_sim(embedding_184, embedding_185)\n",
    "    #     cos_sim_aligned_183_184 = calculate_cos_sim(embedding_183, embedding_aligned_184)\n",
    "    #     cos_sim_aligned_184_185 = calculate_cos_sim(embedding_aligned_184, embedding_aligned_185)\n",
    "    #     print(\"calculate_procrustes_alignment:\", \"cos_sim_183_184:\", cos_sim_183_184)\n",
    "    #     print(\"calculate_procrustes_alignment:\", \"cos_sim_184_185:\", cos_sim_184_185)\n",
    "    #     print(\"calculate_procrustes_alignment:\", \"cos_sim_aligned_183_184:\", cos_sim_aligned_183_184)\n",
    "    #     print(\"calculate_procrustes_alignment:\", \"cos_sim_aligned_184_185:\", cos_sim_aligned_184_185)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6071c8b-73fe-465f-8d1a-acf6b3402632",
   "metadata": {},
   "source": [
    "### DONE: calculate_cos_sim_between_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2fb62d-9303-4469-8ea9-5af2f556dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_sim_between_indices(index_a: Index, index_b: Index) -> LemmaDiffDict:\n",
    "    print(\"calculate_cos_sim_between_indices: start\")\n",
    "    common_lemma = get_common_keys(index_a[1], index_b[1])\n",
    "    lemma_cos_sim_dict = {}\n",
    "    for lemma in common_lemma:\n",
    "        lemma_cos_sim_dict[lemma] = calculate_cos_sim(query_generic(index_a, lemma), query_generic(index_b, lemma))\n",
    "    lemma_cos_sim_dict = sort_dict_by_value(lemma_cos_sim_dict)\n",
    "    print(\"calculcate_cos_sim_between_indices: len(lemma_cos_sim_dict):\", len(lemma_cos_sim_dict))\n",
    "    return lemma_cos_sim_dict\n",
    "\n",
    "\n",
    "def calculate_cos_sim_between_indices_test():\n",
    "    lemma_cos_sim_dict_183_184 = calculate_cos_sim_between_indices(word2vec_183_index, word2vec_184_aligned_index)\n",
    "    return lemma_cos_sim_dict_183_184\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_cos_sim_183_184_dict = load_cache_or_run(calculate_cos_sim_between_indices_test)\n",
    "    for lemma in [\"d\", \"und\", \"gehen\", \"wohnen\", \"FÃ¼rst\"]:\n",
    "        print(\"calculcate_cos_sim_between_indices: lemma:\", lemma)\n",
    "        print(lemma_cos_sim_183_184_dict[lemma])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3199d241-072e-44ae-9e89-ddc37792a4ab",
   "metadata": {},
   "source": [
    "### OLD: weight_and_filter_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad1d66-a69e-4c14-a96f-b610ba675ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_and_filter_lemmas(lemma_value_dict, lemma_occurrence_count_dict, filter_threshold=100):\n",
    "    print(\"weight_and_filter_lemmas: start\")\n",
    "    lemma_value_dict_weighted = {}\n",
    "    for lemma, value in lemma_value_dict.items():\n",
    "        if filter_threshold and lemma_occurrence_count_dict[lemma] >= filter_threshold:\n",
    "            lemma_value_dict_weighted[lemma] = value * np.log1p(np.sqrt(lemma_occurrence_count_dict[lemma]))\n",
    "    lemma_value_dict_weighted = sort_dict_by_value(lemma_value_dict_weighted)\n",
    "    print(\"weight_and_filter_lemmas: len(lemma_value_dict_weighted)\", len(lemma_value_dict_weighted))\n",
    "    return lemma_value_dict_weighted\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_cos_sim_183_184_weighted_dict = weight_and_filter_lemmas(lemma_cos_sim_183_184_dict, lemma_occurrence_count_merged_183_184_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26b65a-15b9-4b23-9c80-32052b9a829d",
   "metadata": {},
   "source": [
    "### DONE: calculate_trajectory_from_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca5fc5-3503-4750-815e-45641b675a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trajectory_from_lemma(index_a: Index, index_b: Index, index_c: Index, lemma: Lemma) -> Trajectory:\n",
    "    a = query_generic(index_a, lemma)\n",
    "    b = query_generic(index_b, lemma)\n",
    "    c = query_generic(index_c, lemma)\n",
    "    if a is not None and b is not None and c is not None:\n",
    "        ab = a - b\n",
    "        bc = b - c\n",
    "        ab_bc_trajectory = np.dot(ab, bc)\n",
    "        return ab_bc_trajectory\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    for lemma in [\"d\", \"und\", \"gehen\", \"wohnen\", \"FÃ¼rst\"]:\n",
    "        ab_bc_trajectory = calculate_trajectory_from_lemma(\n",
    "            word2vec_183_index,\n",
    "            word2vec_184_aligned_index,\n",
    "            word2vec_185_aligned_index,\n",
    "            lemma,\n",
    "        )\n",
    "        print(\"calculate_trajectory_from_diff_per_lemma:\", lemma, ab_bc_trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efd97f-f201-47e1-920b-df23a56fbd72",
   "metadata": {},
   "source": [
    "### DONE: calculate_trajectory_dict_from_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38130a60-c9d9-415a-9b0d-5d5163f2bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trajectory_dict_from_index(index_a: Index, index_b: Index, index_c: Index) -> LemmaDiffDict:\n",
    "    print(\"calculate_trajectory_dict_from_index: start\")\n",
    "    lemma_trajectory_diff_list = []\n",
    "    common_lemma = get_common_keys(index_a[1], index_b[1], index_c[1])\n",
    "    for lemma in common_lemma:\n",
    "        lemma_trajectory_diff = calculate_trajectory_from_lemma(index_a, index_b, index_c, lemma)\n",
    "        lemma_trajectory_diff_list.append((lemma, lemma_trajectory_diff))\n",
    "    lemma_trajectory_diff_list = sorted(lemma_trajectory_diff_list, key=lambda x: -x[1])\n",
    "    lemma_trajectory_dict = {l: d for l, d in lemma_trajectory_diff_list}\n",
    "    return lemma_trajectory_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_trajectory_183_184_185_dict = calculate_trajectory_dict_from_index(\n",
    "        word2vec_183_index,\n",
    "        word2vec_184_aligned_index,\n",
    "        word2vec_185_aligned_index,\n",
    "    )\n",
    "    print(\"len(lemma_trajectory_diff_dict_183_184_185)\", len(lemma_trajectory_183_184_185_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab5ed1-54c5-44f2-aeff-f24ca178d222",
   "metadata": {},
   "source": [
    "### DONE: calculate_relative_diff_from_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73940986-09cc-44e9-8790-b990f1341e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_diff_from_lemma(\n",
    "    index_a: Index,\n",
    "    index_b: Index,\n",
    "    lemma_occurrence_count_a_dict: LemmaOccurrenceCountDict,\n",
    "    lemma_occurrence_count_b_dict: LemmaOccurrenceCountDict,\n",
    "    lemma: Lemma,\n",
    ") -> float:\n",
    "    diff = None\n",
    "\n",
    "    # key and dict synchronization\n",
    "    distances_a_dict = query_related(index_a, lemma, n=10)\n",
    "    distances_b_dict = query_related(index_b, lemma, n=10)\n",
    "    embedding_index_a_lemma = query_generic(index_a, lemma)\n",
    "    embedding_index_b_lemma = query_generic(index_b, lemma)\n",
    "    if embedding_index_a_lemma is not None and embedding_index_b_lemma is not None:\n",
    "        distances_a_lemma_set = set(distances_a_dict.keys())\n",
    "        distances_b_lemma_set = set(distances_b_dict.keys())\n",
    "        lemma_all = set()\n",
    "        for lemma_a in distances_a_lemma_set:\n",
    "            is_in_both = True\n",
    "            if lemma_a not in distances_b_lemma_set:\n",
    "                embedding_index_b_lemma_a = query_generic(index_b, lemma_a)\n",
    "                if embedding_index_b_lemma_a is not None:\n",
    "                    distances_b_dict[lemma_a] = calculate_cos_distance(embedding_index_a_lemma, embedding_index_b_lemma_a)\n",
    "                else:\n",
    "                    is_in_both = False\n",
    "            if is_in_both:\n",
    "                lemma_all.add(lemma_a)\n",
    "        for lemma_b in distances_b_lemma_set:\n",
    "            is_in_both = True\n",
    "            if lemma_b not in distances_a_lemma_set:\n",
    "                embedding_index_a_lemma_b = query_generic(index_a, lemma_b)\n",
    "                if embedding_index_a_lemma_b is not None:\n",
    "                    distances_a_dict[lemma_b] = calculate_cos_distance(embedding_index_b_lemma, embedding_index_a_lemma_b)\n",
    "                else:\n",
    "                    is_in_both = False\n",
    "            if is_in_both:\n",
    "                lemma_all.add(lemma_b)\n",
    "\n",
    "        # difference calculation\n",
    "        diff = 0\n",
    "        for lemma_related in lemma_all:\n",
    "            distance_a = distances_a_dict[lemma_related]\n",
    "            distance_b = distances_b_dict[lemma_related]\n",
    "            diff += abs(distance_a - distance_b)\n",
    "        diff /= len(lemma_all)\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    for lemma in [\"d\", \"und\", \"gehen\", \"wohnen\", \"FÃ¼rst\"]:\n",
    "        print(\n",
    "            lemma,\n",
    "            calculate_relative_diff_from_lemma(\n",
    "                word2vec_183_index,\n",
    "                word2vec_184_index,\n",
    "                lemma_occurrence_count_183_dict,\n",
    "                lemma_occurrence_count_184_dict,\n",
    "                lemma,\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2902c5-a731-451d-887b-dd07f55929d3",
   "metadata": {},
   "source": [
    "### DONE: calculate_relative_diff_dict_from_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70615ba-1a79-407e-a9b6-52546bfddb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_diff_dict_from_index(\n",
    "    index_a: Index,\n",
    "    index_b: Index,\n",
    "    lemma_occurrence_count_a_dict: LemmaOccurrenceCountDict,\n",
    "    lemma_occurrence_count_b_dict: LemmaOccurrenceCountDict,\n",
    "    min_occurrence: int = None,\n",
    "    max_occurrence: int = None,\n",
    ") -> LemmaDiffDict:\n",
    "    print(\"calculate_relative_diff_dict_from_index: start\")\n",
    "    lemma_diff_dict = {}\n",
    "    lemma_common = get_common_keys(index_a[1], index_b[1])\n",
    "    for lemma in lemma_common:\n",
    "        count_a = lemma_occurrence_count_a_dict[lemma]\n",
    "        count_b = lemma_occurrence_count_b_dict[lemma]\n",
    "        if (min_occurrence is None or (count_a >= min_occurrence and count_b >= min_occurrence)) and (\n",
    "            max_occurrence is None or (count_a <= max_occurrence and count_b <= max_occurrence)\n",
    "        ):\n",
    "            diff = calculate_relative_diff_from_lemma(index_a, index_b, lemma_occurrence_count_a_dict, lemma_occurrence_count_b_dict, lemma)\n",
    "            # diff_list.append((lemma, diff))\n",
    "            lemma_diff_dict[lemma] = diff\n",
    "    # diff_list = sorted(diff_list, key=lambda x: -x[1])\n",
    "    # lemma_diff_dict = {lemma: diff for lemma, diff in diff_list}\n",
    "    lemma_diff_dict = sort_dict_by_value(lemma_diff_dict, desc=False)\n",
    "    print(\"create_diff_dict_from_index: len(lemma_diff_dict):\", len(lemma_diff_dict))\n",
    "    return lemma_diff_dict\n",
    "\n",
    "\n",
    "def create_relative_diff_dict_from_index_test():\n",
    "    lemma_diff_183_184_dict = calculate_relative_diff_dict_from_index(\n",
    "        word2vec_183_index,\n",
    "        word2vec_184_index,\n",
    "        lemma_occurrence_count_183_dict,\n",
    "        lemma_occurrence_count_184_dict,\n",
    "    )\n",
    "    lemma_diff_184_185_dict = calculate_relative_diff_dict_from_index(\n",
    "        word2vec_184_index,\n",
    "        word2vec_185_index,\n",
    "        lemma_occurrence_count_184_dict,\n",
    "        lemma_occurrence_count_185_dict,\n",
    "    )\n",
    "    return lemma_diff_183_184_dict, lemma_diff_184_185_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_relative_diff_183_184_dict, lemma_diff_184_185_dict = load_cache_or_run(create_relative_diff_dict_from_index_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19e538-e239-4a5c-95c4-d0aacdea5108",
   "metadata": {},
   "source": [
    "### normalize_lemma_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9749408-008f-4a06-bb7f-f579006fdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_diff_table(lemma_value_dict, enable_inversion=False):\n",
    "    print(\"normalize_lemma_value_dict: start\")\n",
    "    move = min(lemma_value_dict.values())\n",
    "    lemma_value_dict_normalized = {lemma: diff - move for lemma, diff in lemma_value_dict.items()}\n",
    "    scale = 2 / max(lemma_value_dict_normalized.values())\n",
    "    lemma_value_dict_normalized = {lemma: diff * scale for lemma, diff in lemma_value_dict_normalized.items()}\n",
    "    lemma_value_dict_normalized = {lemma: diff - 1 for lemma, diff in lemma_value_dict_normalized.items()}\n",
    "    if enable_inversion:\n",
    "        lemma_value_dict_normalized = {lemma: diff * -1 for lemma, diff in lemma_value_dict_normalized.items()}\n",
    "    print(\"normalize_lemma_value_dict: len(lemma_value_dict_normalized):\", len(lemma_value_dict_normalized))\n",
    "    return lemma_value_dict_normalized\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_cos_sim_183_184_normalized_dict = normalize_diff_table(lemma_cos_sim_183_184_dict)\n",
    "    lemma_trajectory_183_184_185_normalized_dict = normalize_diff_table(lemma_trajectory_183_184_185_dict)\n",
    "    lemma_relative_diff_183_184_normalized_dict = normalize_diff_table(lemma_relative_diff_183_184_dict, enable_inversion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b7feac-604b-4b5d-a8e7-623b68a88a36",
   "metadata": {},
   "source": [
    "### create_random_lemma_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1004eed-1fbe-4095-b392-f4ba28ddbebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_lemma_value_dict(lemma_value_dict, range_min=-1, range_max=1):\n",
    "    range_min *= 1000\n",
    "    range_max *= 1000\n",
    "    random_lemma_value_dict = {}\n",
    "    for lemma in lemma_value_dict.keys():\n",
    "        random_lemma_value_dict[lemma] = random.randint(range_min, range_max) / 1000\n",
    "    return random_lemma_value_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_random_cos_sim_dict = create_random_lemma_value_dict(lemma_relative_diff_183_184_normalized_dict)\n",
    "    lemma_random_trajectory_dict = create_random_lemma_value_dict(lemma_trajectory_183_184_185_normalized_dict)\n",
    "    random_relative_diff_dict = create_random_lemma_value_dict(lemma_relative_diff_183_184_normalized_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b538097-d3e0-41cd-8c42-0c5d1d5ec592",
   "metadata": {},
   "source": [
    "### create_lemma_diff_diff_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212a08a-70a9-4a6b-a397-caa0133b064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lemma_diff_diff_dicts(*lemma_value_dict_list):\n",
    "    print(\"create_lemma_diff_diff_dicts: start\")\n",
    "    lemma_value_dict_list\n",
    "    common_lemma = get_common_keys(*lemma_value_dict_list)\n",
    "    lemma_diff_dict = {}\n",
    "    for lemma in common_lemma:\n",
    "        l = len(lemma_value_dict_list)\n",
    "        for i_a in range(0, l):\n",
    "            for i_b in range(i_a + 1, l):\n",
    "                lemma_value_dict_a = lemma_value_dict_list[i_a]\n",
    "                lemma_value_dict_b = lemma_value_dict_list[i_b]\n",
    "                diff = lemma_diff_dict.get(lemma, 0)\n",
    "                diff += abs(lemma_value_dict_a[lemma] - lemma_value_dict_b[lemma])\n",
    "                lemma_diff_dict[lemma] = diff\n",
    "    lemma_diff_dict = sort_dict_by_value(lemma_diff_dict, desc=False)\n",
    "    diff_avg = sum(lemma_diff_dict.values()) / len(lemma_diff_dict)\n",
    "    diff_median = list(lemma_diff_dict.values())[int(len(lemma_diff_dict) / 2)]\n",
    "    print(\"create_lemma_diff_diff_dicts: avg_diff:\", diff_avg)\n",
    "    print(\"create_lemma_diff_diff_dicts: diff_median:\", diff_median)\n",
    "    return lemma_diff_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_diff_cos_sim_trajectory_183_185_dict = create_lemma_diff_diff_dicts(\n",
    "        lemma_cos_sim_183_184_normalized_dict,\n",
    "        lemma_trajectory_183_184_185_normalized_dict,\n",
    "    )\n",
    "    lemma_diff_cos_sim_relative_diff_183_185_dict = create_lemma_diff_diff_dicts(\n",
    "        lemma_cos_sim_183_184_normalized_dict,\n",
    "        lemma_relative_diff_183_184_normalized_dict,\n",
    "    )\n",
    "    lemma_diff_trajectory_relative_diff_183_185_dict = create_lemma_diff_diff_dicts(\n",
    "        lemma_trajectory_183_184_185_normalized_dict,\n",
    "        lemma_relative_diff_183_184_normalized_dict,\n",
    "    )\n",
    "    lemma_diff_random_cos_sim_trajectory_dict = create_lemma_diff_diff_dicts(\n",
    "        lemma_random_cos_sim_dict,\n",
    "        lemma_random_trajectory_dict,\n",
    "    )\n",
    "    random_diff_cos_sim_relative_diff_dict = create_lemma_diff_diff_dicts(\n",
    "        lemma_random_cos_sim_dict,\n",
    "        random_relative_diff_dict,\n",
    "    )\n",
    "    random_diff_trajectory_relative_diff_dict = create_lemma_diff_diff_dicts(\n",
    "        lemma_random_trajectory_dict,\n",
    "        random_relative_diff_dict,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9afa27-0ded-4d3a-b199-dd8a9b591cda",
   "metadata": {},
   "source": [
    "### merge_lemma_diff_diff_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841b416-2870-4277-918e-27aed216a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lemma_diff_diff_dict(lemma_diff_diff_dict, lemma_diff_dict_a, lemma_diff_dict_b):\n",
    "    print(\"merge_lemma_diff_diff_dict: start\")\n",
    "    lemma_diff_averaged_dict = {}\n",
    "    for lemma in lemma_diff_diff_dict.keys():\n",
    "        lemma_diff_averaged_dict[\"1:\" + lemma] = lemma_diff_dict_a[lemma]\n",
    "        lemma_diff_averaged_dict[\"2:\" + lemma] = lemma_diff_dict_b[lemma]\n",
    "    print(\"merge_lemma_diff_diff_dict: len(lemma_diff_averaged_dict):\", len(lemma_diff_averaged_dict))\n",
    "    return lemma_diff_averaged_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_cos_sim_trajectory_183_185_merged_dict = merge_lemma_diff_diff_dict(\n",
    "        lemma_diff_cos_sim_trajectory_183_185_dict,\n",
    "        lemma_cos_sim_183_184_normalized_dict,\n",
    "        lemma_trajectory_183_184_185_normalized_dict,\n",
    "    )\n",
    "    lemma_cos_sim_relative_diff_183_185_merged_dict = merge_lemma_diff_diff_dict(\n",
    "        lemma_diff_cos_sim_relative_diff_183_185_dict,\n",
    "        lemma_cos_sim_183_184_normalized_dict,\n",
    "        lemma_relative_diff_183_184_normalized_dict,\n",
    "    )\n",
    "    lemma_trajectory_relative_diff_183_185_merged_dict = merge_lemma_diff_diff_dict(\n",
    "        lemma_diff_trajectory_relative_diff_183_185_dict,\n",
    "        lemma_trajectory_183_184_185_normalized_dict,\n",
    "        lemma_relative_diff_183_184_normalized_dict,\n",
    "    )\n",
    "    lemma_merged_random_diff_dict = merge_lemma_diff_diff_dict(\n",
    "        lemma_diff_random_cos_sim_trajectory_dict,\n",
    "        lemma_random_cos_sim_dict,\n",
    "        lemma_random_trajectory_dict,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea1bdb-2d4d-4442-9f5a-9a4e047d7370",
   "metadata": {},
   "source": [
    "### calculate_average_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883eb57c-87af-4274-9144-42468a2d6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_diff(global_diff_dict):\n",
    "    decade_average_diff_dict = {}\n",
    "    for lemma, diff in global_diff_dict.items():\n",
    "        for decade, cos_sim in diff.items():\n",
    "            diff_per_decade_list = decade_average_diff_dict.get(decade, [])\n",
    "            diff_per_decade_list.append(cos_sim)\n",
    "            decade_average_diff_dict[decade] = diff_per_decade_list\n",
    "    decade_average_diff_dict_new = {}\n",
    "    for lemma, diff_per_decade_list in decade_average_diff_dict.items():\n",
    "        decade_average_diff_dict_new[lemma] = sum(diff_per_decade_list) / len(diff_per_decade_list)\n",
    "    decade_average_diff_dict = decade_average_diff_dict_new\n",
    "    return decade_average_diff_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73d210a-6f57-4f0e-97eb-5aae67d32ee4",
   "metadata": {},
   "source": [
    "## aggregate functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f87f77-eef2-4781-9e6b-59757058b48d",
   "metadata": {},
   "source": [
    "### create_decade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18c73b-06aa-4412-833a-fa1c912b0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decade_data(decade: Decade) -> DecadeData:\n",
    "    print(\"create_decade_data: start\")\n",
    "    word2vec_index = create_index_from_word2vec(decade)\n",
    "    lemma_occurrence_count_dict, lemma_occurrence_position_dict = create_occurrence_dicts(decade, word2vec_index)\n",
    "    lemma_occurrence_count_dict = sort_dict_by_value(lemma_occurrence_count_dict)\n",
    "    return [word2vec_index, None, None, lemma_occurrence_count_dict, lemma_occurrence_position_dict]\n",
    "\n",
    "\n",
    "def create_decade_data_test():\n",
    "    return create_decade_data(183), create_decade_data(184), create_decade_data(185)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_183_data, decade_184_data, decade_185_data = load_cache_or_run(create_decade_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799cc116-fc60-4bf6-aa08-166c09f34a30",
   "metadata": {},
   "source": [
    "### align_decade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed779808-07fa-407a-baab-9b93ecb4b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_decade_data(decade_a_data: DecadeData, decade_b_data: DecadeData) -> DecadeData:\n",
    "    print(\"align_decade_data: start\")\n",
    "    index_a = decade_a_data[0]\n",
    "    index_b = decade_b_data[0]\n",
    "    lemma_occurrence_count_a_dict = decade_a_data[3]\n",
    "    lemma_occurrence_count_b_dict = decade_b_data[3]\n",
    "    index_b = calculate_procrustes_alignment(index_a, index_b, lemma_occurrence_count_a_dict, lemma_occurrence_count_b_dict)\n",
    "    decade_b_data[0] = index_b\n",
    "    return decade_b_data\n",
    "\n",
    "\n",
    "def align_decade_data_test():\n",
    "    global decade_184_data\n",
    "    global decade_185_data\n",
    "    decade_184_data = align_decade_data(decade_183_data, decade_184_data)\n",
    "    decade_185_data = align_decade_data(decade_184_data, decade_185_data)\n",
    "    return decade_184_data, decade_185_data\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_184_data, decade_185_data = load_cache_or_run(align_decade_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4bfe5b-d655-4b3f-86b2-0c333c8b45e4",
   "metadata": {},
   "source": [
    "### preprocess_and_persist_decade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807bf63d-36db-4079-aa58-1caa2fbc991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_persist_decade_data(decade_list):\n",
    "\n",
    "    def does_exist(decade):\n",
    "        return os.path.exists(f\"{CACHE_FOLDER}preprocess_and_persist_decade_data__{decade}.pkl\")\n",
    "\n",
    "    print(\"preprocess_and_persist_decade_data: start: decade_list:\", decade_list)\n",
    "    decade = decade_list[0]\n",
    "    if not does_exist(decade):\n",
    "        decade_a_data = create_decade_data(decade)\n",
    "        pickle_save(decade_a_data, f\"preprocess_and_persist_decade_data__{decade_list[0]}\")\n",
    "    for decade in decade_list[1:]:\n",
    "        if not does_exist(decade):\n",
    "            decade_b_data = create_decade_data(decade)\n",
    "            decade_b_data = align_decade_data(decade_a_data, decade_b_data)\n",
    "            pickle_save(decade_b_data, f\"preprocess_and_persist_decade_data__{decade}\")\n",
    "            decade_a_data = decade_b_data\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_list = create_decades_list()\n",
    "    preprocess_and_persist_decade_data(decade_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b494a-4720-4248-9144-079f2b66a5fd",
   "metadata": {},
   "source": [
    "### load_persisted_decade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d73a3-cc43-4590-8cb0-b6c66f44f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_persisted_decade_data(decade):\n",
    "    return pickle_load(f\"preprocess_and_persist_decade_data__{decade}\")\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_184_data = load_persisted_decade_data(184)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120c77e-feeb-4d5e-bc14-0670c53e6117",
   "metadata": {},
   "source": [
    "### load_embeddings_from_persisted_decade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f5bfb-b307-48a3-9104-63486efe3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_from_persisted_decade_data(decade_list, lemma_list):\n",
    "    print(\"load_embeddings_from_persisted_decade_data: start\")\n",
    "    lemma_decade_embdding_list_tmp = []\n",
    "    for decade in decade_list:\n",
    "        decade_data = load_persisted_decade_data(decade)\n",
    "        for lemma in lemma_list:\n",
    "            index = decade_data[0]\n",
    "            embedding = query_generic(index, lemma)\n",
    "            if embedding is not None:\n",
    "                lemma_decade_embdding_list_tmp.append((lemma, decade, embedding))\n",
    "    lemma_decade_embdding_dict = {}\n",
    "    for lemma, decade, embedding in lemma_decade_embdding_list_tmp:\n",
    "        decade_dict = lemma_decade_embdding_dict.get(lemma, {})\n",
    "        decade_dict[decade] = embedding\n",
    "        lemma_decade_embdding_dict[lemma] = decade_dict\n",
    "    print(\"load_embeddings_from_persisted_decade_data: len(lemma_decade_embdding_dict):\", len(lemma_decade_embdding_dict))\n",
    "    return lemma_decade_embdding_dict\n",
    "\n",
    "\n",
    "def load_embeddings_from_persisted_decade_data_test():\n",
    "    lemma_decade_embdding_dict = load_embeddings_from_persisted_decade_data(decade_list, [\"d\", \"und\", \"gehen\", \"wohnen\", \"FÃ¼rst\"])\n",
    "    return lemma_decade_embdding_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_decade_embdding_dict = load_cache_or_run(load_embeddings_from_persisted_decade_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481350da-6136-476b-ac7a-16cfba9567bd",
   "metadata": {},
   "source": [
    "### average_decade_lemma_diff_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0fd2c6-e459-4237-82b2-b722ddd7d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_decade_lemma_diff_dict(decade_lemma_decade_dict: DecadeLemmaDiffDict, enable_avg=True) -> dict[Lemma, float]:\n",
    "    print(\"average_decade_lemma_diff_dict: start\")\n",
    "    lemma_diff_averaged_dict_tmp = {}\n",
    "    for decade, lemma_dict in decade_lemma_decade_dict.items():\n",
    "        for lemma, diff in lemma_dict.items():\n",
    "            diff_list = lemma_diff_averaged_dict_tmp.get(lemma, [])\n",
    "            diff_list.append(diff)\n",
    "            lemma_diff_averaged_dict_tmp[lemma] = diff_list\n",
    "    lemma_diff_averaged_dict = {}\n",
    "    for lemma, diff_list in lemma_diff_averaged_dict_tmp.items():\n",
    "        diff = sum(diff_list)\n",
    "        if enable_avg:\n",
    "            diff /= len(diff_list)\n",
    "        lemma_diff_averaged_dict[lemma] = diff\n",
    "    lemma_diff_averaged_dict = sort_dict_by_value(lemma_diff_averaged_dict)\n",
    "    print(\"average_decade_lemma_diff_dict: len(lemma_diff_averaged_dict):\", len(lemma_diff_averaged_dict))\n",
    "    return lemma_diff_averaged_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_decade_dict_test = {\n",
    "        183: {\n",
    "            \"gehen\": 0.2,\n",
    "            \"laufen\": 0.4,\n",
    "        },\n",
    "        184: {\n",
    "            \"gehen\": 0.3,\n",
    "            \"laufen\": 0.6,\n",
    "        },\n",
    "        185: {\n",
    "            \"gehen\": 0.1,\n",
    "            \"laufen\": 0.1,\n",
    "        },\n",
    "    }\n",
    "    print(average_decade_lemma_diff_dict(lemma_decade_dict_test))\n",
    "    print(average_decade_lemma_diff_dict(lemma_decade_dict_test, enable_avg=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a5fe8-d85b-4952-a646-09982a6136aa",
   "metadata": {},
   "source": [
    "### calculate_cos_sim_between_decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950900e-32de-42d9-903d-73483379e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_sim_between_decades(decade_list) -> DecadeLemmaDiffDict:\n",
    "    print(\"calculate_cos_sim_between_decades: start\")\n",
    "    decade_a = decade_list[0]\n",
    "    decade_a_data = load_persisted_decade_data(decade_a)\n",
    "    decade_lemma_cos_sim_dict = {}\n",
    "    for decade_b in decade_list[1:]:\n",
    "        decade_b_data = load_persisted_decade_data(decade_b)\n",
    "        lemma_cos_sim_dict = calculate_cos_sim_between_indices(decade_a_data[0], decade_b_data[0])\n",
    "        cos_sim_decade_str = str(decade_a) + \"-\" + str(decade_b)\n",
    "        decade_lemma_cos_sim_dict[cos_sim_decade_str] = lemma_cos_sim_dict\n",
    "        # lemma_occurrence_count_merged = merge_count_occurrences_dict(decade_a_data[3], decade_b_data[3])\n",
    "        # lemma_cos_sim_dict_filtered = {}\n",
    "        # for lemma, occurrence_count in lemma_occurrence_count_merged.items():\n",
    "        #     lemma_cos_sim_dict_filtered[lemma] = lemma_cos_sim_dict[lemma]\n",
    "        # lemma_cos_sim_dict = lemma_cos_sim_dict_filtered\n",
    "        # for lemma, cos_sim in lemma_cos_sim_dict.items():\n",
    "        #     decade_cos_sim_dict = decade_lemma_cos_sim_dict.get(lemma, {})\n",
    "        #     decade_cos_sim_dict[cos_sim_decade_str] = cos_sim\n",
    "        #     decade_lemma_cos_sim_dict[lemma] = decade_cos_sim_dict\n",
    "        decade_a_data = decade_b_data\n",
    "    print(\"calculate_cos_sim_between_decades: len(decade_lemma_cos_sim_dict):\", len(decade_lemma_cos_sim_dict))\n",
    "    return decade_lemma_cos_sim_dict\n",
    "\n",
    "\n",
    "def calculate_cos_sim_between_decades_test():\n",
    "    decade_lemma_cos_sim_dict = calculate_cos_sim_between_decades(decade_list)\n",
    "    lemma_cos_sim_averaged_dict = average_decade_lemma_diff_dict(decade_lemma_cos_sim_dict)\n",
    "    return decade_lemma_cos_sim_dict, lemma_cos_sim_averaged_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_lemma_cos_sim_dict, lemma_cos_sim_averaged_dict = load_cache_or_run(calculate_cos_sim_between_decades_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f259275-2e5c-4611-88d1-04ae82a21ffe",
   "metadata": {},
   "source": [
    "### calculate_trajectories_between_decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f6b65-5dec-4988-bcf0-f93bb0b7f9e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_trajectories_between_decades(decade_list: DecadeList) -> DecadeLemmaDiffDict:\n",
    "    print(\"calculate_trajectories_between_decades: start\")\n",
    "    decade_a = decade_list[0]\n",
    "    decade_a_data = load_persisted_decade_data(decade_list[0])\n",
    "    decade_b_data = load_persisted_decade_data(decade_list[1])\n",
    "    decade_lemma_trajectory_dict = {}\n",
    "    for decade_c in decade_list[2:]:\n",
    "        decade_data_c = load_persisted_decade_data(decade_c)\n",
    "        index_a = decade_a_data[0]\n",
    "        index_b = decade_b_data[0]\n",
    "        index_c = decade_data_c[0]\n",
    "        lemma_trajectory_dict_abc = calculate_trajectory_dict_from_index(index_a, index_b, index_c)\n",
    "        trajectory_decades_str = str(decade_a) + \"-\" + str(decade_data_c)\n",
    "        decade_lemma_trajectory_dict[trajectory_decades_str] = lemma_trajectory_dict_abc\n",
    "        # for lemma, trajectory in lemma_trajectory_dict_abc.items():\n",
    "        #     trajectory_lemma_dict = decade_lemma_trajectory_dict.get(lemma, {})\n",
    "        #     trajectory_decades_str = str(decade_a) + \"-\" + str(decade_data_c)\n",
    "        #     trajectory_lemma_dict[trajectory_decades_str] = trajectory\n",
    "        #     decade_lemma_trajectory_dict[lemma] = trajectory_lemma_dict\n",
    "        decade_a_data = decade_b_data\n",
    "        decade_b_data = decade_data_c\n",
    "    print(\"calculate_trajectories_between_decades: len(decade_lemma_trajectory_dict):\", len(decade_lemma_trajectory_dict))\n",
    "    return decade_lemma_trajectory_dict\n",
    "\n",
    "\n",
    "def calculate_trajectories_between_decades_test():\n",
    "    decade_list = create_decades_list()\n",
    "    decade_lemma_trajectory_dict = calculate_trajectories_between_decades(decade_list)\n",
    "    lemma_trajectory_averaged_dict = average_decade_lemma_diff_dict(decade_lemma_trajectory_dict)\n",
    "    return decade_lemma_trajectory_dict, lemma_trajectory_averaged_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_lemma_trajectory_dict, lemma_trajectory_averaged_dict = load_cache_or_run(calculate_trajectories_between_decades_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b72157-37fc-43ac-823d-b1f9f641b14f",
   "metadata": {},
   "source": [
    "### calculate_relative_diff_between_decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45613a-7893-48d5-9b88-69dcdcd3e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_diff_between_decades(decade_list: DecadeList) -> DecadeLemmaDiffDict:\n",
    "    print(\"calculate_relative_diff_between_decades: start\")\n",
    "    decade_a = decade_list[0]\n",
    "    decade_a_data = load_persisted_decade_data(decade_a)\n",
    "    decade_lemma_relative_diff_dict = {}\n",
    "    for decade_b in decade_list[1:]:\n",
    "        decade_b_data = load_persisted_decade_data(decade_b)\n",
    "        lemma_relative_diff_dict = calculate_relative_diff_dict_from_index(\n",
    "            decade_a_data[0],\n",
    "            decade_b_data[0],\n",
    "            decade_a_data[3],\n",
    "            decade_b_data[3],\n",
    "        )\n",
    "        decade_str = str(decade_a) + \"-\" + str(decade_b)\n",
    "        decade_lemma_relative_diff_dict[decade_str] = lemma_relative_diff_dict\n",
    "        # lemma_relative_diff_dict_merged = merge_count_occurrences_dict(decade_a_data[3], decade_b_data[3])\n",
    "        # lemma_relative_diff_dict_filtered = {}\n",
    "        # for lemma, occurrence_count in lemma_relative_diff_dict_merged.items():\n",
    "        #     lemma_relative_diff_dict_filtered[lemma] = lemma_relative_diff_dict[lemma]\n",
    "        # lemma_relative_diff_dict = lemma_relative_diff_dict_filtered\n",
    "        # for lemma, relative_diff in lemma_relative_diff_dict.items():\n",
    "        #     decade_relative_diff_dict = decade_lemma_relative_diff_dict.get(lemma, {})\n",
    "        #     decade_relative_diff_dict[decade_str] = relative_diff\n",
    "        #     decade_lemma_relative_diff_dict[lemma] = decade_relative_diff_dict\n",
    "        decade_a_data = decade_b_data\n",
    "    print(\"calculate_relative_diff_between_decades: len(decade_lemma_relative_diff_dict):\", len(decade_lemma_relative_diff_dict))\n",
    "    return decade_lemma_relative_diff_dict\n",
    "\n",
    "\n",
    "def calculate_relative_diff_between_decades_test():\n",
    "    decade_list = create_decades_list()\n",
    "    decade_lemma_relative_diff_dict = calculate_relative_diff_between_decades(decade_list)\n",
    "    lemma_relative_diff_averaged_dict = average_decade_lemma_diff_dict(decade_lemma_relative_diff_dict)\n",
    "    return decade_lemma_relative_diff_dict, lemma_relative_diff_averaged_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_lemma_relative_diff_dict, lemma_relative_diff_averaged_dict = load_cache_or_run(calculate_relative_diff_between_decades_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a5a39-3f03-4eed-8802-d8547e9706c2",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b000e-97eb-48c7-b884-807abf483fce",
   "metadata": {},
   "source": [
    "## prepare_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5abfbd-ac28-4fe5-8640-3cfe26706ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all():\n",
    "    decade_list = create_decades_list()\n",
    "    preprocess_and_persist_decade_data(decade_list)\n",
    "    decade_lemma_cos_sim_dict = calculate_cos_sim_between_decades(decade_list)\n",
    "    lemma_cos_sim_averaged_dict = average_decade_lemma_diff_dict(decade_lemma_cos_sim_dict)\n",
    "    decade_lemma_trajectory_dict = calculate_trajectories_between_decades(decade_list)\n",
    "    lemma_trajectory_averaged_dict = average_decade_lemma_diff_dict(decade_lemma_trajectory_dict)\n",
    "    decade_lemma_relative_diff_dict = calculate_relative_diff_between_decades(decade_list)\n",
    "    lemma_relative_diff_averaged_dict = average_decade_lemma_diff_dict(decade_lemma_relative_diff_dict)\n",
    "    return (\n",
    "        decade_list,\n",
    "        decade_lemma_cos_sim_dict,\n",
    "        lemma_cos_sim_averaged_dict,\n",
    "        decade_lemma_trajectory_dict,\n",
    "        lemma_trajectory_averaged_dict,\n",
    "        decade_lemma_relative_diff_dict,\n",
    "        lemma_relative_diff_averaged_dict,\n",
    "    )\n",
    "\n",
    "\n",
    "(\n",
    "    decade_list,\n",
    "    decade_lemma_cos_sim_dict,\n",
    "    lemma_cos_sim_averaged_dict,\n",
    "    decade_lemma_trajectory_dict,\n",
    "    lemma_trajectory_averaged_dict,\n",
    "    decade_lemma_relative_diff_dict,\n",
    "    lemma_relative_diff_averaged_dict,\n",
    ") = load_cache_or_run(prepare_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d8dd1-f18c-4d7a-b710-ed3cbd1dd709",
   "metadata": {},
   "source": [
    "## global changes analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a4ee1-9dcb-4add-b0b5-593841e0d325",
   "metadata": {},
   "source": [
    "### global cosine similarity changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa27b2-8a30-4a14-bcbf-307bbcb61066",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_scatter(lemma_cos_sim_averaged_dict, \"global average change between decades regarding cosine similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77acda-de6e-4c2f-ba6f-d16a8a1b05d6",
   "metadata": {},
   "source": [
    "### global trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939ac9c-30c5-44e6-b798-a3c837c9767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_scatter(lemma_trajectory_averaged_dict, \"global average change between decades regarding trajectory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291e935-db06-4acb-a15d-8fd70fc149f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_scatter(lemma_relative_diff_averaged_dict, \"global average change between decades regarding relative differences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251a4a6-9485-423e-98e7-209cefc94da3",
   "metadata": {},
   "source": [
    "### filter_on_decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26748a-75ff-4e61-8ee7-b3982c9970e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_decades(decade_lemma_diff_dict, num_decades=2):\n",
    "    lemma_decade_count_dict = {}\n",
    "    for decade, lemma_diff_dict in decade_lemma_diff_dict.items():\n",
    "        for lemma in lemma_diff_dict.keys():\n",
    "            decade_count = lemma_decade_count_dict.get(lemma, 0)\n",
    "            lemma_decade_count_dict[lemma] = decade_count + 1\n",
    "    lemma_set = set()\n",
    "    for lemma, decade_count in lemma_decade_count_dict.items():\n",
    "        if decade_count >= num_decades:\n",
    "            lemma_set.add(lemma)\n",
    "    decade_lemma_dict_filtered = {}\n",
    "    for decade, lemma_diff_dict in decade_lemma_diff_dict.items():\n",
    "        lemma_diff_dict_new = {}\n",
    "        for lemma, diff in lemma_diff_dict.items():\n",
    "            if lemma in lemma_set:\n",
    "                lemma_diff_dict_new[lemma] = diff\n",
    "        decade_lemma_dict_filtered[decade] = lemma_diff_dict_new\n",
    "    return decade_lemma_dict_filtered\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_lemma_dict_filtered = filter_on_decades(\n",
    "        {\n",
    "            180: {\n",
    "                \"gehen\": 1,\n",
    "                \"laufen\": 1,\n",
    "                \"Haus\": 1,\n",
    "            },\n",
    "            181: {\n",
    "                \"gehen\": 1,\n",
    "                \"wandern\": 1,\n",
    "            },\n",
    "            182: {\n",
    "                \"gehen\": 1,\n",
    "                \"wandern\": 1,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    print(decade_lemma_dict_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed077e-98dd-46d5-9a01-149cf41d0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_lemma_cos_sim_filtered_dict = filter_on_decades(decade_lemma_cos_sim_dict)\n",
    "decade_lemma_cos_sim_filtered_merged_dict = average_decade_lemma_diff_dict(decade_lemma_cos_sim_filtered_dict)\n",
    "plot_2d_scatter(decade_lemma_cos_sim_filtered_merged_dict, \"global filtered average change between decades regarding cosine similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2d811-b089-400f-a21b-70d1b3842be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_lemma_trajectory_dict_filtered = filter_on_decades(decade_lemma_trajectory_dict)\n",
    "decade_lemma_trajectory_dict_filtered_merged = average_decade_lemma_diff_dict(decade_lemma_trajectory_dict_filtered)\n",
    "plot_2d_scatter(decade_lemma_trajectory_dict_filtered_merged, \"global filtered average change between decades regarding trajectory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619649b1-9e5e-477d-aeb4-7d89c6a5bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_lemma_relative_diff_dict_filtered = filter_on_decades(decade_lemma_relative_diff_dict, num_decades=3)\n",
    "decade_lemma_relative_diff_dict_filtered_merged = average_decade_lemma_diff_dict(decade_lemma_relative_diff_dict_filtered)\n",
    "plot_2d_scatter(\n",
    "    decade_lemma_relative_diff_dict_filtered_merged, \"global filtered average change between decades regarding relative differences\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495a29b-e701-4e16-b6e5-d8d7d21ec670",
   "metadata": {},
   "source": [
    "### compare cos sim and trajectories differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b4630-e8c7-46dc-8fd2-8956afd69dd9",
   "metadata": {},
   "source": [
    "### normalize global diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c191c-8ff4-4e3e-8085-c47164c2e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_lemma_cos_sim_filtered_merged_dict_normalized = normalize_diff_table(decade_lemma_cos_sim_filtered_merged_dict)\n",
    "plot_2d_scatter(\n",
    "    decade_lemma_cos_sim_filtered_merged_dict_normalized,\n",
    "    \"global normalized filtered average change between decades regarding cosine similarity\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1965759-84ed-4091-82d7-d68a1a4afef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_lemma_trajectory_dict_filtered_merged_normalized = normalize_diff_table(decade_lemma_trajectory_dict_filtered_merged)\n",
    "plot_2d_scatter(\n",
    "    decade_lemma_trajectory_dict_filtered_merged_normalized,\n",
    "    \"global normalized filtered average change between decades regarding trajectory\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986a1e2-635f-41ab-b75a-cd68197fb411",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_lemma_relative_diff_dict_filtered_merged_normalized = normalize_diff_table(\n",
    "    decade_lemma_relative_diff_dict_filtered_merged,\n",
    "    enable_inversion=True,\n",
    ")\n",
    "plot_2d_scatter(\n",
    "    decade_lemma_relative_diff_dict_filtered_merged_normalized,\n",
    "    \"global normalized filtered average change between decades regarding trajectory\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b3a63-3bf0-44c0-a529-be755eaaed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_lemma_diffs_compared = create_lemma_diff_diff_dicts(\n",
    "    decade_lemma_cos_sim_filtered_merged_dict_normalized, decade_lemma_trajectory_dict_filtered_merged_normalized\n",
    ")\n",
    "plot_2d_scatter(decade_lemma_diffs_compared, \"difference between normalized cos sim and trajectories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8045b8d-a5d7-4f44-9e38-5b828b5124ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_lemma_diffs_compared_merged = merge_lemma_diff_diff_dict(\n",
    "    decade_lemma_diffs_compared,\n",
    "    decade_lemma_cos_sim_filtered_merged_dict_normalized,\n",
    "    decade_lemma_trajectory_dict_filtered_merged_normalized,\n",
    ")\n",
    "plot_2d_scatter(decade_lemma_diffs_compared_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694d7de-bd4d-42b2-b47c-30ca97761b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dict_a = create_random_lemma_value_dict(decade_lemma_cos_sim_filtered_merged_dict_normalized)\n",
    "random_dict_b = create_random_lemma_value_dict(decade_lemma_trajectory_dict_filtered_merged_normalized)\n",
    "random_lemma_diff_diff_dict = create_lemma_diff_diff_dicts(random_dict_a, random_dict_b)\n",
    "decade_lemma_diffs_compared_merged_random = merge_lemma_diff_diff_dict(random_lemma_diff_diff_dict, random_dict_a, random_dict_b)\n",
    "plot_2d_scatter(decade_lemma_diffs_compared_merged_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6adc114-536f-45d2-a87c-b71a93334224",
   "metadata": {},
   "source": [
    "### compare cos sim and relative diff differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ad1e8-4d46-4509-b702-242d6b17dfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4424c204-4b50-4123-95f7-78ccaded7af8",
   "metadata": {},
   "source": [
    "### average differences per decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c6df1-b4a1-4433-9792-a2df33d80808",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cos_sim_per_decade_dict = calculate_average_diff(decade_lemma_cos_sim_dict)\n",
    "plot_2d_scatter(average_cos_sim_per_decade_dict, draw_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31281295-5c3e-4837-bd29-7b8341feca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_trajectory_per_decade_dict = calculate_average_diff(decade_lemma_trajectory_dict)\n",
    "plot_2d_scatter(average_trajectory_per_decade_dict, draw_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05cb213-3124-4fa4-96de-da0f21f61f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_relative_diff_per_decade_dict = calculate_average_diff(decade_lemma_relative_diff_dict)\n",
    "plot_2d_scatter(average_relative_diff_per_decade_dict, draw_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0a174-a32f-41d1-b1c3-39af728f617f",
   "metadata": {},
   "source": [
    "## sample analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c4841-c1b1-46a8-b348-a17605d5dafd",
   "metadata": {},
   "source": [
    "### get_lemma_by_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45440e2-4ae4-41d1-a03e-20f52d8ad29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_by_position(lemma_dict, index_start=0, n=10, direction_forward=True, index_start_is_percent=False):\n",
    "    lemma_dict_selected = {}\n",
    "    key_value_list = []\n",
    "    if direction_forward:\n",
    "        for key, value in lemma_dict.items():\n",
    "            if is_word(key):\n",
    "                key_value_list.append((key, value))\n",
    "    else:\n",
    "        for key, value in list(lemma_dict.items())[::-1]:\n",
    "            if is_word(key):\n",
    "                key_value_list.append((key, value))\n",
    "    if index_start_is_percent:\n",
    "        index_start = int((len(key_value_list) / 100) * index_start)\n",
    "    index_end = index_start + n\n",
    "    for i, (key, value) in enumerate(key_value_list):\n",
    "        if index_start <= i:\n",
    "            if i < index_end:\n",
    "                lemma_dict_selected[key] = value\n",
    "            else:\n",
    "                break\n",
    "    return lemma_dict_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d30c3-54ce-4961-91a5-ce74f456b95b",
   "metadata": {},
   "source": [
    "### sample_and_plot_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77a9b6-b8c9-4e9e-986e-20802c99fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_plot_lemmas(\n",
    "    decade_lemma_cos_sim_dict,\n",
    "    lemma_cos_sim_averaged_dict,\n",
    "    decade_lemma_trajectory_dict,\n",
    "    lemma_trajectory_averaged_dict,\n",
    "    decade_lemma_relative_diff_dict,\n",
    "    lemma_relative_diff_averaged_dict,\n",
    "    index_start,\n",
    "    n=10,\n",
    "    direction_forward=True,\n",
    "    index_start_is_percent=False,\n",
    "    plot_limit=3,\n",
    "):\n",
    "\n",
    "    def sample_and_plot_lemmas_internal(\n",
    "        decade_lemma_diff_dict,\n",
    "        lemma_diff_averaged_dict,\n",
    "        title,\n",
    "    ):\n",
    "        lemma_diff_sampled_dict = get_lemma_by_position(\n",
    "            lemma_diff_averaged_dict,\n",
    "            index_start=index_start,\n",
    "            n=n,\n",
    "            direction_forward=direction_forward,\n",
    "            index_start_is_percent=index_start_is_percent,\n",
    "        )\n",
    "        print(lemma_diff_sampled_dict)\n",
    "        lemma_diff_list_sampled = list(lemma_diff_sampled_dict.keys())[:plot_limit]\n",
    "        for lemma in lemma_diff_list_sampled:\n",
    "            decade_diff_dict = {}\n",
    "            for decade, lemma_diff_dict in decade_lemma_diff_dict.items():\n",
    "                diff = lemma_diff_dict.get(lemma)\n",
    "                if diff is not None:\n",
    "                    decade_diff_dict[decade] = diff\n",
    "            plot_2d_scatter(decade_diff_dict, draw_line=True, title=title + \": \" + lemma)\n",
    "        return lemma_diff_list_sampled\n",
    "\n",
    "    lemma_diff_list_sampled = sample_and_plot_lemmas_internal(decade_lemma_cos_sim_dict, lemma_cos_sim_averaged_dict, \"cosine similarity\")\n",
    "    lemma_diff_list_sampled += sample_and_plot_lemmas_internal(decade_lemma_trajectory_dict, lemma_trajectory_averaged_dict, \"trajectory\")\n",
    "    lemma_diff_list_sampled += sample_and_plot_lemmas_internal(decade_relative_diff_dict, lemma_relative_diff_averaged_dict, \"trajectory\")\n",
    "    lemma_diff_list_sampled = list(set(lemma_diff_list_sampled))\n",
    "    plot_lemma_and_decade_from_lemma_list(lemma_diff_list_sampled, \"embeddings samples regarding cosine similarity and trajectory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f0329-26c8-4f0d-96b0-620067cb2e4c",
   "metadata": {},
   "source": [
    "### top lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5f9bc-daad-4929-bbbc-ef63754c9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_and_plot_lemmas(\n",
    "    decade_lemma_cos_sim_dict,\n",
    "    decade_lemma_cos_sim_filtered_merged_dict,\n",
    "    decade_lemma_trajectory_dict,\n",
    "    decade_lemma_trajectory_dict_filtered_merged,\n",
    "    decade_lemma_relative_diff_dict,\n",
    "    lemma_relative_diff_averaged_dict,\n",
    "    index_start=0,\n",
    "    n=10,\n",
    "    plot_limit=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473b961-2181-4657-9194-6353a1e23b79",
   "metadata": {},
   "source": [
    "### middle lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d998f-2bb2-4472-91c0-100f264bf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_and_plot_lemmas(\n",
    "    decade_lemma_cos_sim_dict,\n",
    "    decade_lemma_cos_sim_filtered_merged_dict,\n",
    "    decade_lemma_trajectory_dict,\n",
    "    decade_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=50,\n",
    "    n=10,\n",
    "    plot_limit=3,\n",
    "    index_start_is_percent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45023571-43d7-4179-a6dc-a57c2d71b298",
   "metadata": {},
   "source": [
    "### bottom lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4607e02-df59-412e-8f96-f323c1656fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_and_plot_lemmas(\n",
    "    decade_lemma_cos_sim_dict,\n",
    "    decade_lemma_cos_sim_filtered_merged_dict,\n",
    "    decade_lemma_trajectory_dict,\n",
    "    decade_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=0,\n",
    "    n=10,\n",
    "    plot_limit=3,\n",
    "    direction_forward=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54933c79-1604-41a9-9027-3eaa578af406",
   "metadata": {},
   "source": [
    "### together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbca0cd-2747-4bf6-aeb5-be6899241e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top\n",
    "global_top_cos_sim = sample_diff_dict = get_lemma_by_position(\n",
    "    decade_lemma_cos_sim_filtered_merged_dict,\n",
    "    index_start=0,\n",
    "    n=2,\n",
    ")\n",
    "global_top_cos_sim = list(global_top_cos_sim.keys())\n",
    "\n",
    "# middle\n",
    "global_middle_cos_sim = sample_diff_dict = get_lemma_by_position(\n",
    "    decade_lemma_cos_sim_filtered_merged_dict,\n",
    "    index_start=50,\n",
    "    n=2,\n",
    "    index_start_is_percent=True,\n",
    ")\n",
    "global_middle_cos_sim = list(global_middle_cos_sim.keys())\n",
    "\n",
    "# bottom\n",
    "global_bottom_cos_sim = sample_diff_dict = get_lemma_by_position(\n",
    "    decade_lemma_cos_sim_filtered_merged_dict,\n",
    "    index_start=0,\n",
    "    n=2,\n",
    "    direction_forward=False,\n",
    ")\n",
    "global_bottom_cos_sim = list(global_bottom_cos_sim.keys())\n",
    "\n",
    "# together\n",
    "global_together_cos_sim = global_top_cos_sim + global_middle_cos_sim + global_bottom_cos_sim\n",
    "plot_lemma_and_decade_from_lemma_list(global_together_cos_sim, \"sampled via cosine similarity: \" + str(global_together_cos_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c673c-6425-4e06-b787-baf0f3ca2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top\n",
    "global_top_trajectory = sample_diff_dict = get_lemma_by_position(\n",
    "    decade_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=0,\n",
    "    n=2,\n",
    ")\n",
    "global_top_trajectory = list(global_top_trajectory.keys())\n",
    "\n",
    "# middle\n",
    "global_middle_trajectory = sample_diff_dict = get_lemma_by_position(\n",
    "    decade_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=50,\n",
    "    n=2,\n",
    "    index_start_is_percent=True,\n",
    ")\n",
    "global_middle_trajectory = list(global_middle_trajectory.keys())\n",
    "\n",
    "# bottom\n",
    "global_bottom_trajectory = sample_diff_dict = get_lemma_by_position(\n",
    "    decade_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=0,\n",
    "    n=2,\n",
    "    direction_forward=False,\n",
    ")\n",
    "global_bottom_trajectory = list(global_bottom_trajectory.keys())\n",
    "\n",
    "# together\n",
    "global_together_trajectory = global_top_trajectory + global_middle_trajectory + global_bottom_trajectory\n",
    "plot_lemma_and_decade_from_lemma_list(global_together_trajectory, \"sampled via trajectory: \" + str(global_together_trajectory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c607e5-cdd9-48c3-bf97-fd0d6444fae9",
   "metadata": {},
   "source": [
    "# DB Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e05fb-0151-4114-9713-16364b31f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd199dee-3882-447b-aac6-cebf10a2500b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
