{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a2e1c5-aa05-466b-be11-b422da4f7c25",
   "metadata": {},
   "source": [
    "# modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b395f2c-139d-4563-9eee-492057582cb8",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535e21a-6c2f-44d9-aa28-faa91de14ad7",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1d90b-4a93-4b63-b22d-a20fa107c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "from typing import TypeAlias\n",
    "\n",
    "import hnswlib\n",
    "import hunspell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import psycopg\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from joblib import Memory\n",
    "from pgvector.psycopg import register_vector\n",
    "from psycopg.sql import SQL, Identifier, Placeholder\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d4d4c-74af-408e-90e7-431639f319d9",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f6dec-d63a-4c18-8806-59186587fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = True\n",
    "RESET_DB = False\n",
    "\n",
    "MODELS_WORD2VEC_FOLDER = \"/veld/input/models/word2vec/\"\n",
    "MODELS_FASTTEXT_FOLDER = \"/veld/input/models/fasttext/\"\n",
    "MODELS_GLOVE_FOLDER = \"/veld/input/models/glove/\"\n",
    "TEXTS_FOLDER = \"/veld/input/texts/\"\n",
    "CACHE_FOLDER = \"/veld/storage/cache/\"\n",
    "\n",
    "INDEX_EF_CONSTRUCTION = 100\n",
    "INDEX_M = 16\n",
    "\n",
    "USABLE_DECADES = [156, 191]\n",
    "\n",
    "PLOT_SLEEP = 2\n",
    "\n",
    "DB_NAME = \"postgres_db\"\n",
    "DB_USER = \"postgres_user\"\n",
    "DB_PASSWORD = \"postgres_password\"\n",
    "DB_HOST = \"veld_step_7_run_embeddings_sql_server\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "COLS_EMBEDDING = [\"lemma\", \"occurrence_count\", \"embedding\"]\n",
    "COLS_DIFF = [\"lemma\", \"occurrence_count\", \"diff\"]\n",
    "\n",
    "TEST_LEMMA_RANGED_LIST = sorted([\"d\", \"und\", \"gehen\", \"wohnen\", \"FÃ¼rst\"], key=str.lower)\n",
    "TEST_LEMMA_CLOSE_LIST = sorted([\"gehen\", \"laufen\", \"wandern\", \"wohnen\", \"trinken\"], key=str.lower)\n",
    "\n",
    "memory = Memory(location=\"/veld/storage/cache/\", verbose=0)\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "hunspell_check = hunspell.HunSpell(\"/usr/share/hunspell/de_DE.dic\", \"/usr/share/hunspell/de_DE.aff\")\n",
    "random.seed(42)\n",
    "pio.renderers.default = \"iframe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e02a5-9c4c-49c9-a2a3-260a790b2496",
   "metadata": {},
   "source": [
    "## helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520512ab-dc8f-44cc-adf0-ddc4dcf8e5cd",
   "metadata": {},
   "source": [
    "### is_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243c2ea-3957-459e-8f14-c71742bef448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word(word):\n",
    "    try:\n",
    "        _ = int(word)\n",
    "    except:\n",
    "        if len(word) == 1 and word != \"d\":\n",
    "            return False\n",
    "        else:\n",
    "            return hunspell_check.spell(word)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58044656-cc17-4f9f-8959-2697f02436ee",
   "metadata": {},
   "source": [
    "### create_decades_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc419e9c-6232-421a-9863-fe087ed40e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decades_list(decade_start: int = USABLE_DECADES[0], decade_end: int = USABLE_DECADES[1]):\n",
    "    return [d for d in range(decade_start, decade_end + 1)]\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_list_test = create_decades_list(183, 187)\n",
    "    print(decade_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744e237-c5e4-4e89-aa23-97bc1c9fedb8",
   "metadata": {},
   "source": [
    "### create_occurrence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cce9fe-b5c7-46f9-af1e-249438285932",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def create_occurrence_dict(decade) -> dict:\n",
    "    print(\"create_occurrence_dicts: start: decade:\", decade)\n",
    "    # lemma_occurrence_position_dict = {}\n",
    "    lemma_occurrence_count_dict = {}\n",
    "    total_occurrence_count = 0\n",
    "    with open(TEXTS_FOLDER + str(decade) + \".txt\", \"r\") as f:\n",
    "        for line_number, line in enumerate(f):\n",
    "            for lemma_number, lemma in enumerate(line.rstrip(\"\\n\").split()):\n",
    "                occurrence_count = lemma_occurrence_count_dict.get(lemma, 0)\n",
    "                lemma_occurrence_count_dict[lemma] = occurrence_count + 1\n",
    "                total_occurrence_count += 1\n",
    "    lemma_count = len(lemma_occurrence_count_dict)\n",
    "    occurrence_avg = total_occurrence_count / lemma_count\n",
    "    median_pos = int(lemma_count / 2)\n",
    "    occurrence_median = list(lemma_occurrence_count_dict.values())[median_pos]\n",
    "    print(\"create_occurrence_dicts: uniqe lemma_count:\", lemma_count)\n",
    "    print(\"create_occurrence_dicts: total_occurrence_count:\", total_occurrence_count)\n",
    "    print(\"create_occurrence_dicts: occurrence_avg:\", occurrence_avg)\n",
    "    print(\"create_occurrence_dicts: occurrence_median:\", occurrence_median)\n",
    "    return lemma_occurrence_count_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    decade_lemma_occurrence_count_dict = {}\n",
    "    for decade in decade_list_test:\n",
    "        decade_lemma_occurrence_count_dict[decade] = create_occurrence_dict(decade)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783db00-dc44-4555-9e16-67d9b770d9b6",
   "metadata": {},
   "source": [
    "### sort_dict_by_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8158cc-2e60-4f21-9afe-58f87b23d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict_by_value(key_value_dict: dict, desc=True) -> dict:\n",
    "    if desc:\n",
    "        sort_mod = -1\n",
    "    else:\n",
    "        sort_mod = 1\n",
    "    return dict(sorted(key_value_dict.items(), key=lambda x: sort_mod * x[1]))\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    print(\n",
    "        sort_dict_by_value(\n",
    "            {\n",
    "                \"x\": 3,\n",
    "                \"y\": 2,\n",
    "                \"z\": 4,\n",
    "            },\n",
    "            desc=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acd79d-0484-47d3-984c-718bc0b8e307",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e523ce57-2502-4fcc-bd36-6bbd87d369a3",
   "metadata": {},
   "source": [
    "### plot_tsne_from_labels_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7e74a-c798-48c8-850c-e61abea2fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_from_labels_embeddings(\n",
    "    label_embedding_list: list[str, np.array],\n",
    "    title: str = None,\n",
    "    height: int = None,\n",
    "    width: int = None,\n",
    "    rotation_degree: int = None,\n",
    "    perplexity: int = None,\n",
    "):\n",
    "    labels = []\n",
    "    embeddings = []\n",
    "    for l, e in label_embedding_list:\n",
    "        labels.append(l)\n",
    "        embeddings.append(e)\n",
    "    reduced_vectors_tsne = calculate_tsne(embeddings, perplexity)\n",
    "\n",
    "    if rotation_degree:\n",
    "        angle_rad = np.deg2rad(-rotation_degree)\n",
    "        rotation_matrix = np.array([[np.cos(angle_rad), -np.sin(angle_rad)], [np.sin(angle_rad), np.cos(angle_rad)]])\n",
    "        reduced_vectors_tsne = reduced_vectors_tsne @ rotation_matrix.T\n",
    "\n",
    "    if height is None:\n",
    "        height = 800\n",
    "    if width is None:\n",
    "        width = 800\n",
    "    time.sleep(PLOT_SLEEP)\n",
    "    fig = px.scatter(\n",
    "        x=reduced_vectors_tsne[:, 0],\n",
    "        y=reduced_vectors_tsne[:, 1],\n",
    "        text=labels,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        title=title,\n",
    "    )\n",
    "    fig.update_layout(xaxis=dict(title=None, showticklabels=False), yaxis=dict(title=None, showticklabels=False))\n",
    "    fig.update_traces(\n",
    "        marker=dict(size=10),\n",
    "        textposition=\"bottom center\",\n",
    "        textfont=dict(size=12),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# if TEST:\n",
    "#     plot_tsne_from_labels_embeddings(query_generic(\"word2vec__185\", lemma_list=[\"gehen\", \"laufen\", \"essen\", \"Haus\", \"Philosophie\"], select_cols=[\"lemma\", \"embedding\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef5750-3378-4d81-a89a-4c0b38c16339",
   "metadata": {},
   "source": [
    "### plot_tsne_from_lemma_and_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ab989-c2ac-499d-99f1-de8a7302c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_from_lemma_and_related(\n",
    "    table_name,\n",
    "    lemma: str = None,\n",
    "    n: int = 100,\n",
    "    title: str = None,\n",
    "    height: int = None,\n",
    "    width: int = None,\n",
    "    rotation_degree: int = None,\n",
    "):\n",
    "    plot_tsne_from_labels_embeddings(query_related(table_name, lemma, select_cols=[\"lemma\", \"embedding\"], n=n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5f43a-bf3e-428d-88bd-09ec9b0b7926",
   "metadata": {},
   "source": [
    "### plot_2d_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94128bff-5d4e-471e-b65f-37ad50dba3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_scatter(data: dict | list[list], title: str = None, draw_line=False, show_x_labels=True, xaxis_range=None, yaxis_range=None):\n",
    "    time.sleep(PLOT_SLEEP)\n",
    "    key_list = []\n",
    "    value_list = []\n",
    "    if type(data) is dict:\n",
    "        for key, value in data.items():\n",
    "            key_list.append(key)\n",
    "            value_list.append(value)\n",
    "    else:\n",
    "        for key, value in data:\n",
    "            key_list.append(key)\n",
    "            value_list.append(value)\n",
    "    fig = px.scatter(x=key_list, y=value_list, title=title)\n",
    "    if draw_line:\n",
    "        fig.update_traces(mode=\"lines+markers\")\n",
    "    fig.update_layout(xaxis_title=None, yaxis_title=None)\n",
    "    if not show_x_labels:\n",
    "        fig.update_xaxes(showticklabels=False)\n",
    "    if xaxis_range:\n",
    "        fig.update_layout(xaxis_range=xaxis_range)\n",
    "    if yaxis_range:\n",
    "        fig.update_layout(yaxis_range=yaxis_range)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc937ba-b834-44be-8a84-08b1ccb8472b",
   "metadata": {},
   "source": [
    "### plot_merged_diff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46991e-d174-4ace-a3fc-22f1e5f933e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_merged_diff_table(merged_diff_table):\n",
    "    data = []\n",
    "    for merged_diff in merged_diff_table:\n",
    "        data.append((\"A:\" + merged_diff[0], merged_diff[1]))\n",
    "        data.append((\"B:\" + merged_diff[0], merged_diff[2]))\n",
    "    plot_2d_scatter(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe0722-f900-4c39-ae9e-66ef7bdc11d3",
   "metadata": {},
   "source": [
    "### plot_lemma_and_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0cf9f-79c9-43a8-a3cd-b1218e3aabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lemma_and_decade(decade_list, lemma_list, perplexity=None, title=None):\n",
    "    time.sleep(PLOT_SLEEP)\n",
    "\n",
    "    # prepare data\n",
    "    global_labels_list = []\n",
    "    global_embeddings_list = []\n",
    "    group_end_position_list = []\n",
    "    position_count = 0\n",
    "    lemma_decade_embdding = {}\n",
    "    for decade, lemma, embedding in query_lemma_over_decades(decade_list, lemma_list, print_query=False):\n",
    "        decade_embedding_dict = lemma_decade_embdding.get(lemma, {})\n",
    "        decade_embedding_dict[decade] = embedding\n",
    "        lemma_decade_embdding[lemma] = decade_embedding_dict\n",
    "    for lemma, decade_embedding_dict in lemma_decade_embdding.items():\n",
    "        for decade, embedding in decade_embedding_dict.items():\n",
    "            global_labels_list.append(str(decade) + \":\" + lemma)\n",
    "            global_embeddings_list.append(embedding)\n",
    "            position_count += 1\n",
    "        group_end_position_list.append(position_count)\n",
    "    if 1 < len(global_embeddings_list) < 6:\n",
    "        perplexity = len(global_embeddings_list) - 1\n",
    "    else:\n",
    "        perplexity = None\n",
    "    lemma_embeddings_reduced_array = calculate_tsne(global_embeddings_list, perplexity=perplexity)\n",
    "\n",
    "    # create plot\n",
    "    fig = go.Figure()\n",
    "    group_start_position = 0\n",
    "    for group_end_position in group_end_position_list:\n",
    "        lemma_respective_embeddings = lemma_embeddings_reduced_array[group_start_position:group_end_position]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=lemma_respective_embeddings[:, 0],\n",
    "                y=lemma_respective_embeddings[:, 1],\n",
    "                mode=\"lines\",\n",
    "            )\n",
    "        )\n",
    "        group_start_position = group_end_position\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=lemma_embeddings_reduced_array[:, 0],\n",
    "            y=lemma_embeddings_reduced_array[:, 1],\n",
    "            mode=\"markers+text\",\n",
    "            text=global_labels_list,\n",
    "            textposition=\"top center\",\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=title if title is not None else \"\",\n",
    "        showlegend=False,\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# if TEST:\n",
    "#     plot_lemma_and_decade(decade_list_test, [\"Haus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb2c202-29f3-4182-b859-0c9f43a7854b",
   "metadata": {},
   "source": [
    "### plot_average_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b045e-ed98-4523-9849-3cbd48a4404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_diff(decade_list, avg_diff_table, order_desc=True, lemma_min_occurrence=None):\n",
    "\n",
    "    result = query_generic(avg_diff_table, select_cols=[\"lemma\", \"avg\"], order_by=\"avg\", order_desc=order_desc, print_query=False)\n",
    "    if lemma_min_occurrence is not None:\n",
    "        result_lemma_set = set(r[0] for r in result)\n",
    "        lemma_decade_occurrence_dict = {}\n",
    "        for decade in decade_list:\n",
    "            decades_lemma_set = set(query_generic(f\"word2vec__{decade}\", select_cols=[\"lemma\"], print_query=False))\n",
    "            for lemma in result_lemma_set:\n",
    "                if lemma in decades_lemma_set:\n",
    "                    count = lemma_decade_occurrence_dict.get(lemma, 0)\n",
    "                    lemma_decade_occurrence_dict[lemma] = count + 1\n",
    "        result_filtered = []\n",
    "        for r in result:\n",
    "            if lemma_decade_occurrence_dict.get(r[0], 0) >= lemma_min_occurrence:\n",
    "                result_filtered.append(r)\n",
    "        result = result_filtered\n",
    "    plot_2d_scatter(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976038f-f452-4c2f-a915-c420eaee6f3d",
   "metadata": {},
   "source": [
    "### plot_lemma_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945dee2-b907-42a7-adda-c53ed139cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lemma_diff(decade_list, lemma, diff_table_prefix, yaxis_range=None):\n",
    "    table = []\n",
    "    decade_a = decade_list[0]\n",
    "    if \"trajectory\" in diff_table_prefix:\n",
    "        start_i = 2\n",
    "    else:\n",
    "        start_i = 1\n",
    "    for decade_b in decade_list[start_i:]:\n",
    "        result = query_generic(f\"{diff_table_prefix}__{decade_a}_{decade_b}\", lemma_list=[lemma], select_cols=[\"diff\"], print_query=False)\n",
    "        if result:\n",
    "            table.append(\n",
    "                (\n",
    "                    f\"{decade_a}-{decade_b}\",\n",
    "                    result[0]\n",
    "                )\n",
    "            )\n",
    "        decade_a += 1\n",
    "    plot_2d_scatter(table, draw_line=True, yaxis_range=yaxis_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a48974-ea44-4e6e-8e2f-e39d0150a009",
   "metadata": {},
   "source": [
    "## DB functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47764fca-c955-4cde-b1c1-d17960722b12",
   "metadata": {},
   "source": [
    "### connect_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9d741-c3b1-48fb-a99e-2e6df98bf98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(create_cursor=True):\n",
    "    conn = psycopg.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cursor = None\n",
    "    if create_cursor:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT version();\")\n",
    "        print(\"connected to:\", cursor.fetchone())\n",
    "    return conn, cursor\n",
    "\n",
    "\n",
    "conn, cursor = connect_db()\n",
    "\n",
    "register_vector(conn)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bea8ff-5722-48ca-8493-ce62b0ed86d5",
   "metadata": {},
   "source": [
    "### reset_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648237ca-c546-435d-a7fb-56dd3479c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_db(decade_list):\n",
    "    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    cursor.execute(\"SELECT tablename FROM pg_tables WHERE schemaname = 'public';\")\n",
    "    for table in cursor.fetchall():\n",
    "        drop_table(table[0])\n",
    "    for decade in decade_list:\n",
    "        # for model in [\"word2vec\", \"fasttext\", \"glove\"]:\n",
    "        for model in [\"word2vec\"]:\n",
    "            create_embeddings_table(f\"{model}__{decade}\")\n",
    "\n",
    "\n",
    "if TEST and RESET_DB:\n",
    "    reset_db(decade_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4893c2f-aed1-49ba-9ce7-9cd01bb755f8",
   "metadata": {},
   "source": [
    "### register_vector_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfabafb-f484-4768-9a04-ef107278200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_vector_conn():\n",
    "    global conn\n",
    "    global cursor\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    conn, _ = connect_db(create_cursor=False)\n",
    "    register_vector(conn)\n",
    "    cursor = conn.cursor()\n",
    "    return conn, cursor\n",
    "\n",
    "\n",
    "conn, cursor = register_vector_conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171613a2-b196-41c6-a26d-f2c7840f631b",
   "metadata": {},
   "source": [
    "### drop_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35a3d7-1113-4551-8b5c-ea25ad3d8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_table(table_name):\n",
    "    print(\"drop_table: table_name:\", table_name)\n",
    "    cursor.execute(f'DROP TABLE IF EXISTS \"{table_name}\" CASCADE;')\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    drop_table(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e184eb-ad71-4f28-8d5a-a0cfb6f14c26",
   "metadata": {},
   "source": [
    "### create_embeddings_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda44a3-9132-4371-8d86-8d7abd0805da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_table(table_name):\n",
    "    print(\"create_embeddings_table: table_name:\", table_name)\n",
    "    cursor.execute(\n",
    "        f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "        f\"lemma TEXT PRIMARY KEY, \"\n",
    "        f\"occurrence_count INTEGER, \"\n",
    "        f\"embedding VECTOR(300) not null\"\n",
    "        f\");\"\n",
    "    )\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    create_embeddings_table(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c17aa9f-2ef5-4d6b-9ad4-8fe898623c82",
   "metadata": {},
   "source": [
    "### create_diff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a108d70-30f5-48f4-b6b9-bb07e6841342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff_table(table_name):\n",
    "    print(\"create_diff_table: table_name:\", table_name)\n",
    "    cursor.execute(\n",
    "        f\"CREATE TABLE IF NOT EXISTS {table_name} (\" f\"lemma TEXT PRIMARY KEY, \" f\"occurrence_count INTEGER, \" f\"diff REAL\" f\");\"\n",
    "    )\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    create_diff_table(\"test_diff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff3ebb-891f-4bd0-a0d9-9fa92fbaaa13",
   "metadata": {},
   "source": [
    "### create_merged_diff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da22f4-252d-49b1-b4e5-b006b8e4ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merged_diff_table(table_name):\n",
    "    print(\"create_diff_table: table_name:\", table_name)\n",
    "    cursor.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} (lemma TEXT PRIMARY KEY, diff_a REAL, diff_b REAL, diff_diff REAL);\")\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    create_diff_table(\"test_merged_diff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3826b7c-35ba-4aa2-a02b-425348eff789",
   "metadata": {},
   "source": [
    "### create_avg_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc471b-3259-47aa-a999-88d9163b974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_avg_table(table_name, avg_is_int=True):\n",
    "    print(\"create_diff_table: table_name:\", table_name)\n",
    "    if avg_is_int:\n",
    "        cursor.execute(\n",
    "            f\"CREATE TABLE IF NOT EXISTS {table_name} (lemma TEXT PRIMARY KEY, avg INTEGER);\"\n",
    "        )\n",
    "    else:\n",
    "        cursor.execute(\n",
    "            f\"CREATE TABLE IF NOT EXISTS {table_name} (lemma TEXT PRIMARY KEY, avg REAL);\"\n",
    "        )\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    create_avg_table(\"test_avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fdd8d-c3d6-4a25-8a74-301ccfb843cc",
   "metadata": {},
   "source": [
    "### insert_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212a339-2fbb-4930-8165-1fd14ac5f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_db(table_name, table_data, cols=COLS_EMBEDDING):\n",
    "    print(\"insert_to_db: table_name:\", table_name, \"len(table_data):\", len(table_data))\n",
    "    query = SQL(\"INSERT INTO {table_name} ({cols}) VALUES ({values}) ON CONFLICT(lemma) DO NOTHING\")\n",
    "    query = query.format(\n",
    "        table_name=Identifier(table_name),\n",
    "        cols=SQL(\", \").join([Identifier(c) for c in cols]),\n",
    "        values=SQL(\", \").join([Placeholder() for _ in cols]),\n",
    "    )\n",
    "    print(query.as_string())\n",
    "    cursor.executemany(query, table_data)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    table_data = [\n",
    "        [\"gehen\", 25, [4.3, 1.2, 0.3] * 100],\n",
    "        [\"laufen\", 17, [3.2, 1.7, 2.5] * 100],\n",
    "    ]\n",
    "    insert_to_db(\"test\", table_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905412c-2cce-42a7-a6d6-848065bdd89c",
   "metadata": {},
   "source": [
    "### load_word2vec_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1255b-3b0b-4ef7-9681-370713a93993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vec_to_db(decade, lemma_occurrence_count_dict):\n",
    "    print(\"load_word2vec_to_db: start: decade:\", decade)\n",
    "    model_path = MODELS_WORD2VEC_FOLDER + str(decade) + \".bin\"\n",
    "    model = Word2Vec.load(model_path)\n",
    "    db_insertion_list = []\n",
    "    for lemma in model.wv.index_to_key:\n",
    "        if is_word(lemma):\n",
    "            embedding = model.wv[lemma]\n",
    "            embedding_normalized = embedding / np.linalg.norm(embedding)\n",
    "            db_insertion_list.append((lemma, lemma_occurrence_count_dict[lemma], embedding_normalized))\n",
    "    insert_to_db(f\"word2vec__{decade}\", db_insertion_list)\n",
    "\n",
    "\n",
    "if TEST and RESET_DB:\n",
    "    for decade, lemma_occurrence_count_dict in decade_lemma_occurrence_count_dict.items():\n",
    "        load_word2vec_to_db(decade, lemma_occurrence_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57554cf-db78-407f-b4c8-fe3c43997468",
   "metadata": {},
   "source": [
    "### load_glove_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad80f6-d715-4e4d-b450-bc35e5fa0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_to_db(decade, lemma_occurrence_count_dict):\n",
    "    VECTORS = {}\n",
    "    model_path = MODELS_GLOVE_FOLDER + str(decade) + \"_vector.txt\"\n",
    "    with open(model_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            vals = line.rstrip().split(\" \")\n",
    "            VECTORS[vals[0]] = np.array([float(x) for x in vals[1:]])\n",
    "    return VECTORS\n",
    "\n",
    "\n",
    "if TEST and RESET_DB:\n",
    "    load_glove_to_db(185, decade_lemma_occurrence_count_dict[185])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653aa446-c63d-4544-a0d7-819c1c0324cb",
   "metadata": {},
   "source": [
    "### query_generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e405f-1a61-4c6a-8802-75245f1c6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_generic(table_name, lemma_list=None, select_cols=COLS_EMBEDDING, order_by=None, order_desc=False, print_query=True):\n",
    "    query = SQL(\"SELECT {select_cols} FROM {table_name}\")\n",
    "    query = query.format(select_cols=SQL(\", \").join([Identifier(c) for c in select_cols]), table_name=Identifier(table_name))\n",
    "    if lemma_list:\n",
    "        query_where = SQL(\"WHERE lemma = ANY({lemma_list})\")\n",
    "        query_where = query_where.format(lemma_list=Placeholder(\"lemma_list\"))\n",
    "        query = SQL(\" \").join([query, query_where])\n",
    "        params = {\"lemma_list\": lemma_list}\n",
    "    else:\n",
    "        params = {}\n",
    "    if order_by:\n",
    "        query += SQL(\" ORDER BY {order_col}\").format(order_col=Identifier(order_by))\n",
    "        if order_desc:\n",
    "            query += SQL(\" DESC\")\n",
    "    if print_query:\n",
    "        print(query.as_string())\n",
    "    cursor.execute(query=query, params=params)\n",
    "    result = cursor.fetchall()\n",
    "    if len(select_cols) == 1:\n",
    "        result = [r[0] for r in result]\n",
    "    return result\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    print(len(query_generic(\"word2vec__185\")))\n",
    "    print(len(query_generic(\"word2vec__185\", [\"gehen\"])))\n",
    "    print(len(query_generic(\"word2vec__185\", [\"gehen\", \"laufen\"])))\n",
    "    print(len(query_generic(\"word2vec__185\", [\"gehen\"], [\"lemma\"], \"lemma\", order_desc=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b1ab9-42e9-4949-88b8-07cff06e7bb4",
   "metadata": {},
   "source": [
    "### query_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb4cef-2fdd-40f7-ba41-97f33edf60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_related(table_name, lemma, n=10, select_cols=[\"lemma\", \"cos_sim\"]):\n",
    "    select_cols_sql = \", \".join(select_cols)\n",
    "    cursor.execute(\n",
    "        f\"\"\"\n",
    "        WITH similarities AS (\n",
    "            SELECT a.lemma, a.embedding, 1 - (a.embedding <=> b.embedding) AS cos_sim\n",
    "            FROM {table_name} a\n",
    "            CROSS JOIN (\n",
    "                SELECT embedding FROM {table_name}\n",
    "                WHERE lemma = '{lemma}'\n",
    "            ) AS b\n",
    "            WHERE lemma != '{lemma}'\n",
    "        )\n",
    "        SELECT {select_cols_sql}\n",
    "        FROM similarities\n",
    "        ORDER BY cos_sim DESC\n",
    "        LIMIT {n};\n",
    "    \"\"\"\n",
    "    )\n",
    "    return cursor.fetchall()\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    print(query_related(\"word2vec__185\", \"gehen\"))\n",
    "    print(query_related(\"word2vec__185\", \"Frau\", n=5))\n",
    "    print(query_related(\"word2vec__185\", \"Frau\", n=1, select_cols=[\"embedding\"])[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c4524-a8e3-49a4-8898-b87287d0be1a",
   "metadata": {},
   "source": [
    "### query_mutual_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e8a1b-ae53-4bd3-b338-b9e2efe507f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_mutual_lemmas(table_list, include_count=True, print_query=True):\n",
    "    select_occurrence_part = \"\"\n",
    "    if include_count:\n",
    "        select_occurrence_part = \", \" + \" + \".join([t + \".occurrence_count\" for t in table_list])\n",
    "    join_part = table_list[0]\n",
    "    for table in table_list[1:]:\n",
    "        join_part += \" INNER JOIN \" + table + \" USING (lemma) \"\n",
    "    query = f\"SELECT lemma {select_occurrence_part} FROM {join_part}\"\n",
    "    query += \";\"\n",
    "    if print_query:\n",
    "        print(\"query_mutual_lemmas: query:\", query)\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    if not include_count:\n",
    "        result = [r[0] for r in result]\n",
    "    return result\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    table_list_list = [\n",
    "        [[\"word2vec__183\"], True],\n",
    "        [[\"word2vec__183\", \"word2vec__184\"], True],\n",
    "        [[\"word2vec__183\", \"word2vec__184\", \"word2vec__185\"], False],\n",
    "    ]\n",
    "    for table_list, include_count in table_list_list:\n",
    "        r = query_mutual_lemmas(table_list, include_count)\n",
    "        print(len(r))\n",
    "        print(r[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3cd3c1-3ae1-4a97-b46d-99687bcdcd0a",
   "metadata": {},
   "source": [
    "### query_average_create_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43fb78-c3b4-4fa7-949a-44ceeb7f8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_average_create_table(table_prefix, table_kind, decade_list, select_cols, table_name_avg=None, round_value=False):\n",
    "    lemma_value_dict = {}\n",
    "    decade_a = decade_list[0]\n",
    "    decade_b = decade_list[1]\n",
    "    decade_c = decade_list[2]\n",
    "    for decade in decade_list[3:] + [None]:\n",
    "        if table_kind == \"embedding\":\n",
    "            table_name = f\"{table_prefix}__{decade_a}\"\n",
    "        elif table_kind == \"diff__cos_sim\" or table_kind == \"diff__relative\":\n",
    "            table_name = f\"{table_prefix}__{table_kind}__{decade_a}_{decade_b}\"\n",
    "        elif table_kind == \"diff__trajectory\":\n",
    "            table_name = f\"{table_prefix}__{table_kind}__{decade_a}_{decade_c}\"\n",
    "        else:\n",
    "            raise Exception(\"no table_kind specified\")\n",
    "        for lemma, value in query_generic(table_name, select_cols=select_cols):\n",
    "            value_list = lemma_value_dict.get(lemma, [])\n",
    "            value_list.append(value)\n",
    "            lemma_value_dict[lemma] = value_list\n",
    "        decade_a = decade_b\n",
    "        decade_b = decade_c\n",
    "        decade_c = decade\n",
    "    lemma_value_average_dict = {}\n",
    "    for lemma, value_list in lemma_value_dict.items():\n",
    "        value_avg = sum(value_list) / len(value_list)\n",
    "        if round_value:\n",
    "            value_avg = int(value_avg)\n",
    "        lemma_value_average_dict[lemma] = value_avg\n",
    "    lemma_value_average_dict = sort_dict_by_value(lemma_value_average_dict)\n",
    "    if table_name_avg:\n",
    "        drop_table(table_name_avg)\n",
    "        create_avg_table(table_name_avg, avg_is_int=round_value)\n",
    "        lemma_value_average_list = [(k, v) for k, v in lemma_value_average_dict.items()]\n",
    "        insert_to_db(table_name_avg, lemma_value_average_list, cols=[\"lemma\", \"avg\"])\n",
    "    return lemma_value_average_dict\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    lemma_count_average_dict = query_average_create_table(\n",
    "        \"word2vec\",\n",
    "        table_kind=\"embedding\",\n",
    "        decade_list=decade_list_test,\n",
    "        select_cols=[\"lemma\", \"occurrence_count\"],\n",
    "        table_name_avg=\"word2vec__occurrence_count__avg\",\n",
    "        round_value=True,\n",
    "    )\n",
    "    print(list(lemma_count_average_dict.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339d3b8-3aa5-4032-9033-4b94bcef99d4",
   "metadata": {},
   "source": [
    "### query_over_mutual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6cb1c-def8-44b5-acef-e6ed27815740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_over_mutual(table_name_list, select_cols=COLS_EMBEDDING):\n",
    "    print(\"query_over_mutual: start: table_name_list:\", table_name_list)\n",
    "    common_lemma = query_mutual_lemmas(table_name_list, include_count=False)\n",
    "    embeddings_table_list = []\n",
    "    for table_name in table_name_list:\n",
    "        embeddings_table_list.append(query_generic(table_name, common_lemma, select_cols=select_cols, order_by=\"lemma\"))\n",
    "    return zip(*embeddings_table_list)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    for count, x in enumerate(query_over_mutual([\"word2vec__183\", \"word2vec__184\"])):\n",
    "        a = x[0]\n",
    "        b = x[1]\n",
    "        print(a[0:2], a[2].shape, b[0:2], b[2].shape)\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1bd00f-6740-4f04-8dd5-fb119b31823b",
   "metadata": {},
   "source": [
    "### query_lemma_over_decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ed088-796d-4a93-95e4-3be145905a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_lemma_over_decades(decade_list, lemma_list, print_query=True):\n",
    "    result_table = []\n",
    "    for decade in decade_list:\n",
    "        for lemma, embedding in query_generic(f\"word2vec__{decade}\", lemma_list, select_cols=[\"lemma\", \"embedding\"], print_query=print_query):\n",
    "            result_table.append((decade, lemma, embedding))\n",
    "    return result_table\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    print(len(query_lemma_over_decades([184,185,186], [\"gehen\", \"essen\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560b448f-8ad0-4ddf-9131-5438414f47c3",
   "metadata": {},
   "source": [
    "## difference analysis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797b6e1-33f3-45e0-a711-86d51d547d7c",
   "metadata": {},
   "source": [
    "### calculate_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f02bef-6c1c-47b2-ba0e-ca03eea28722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_sim(embedding_a: np.ndarray, embedding_b: np.ndarray) -> float:\n",
    "    return np.dot(embedding_a, embedding_b) / (np.linalg.norm(embedding_a) * np.linalg.norm(embedding_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d60524-a615-4213-bc2a-d05edfa78180",
   "metadata": {},
   "source": [
    "### calculate_cos_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c26e6-cf9a-4fed-bb75-be68aaa67d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_distance(embedding_a: np.ndarray, embedding_b: np.ndarray) -> float:\n",
    "    return 1 - calculate_cos_sim(embedding_a, embedding_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908ad80-d33c-4bde-a049-e42f89136c02",
   "metadata": {},
   "source": [
    "### calculate_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54291d-0139-468a-9668-6aad14749cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tsne(embeddings, perplexity=None):\n",
    "    if perplexity is None:\n",
    "        if len(embeddings) < 6:\n",
    "            perplexity = len(embeddings) - 1\n",
    "        else:\n",
    "            perplexity = 40\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    embeddings_reduced = tsne.fit_transform(np.array(embeddings))\n",
    "    return embeddings_reduced\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    embeddings_reduced = calculate_tsne(query_generic(\"word2vec__185\", TEST_LEMMA_CLOSE_LIST, select_cols=[\"embedding\"]))\n",
    "    print(embeddings_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67979ca3-07c2-4b15-9bdf-7bf358f49360",
   "metadata": {},
   "source": [
    "### calculate_trajectory_between_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66127113-facd-4cb9-a43d-2a112afa02dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trajectory_between_vectors(vector_a, vector_b, vector_c):\n",
    "    vector_ab = vector_a - vector_b\n",
    "    vector_bc = vector_b - vector_c\n",
    "    return np.dot(vector_ab, vector_bc)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    vector_list_list = [\n",
    "        (np.array([1, 2]), np.array([2, 3]), np.array([2, 5])),\n",
    "        (np.array([1, 2]), np.array([2, 3]), np.array([2, 3])),\n",
    "        (np.array([1, 2]), np.array([2, 3]), np.array([1, 2])),\n",
    "    ]\n",
    "    for vector_list in vector_list_list:\n",
    "        print(calculate_trajectory_between_vectors(*vector_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde629a-b62a-4bfd-8023-51bf0865c671",
   "metadata": {},
   "source": [
    "### calculate_procrustes_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec26a94-baf4-4239-8985-7c865dac662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_procrustes_alignment(table_name_a, table_name_b, table_aligned_name_b):\n",
    "    print(\"calculate_procrustes_alignment: start: (table_name_a, table_name_b, table_aligned_name_b):\", (table_name_a, table_name_b, table_aligned_name_b))\n",
    "    overlap_matrix_a = []\n",
    "    overlap_matrix_b = []\n",
    "    for lemma_embedding_a, lemma_embedding_b in query_over_mutual([table_name_a, table_name_b]):\n",
    "        occurrence_count_sqrt = np.log1p((lemma_embedding_a[1] + lemma_embedding_b[1]) / 2)\n",
    "        overlap_matrix_a.append(lemma_embedding_a[2] * occurrence_count_sqrt)\n",
    "        overlap_matrix_b.append(lemma_embedding_b[2] * occurrence_count_sqrt)\n",
    "    overlap_matrix_a = np.stack(overlap_matrix_a)\n",
    "    overlap_matrix_b = np.stack(overlap_matrix_b)\n",
    "\n",
    "    # do procrustes transformation\n",
    "    r, _ = orthogonal_procrustes(overlap_matrix_b, overlap_matrix_a)\n",
    "    embeddings_table_all_b = query_generic(table_name_b, select_cols=COLS_EMBEDDING, order_by=\"lemma\")\n",
    "    matrix_b = [e[2] for e in embeddings_table_all_b]\n",
    "    matrix_b = np.stack(matrix_b)\n",
    "    matrix_b_aligned = matrix_b @ r\n",
    "    matrix_b_aligned_normalized = matrix_b_aligned / np.linalg.norm(matrix_b_aligned, axis=1, keepdims=True)\n",
    "    print(\"calculate_procrustes_alignment: matrix_b_aligned.shape:\", matrix_b_aligned.shape)\n",
    "    db_insertion_data = []\n",
    "    for embeddings_table_b_data, embedding_b_aligned in zip(embeddings_table_all_b, matrix_b_aligned_normalized):\n",
    "        db_insertion_data.append([embeddings_table_b_data[0], embeddings_table_b_data[1], embedding_b_aligned])\n",
    "    drop_table(table_aligned_name_b)\n",
    "    create_embeddings_table(table_aligned_name_b)\n",
    "    insert_to_db(table_aligned_name_b, db_insertion_data)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    if RESET_DB:\n",
    "        calculate_procrustes_alignment(\"word2vec__184\", \"word2vec__185\", \"word2vec__185__aligned\")\n",
    "        calculate_procrustes_alignment(\"word2vec__185__aligned\", \"word2vec__186\", \"word2vec__186__aligned\")\n",
    "    embeddings_table_184 = query_generic(\n",
    "        \"word2vec__184\",\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        select_cols=[\"lemma\", \"embedding\"],\n",
    "        order_by=\"lemma\",\n",
    "    )\n",
    "    embeddings_table_185 = query_generic(\n",
    "        \"word2vec__185\",\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        select_cols=[\"lemma\", \"embedding\"],\n",
    "        order_by=\"lemma\",\n",
    "    )\n",
    "    embeddings_table_186 = query_generic(\n",
    "        \"word2vec__186\",\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        select_cols=[\"lemma\", \"embedding\"],\n",
    "        order_by=\"lemma\",\n",
    "    )\n",
    "    embeddings_table_185_aligned = query_generic(\n",
    "        \"word2vec__185__aligned\",\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        select_cols=[\"lemma\", \"embedding\"],\n",
    "        order_by=\"lemma\",\n",
    "    )\n",
    "    embeddings_table_186_aligned = query_generic(\n",
    "        \"word2vec__186__aligned\",\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        select_cols=[\"lemma\", \"embedding\"],\n",
    "        order_by=\"lemma\",\n",
    "    )\n",
    "    for lemma, e_184, e_185, e_186, e_185_aligned, e_186_aligned in zip(\n",
    "        TEST_LEMMA_RANGED_LIST,\n",
    "        embeddings_table_184,\n",
    "        embeddings_table_185,\n",
    "        embeddings_table_186,\n",
    "        embeddings_table_185_aligned,\n",
    "        embeddings_table_186_aligned,\n",
    "    ):\n",
    "        print(lemma)\n",
    "        print(\"184-185:\", calculate_cos_sim(e_184[1], e_185[1]))\n",
    "        print(\"185-186:\", calculate_cos_sim(e_185[1], e_186[1]))\n",
    "        print(\"184-185_aligned:\", calculate_cos_sim(e_184[1], e_185_aligned[1]))\n",
    "        print(\"185_aligned-186_aligned:\", calculate_cos_sim(e_185_aligned[1], e_186_aligned[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66775e-5bcd-46cb-8213-6971496bb6f1",
   "metadata": {},
   "source": [
    "### calculate_cos_sim_between_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb5814-48e1-4ef3-be5a-653f27590f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_sim_between_tables(table_name_a, table_name_b, table_name_diff):\n",
    "    print(\n",
    "        \"calculate_cos_sim_between_tables: start: (table_name_a, table_name_b, table_name_diff)\",\n",
    "        (table_name_a, table_name_b, table_name_diff),\n",
    "    )\n",
    "    db_insertion_data = []\n",
    "    for lemma_embedding_a, lemma_embedding_b in query_over_mutual([table_name_a, table_name_b]):\n",
    "        db_insertion_data.append(\n",
    "            (\n",
    "                lemma_embedding_a[0],\n",
    "                int((lemma_embedding_a[1] + lemma_embedding_b[1]) / 2),\n",
    "                calculate_cos_sim(lemma_embedding_a[2], lemma_embedding_b[2]),\n",
    "            )\n",
    "        )\n",
    "    print(\"calculate_cos_sim_between_tables: len(db_insertion_data):\", len(db_insertion_data))\n",
    "    drop_table(table_name_diff)\n",
    "    create_diff_table(table_name_diff)\n",
    "    insert_to_db(table_name_diff, db_insertion_data, cols=[\"lemma\", \"occurrence_count\", \"diff\"])\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    diff_table_name = \"word2vec__diff__cos_sim__184_185\"\n",
    "    if RESET_DB:\n",
    "        calculate_cos_sim_between_tables(\"word2vec__185__aligned\", \"word2vec__186__aligned\", diff_table_name)\n",
    "    diff_table = query_generic(\n",
    "        diff_table_name,\n",
    "        select_cols=[\"lemma\", \"diff\"],\n",
    "        order_by=\"diff\",\n",
    "        order_desc=True,\n",
    "    )\n",
    "    plot_2d_scatter(diff_table, diff_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124d33a-12fa-41ad-9b73-4f400ed27930",
   "metadata": {},
   "source": [
    "### calculate_trajectory_between_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d2d56-898e-4856-9d7a-2d324293bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trajectory_between_tables(table_name_a, table_name_b, table_name_c, table_name_diff):\n",
    "    print(\n",
    "        \"calculate_trajectory_between_tables: start: (table_name_a, table_name_b, table_name_c, table_name_diff):\",\n",
    "        (table_name_a, table_name_b, table_name_c, table_name_diff),\n",
    "    )\n",
    "    db_insertion_data = []\n",
    "    for lemma_embedding_a, lemma_embedding_b, lemma_embedding_c in query_over_mutual([table_name_a, table_name_b, table_name_c]):\n",
    "        db_insertion_data.append(\n",
    "            (\n",
    "                lemma_embedding_a[0],\n",
    "                int((lemma_embedding_a[1] + lemma_embedding_b[1] + lemma_embedding_c[1]) / 3),\n",
    "                calculate_trajectory_between_vectors(lemma_embedding_a[2], lemma_embedding_b[2], lemma_embedding_c[2]),\n",
    "            )\n",
    "        )\n",
    "    print(\"calculate_cos_sim_between_tables: len(db_insertion_data):\", len(db_insertion_data))\n",
    "    drop_table(table_name_diff)\n",
    "    create_diff_table(table_name_diff)\n",
    "    insert_to_db(table_name_diff, db_insertion_data, cols=[\"lemma\", \"occurrence_count\", \"diff\"])\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    diff_table_name = \"word2vec__diff__trajectory__184_186\"\n",
    "    if RESET_DB:\n",
    "        calculate_trajectory_between_tables(\"word2vec__184\", \"word2vec__185__aligned\", \"word2vec__186__aligned\", diff_table_name)\n",
    "    diff_table = query_generic(\n",
    "        diff_table_name,\n",
    "        select_cols=[\"lemma\", \"diff\"],\n",
    "        order_by=\"diff\",\n",
    "        order_desc=True,\n",
    "    )\n",
    "    plot_2d_scatter(diff_table, diff_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28537d-811a-403d-9210-44c323abbb2e",
   "metadata": {},
   "source": [
    "### calculate_relative_diff_between_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d16d8-8254-4003-a182-5612b6d94a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_diff_between_tables(table_name_a, table_name_b, table_name_diff):\n",
    "    print(\"calculate_relative_diff_between_tables: start: (table_name_a, table_name_b):\", (table_name_a, table_name_b))\n",
    "    db_insertion_data = []\n",
    "    for mutual in query_mutual_lemmas([table_name_a, table_name_b], include_count=True):\n",
    "        lemma = mutual[0]\n",
    "        related_lemma_embedding_a = query_related(table_name_a, lemma, n=100)\n",
    "        related_lemma_embedding_b = query_related(table_name_b, lemma, n=100)\n",
    "        similarity_dict_a = {l: c for l, c in related_lemma_embedding_a}\n",
    "        similarity_dict_b = {l: c for l, c in related_lemma_embedding_b}\n",
    "        common_related_lemma = set(similarity_dict_a.keys()) & set(similarity_dict_b.keys())\n",
    "        diff = 0\n",
    "        for lemma_related in common_related_lemma:\n",
    "            diff += abs(similarity_dict_a[lemma_related] - similarity_dict_b[lemma_related])\n",
    "        db_insertion_data.append((lemma, int(mutual[1] / 2), diff))\n",
    "    print(\"calculate_cos_sim_between_tables: len(db_insertion_data):\", len(db_insertion_data))\n",
    "    drop_table(table_name_diff)\n",
    "    create_diff_table(table_name_diff)\n",
    "    insert_to_db(table_name_diff, db_insertion_data, cols=[\"lemma\", \"occurrence_count\", \"diff\"])\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    diff_table_name = \"word2vec__diff__relative__184_185\"\n",
    "    if RESET_DB:\n",
    "        calculate_relative_diff_between_tables(\"word2vec__184\", \"word2vec__185\", diff_table_name)\n",
    "    diff_table = query_generic(\n",
    "        diff_table_name,\n",
    "        select_cols=[\"lemma\", \"diff\"],\n",
    "        order_by=\"diff\",\n",
    "        order_desc=False,\n",
    "    )\n",
    "    plot_2d_scatter(diff_table, diff_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f98c122-f4ef-49c1-86e9-186677d0c2f3",
   "metadata": {},
   "source": [
    "## compare diff methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f4a336-2d13-4a8a-85a2-b54e994e0e9e",
   "metadata": {},
   "source": [
    "### create_random_diff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7230e81-6a2f-4518-927c-487b51affe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_diff_table(table_name_from, table_name_random_a, table_name_random_b):\n",
    "    lemma_table = query_generic(table_name_from, select_cols=[\"lemma\"])\n",
    "\n",
    "    range_min = -1000\n",
    "    range_max = 1000\n",
    "    random_diff_table_a = []\n",
    "    random_diff_table_b = []\n",
    "    for lemma in lemma_table:\n",
    "        random_diff_table_a.append((lemma, 0, random.randint(range_min, range_max) / 1000))\n",
    "        random_diff_table_b.append((lemma, 0, random.randint(range_min, range_max) / 1000))\n",
    "    drop_table(table_name_random_a)\n",
    "    drop_table(table_name_random_b)\n",
    "    create_diff_table(table_name_random_a)\n",
    "    create_diff_table(table_name_random_b)\n",
    "    insert_to_db(table_name_random_a, random_diff_table_a, cols=COLS_DIFF)\n",
    "    insert_to_db(table_name_random_b, random_diff_table_b, cols=COLS_DIFF)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    table_name_a = \"test__diff__random__a\"\n",
    "    table_name_b = \"test__diff__random__b\"\n",
    "    create_random_diff_table(\"word2vec__diff__cos_sim__184_185\", table_name_a, table_name_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54063f6-a3eb-4949-9797-852dd9530360",
   "metadata": {},
   "source": [
    "### normalize_diff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0376830f-04c2-443a-bb58-45a0209d0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_diff_table(diff_table_name, diff_table_name_new, invert=False):\n",
    "    print(\"normalize_diff_table: start: table_name_diff:\", diff_table_name)\n",
    "    diff_table = query_generic(diff_table_name, select_cols=COLS_DIFF, order_by=\"diff\")\n",
    "    min_diff = None\n",
    "    max_diff = None\n",
    "    for diff_row in diff_table:\n",
    "        diff_value = diff_row[2]\n",
    "        if min_diff is None and max_diff is None:\n",
    "            min_diff = diff_value\n",
    "            max_diff = diff_value\n",
    "        else:\n",
    "            if diff_value < min_diff:\n",
    "                min_diff = diff_value\n",
    "            if diff_value > max_diff:\n",
    "                max_diff = diff_value\n",
    "    scale = 2 / (max_diff - min_diff)\n",
    "    print(max_diff)\n",
    "    diff_table_new = []\n",
    "    for diff_row in diff_table:\n",
    "        value = ((diff_row[2] - min_diff) * scale) - 1\n",
    "        if invert:\n",
    "            value *= -1\n",
    "        diff_table_new.append((diff_row[0], diff_row[1], value))\n",
    "    print(\"normalize_diff_table: len(diff_table_new):\", len(diff_table_new))\n",
    "    drop_table(diff_table_name_new)\n",
    "    create_diff_table(diff_table_name_new)\n",
    "    insert_to_db(diff_table_name_new, diff_table_new, cols=COLS_DIFF)\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    table_list = [\n",
    "        (\"word2vec__diff__cos_sim__184_185\", \"word2vec__diff__cos_sim__normalized__184_185\", False),\n",
    "        (\"word2vec__diff__trajectory__184_186\", \"word2vec__diff__trajectory__normalized__184_186\", False),\n",
    "        (\"word2vec__diff__relative__184_185\", \"word2vec__diff__relative__normalized__184_185\", True),\n",
    "        (\"test__diff__random__a\", \"test__diff__random__normalized__a\", False),\n",
    "        (\"test__diff__random__b\", \"test__diff__random__normalized__b\", False),\n",
    "    ]\n",
    "    for table in table_list:\n",
    "        normalize_diff_table(*table)\n",
    "    for table in table_list:\n",
    "        plot_2d_scatter(query_generic(table[1], select_cols=[\"lemma\", \"diff\"], order_by=\"diff\", order_desc=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a640a-5994-4dd3-91ee-973f7a957587",
   "metadata": {},
   "source": [
    "### merge_normalized_diff_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd1bfa-cee1-48aa-94d2-b1c113a479d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_normalized_diff_tables(table_name_a, table_name_b, diff_compared_table_name):\n",
    "    print(\n",
    "        \"merge_normalized_diff_tables: start: (table_name_a, table_name_b, diff_compared_table_name)\",\n",
    "        (table_name_a, table_name_b, diff_compared_table_name),\n",
    "    )\n",
    "\n",
    "    db_insertion_data = []\n",
    "    for lemma_diff_a, lemma_diff_b in query_over_mutual([table_name_a, table_name_b], select_cols=[\"lemma\", \"diff\"]):\n",
    "        db_insertion_data.append(\n",
    "            (\n",
    "                lemma_diff_a[0],\n",
    "                lemma_diff_a[1],\n",
    "                lemma_diff_b[1],\n",
    "                abs(lemma_diff_a[1] - lemma_diff_b[1]),\n",
    "            )\n",
    "        )\n",
    "    print(\"merge_normalized_diff_tables: len(db_insertion_data):\", len(db_insertion_data))\n",
    "    drop_table(diff_compared_table_name)\n",
    "    create_merged_diff_table(diff_compared_table_name)\n",
    "    insert_to_db(diff_compared_table_name, db_insertion_data, cols=[\"lemma\", \"diff_a\", \"diff_b\", \"diff_diff\"])\n",
    "\n",
    "\n",
    "if TEST:\n",
    "    table_list = [\n",
    "        (\n",
    "            \"word2vec__diff__cos_sim__normalized__184_185\",\n",
    "            \"word2vec__diff__trajectory__normalized__184_186\",\n",
    "            \"word2vec__merged__cos_sim_trajectory__184_186\",\n",
    "        ),\n",
    "        (\n",
    "            \"word2vec__diff__cos_sim__normalized__184_185\",\n",
    "            \"word2vec__diff__relative__normalized__184_185\",\n",
    "            \"word2vec__merged__cos_relative__184_186\",\n",
    "        ),\n",
    "        (\n",
    "            \"word2vec__diff__trajectory__normalized__184_186\",\n",
    "            \"word2vec__diff__relative__normalized__184_185\",\n",
    "            \"word2vec__merged__trajectory_relative__184_186\",\n",
    "        ),\n",
    "        (\n",
    "            \"test__diff__random__normalized__a\",\n",
    "            \"test__diff__random__normalized__b\",\n",
    "            \"test__merged__random__a_b\",\n",
    "        ),\n",
    "    ]\n",
    "    for table in table_list:\n",
    "        merge_normalized_diff_tables(*table)\n",
    "    for table in table_list:\n",
    "        plot_merged_diff_table(\n",
    "            query_generic(\n",
    "                table[2],\n",
    "                select_cols=[\"lemma\", \"diff_a\", \"diff_b\", \"diff_diff\"],\n",
    "                order_by=\"diff_diff\",\n",
    "                order_desc=False,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c9adf6-17ce-42af-b3dc-80ce4c861a75",
   "metadata": {},
   "source": [
    "## aggregate functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914dae72-ce55-4f3e-ac5d-9fcc854a6d7c",
   "metadata": {},
   "source": [
    "### load_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e4a0c-24e0-4ebc-9983-459424325830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_decade(decade):\n",
    "    occurrence_dict = create_occurrence_dict(decade)\n",
    "    load_word2vec_to_db(decade, occurrence_dict)\n",
    "\n",
    "\n",
    "if TEST and RESET_DB:\n",
    "    load_decade(185)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180dd3fa-17d5-4ac0-b21e-7f27e2140427",
   "metadata": {},
   "source": [
    "### load_decade_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a7eb5c-5a6c-4818-8397-f3c8209012ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_decade_pair(decade_a, decade_b, a_is_aligned=True):\n",
    "    load_decade(decade_a)\n",
    "    load_decade(decade_b)\n",
    "    table_name_a = f\"word2vec__{decade_a}\"\n",
    "    table_name_b = f\"word2vec__{decade_b}\"\n",
    "    if a_is_aligned:\n",
    "        table_name_aligned_a = f\"word2vec__{decade_a}__aligned\"\n",
    "    else:\n",
    "        table_name_aligned_a = table_name_a\n",
    "    table_name_aligned_b = f\"word2vec__{decade_b}__aligned\"\n",
    "    calculate_procrustes_alignment(table_name_aligned_a, table_name_b, table_name_aligned_b)\n",
    "    calculate_cos_sim_between_tables(table_name_aligned_a, table_name_aligned_b, f\"word2vec__diff__cos_sim__{decade_a}_{decade_b}\")\n",
    "    calculate_relative_diff_between_tables(table_name_a, table_name_b, f\"word2vec__diff__relative__{decade_a}_{decade_b}\")\n",
    "\n",
    "\n",
    "if TEST and RESET_DB:\n",
    "    load_decade_pair(185, 186, a_is_aligned=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee07722-b7d5-4442-beef-55d84ad280bf",
   "metadata": {},
   "source": [
    "### create_average_diff_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdfcdd7-30f2-46b8-a468-fdffed6830b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_average_diff_tables(decade_list):\n",
    "    decade_start = decade_list[0]\n",
    "    decade_end = decade_list[-1]\n",
    "    for diff_table in [\"diff__cos_sim\", \"diff__trajectory\", \"diff__relative\"]:\n",
    "        table_prefix = \"word2vec\"\n",
    "        query_average_create_table(\n",
    "            table_prefix=table_prefix,\n",
    "            table_kind=diff_table,\n",
    "            decade_list=decade_list,\n",
    "            select_cols=[\"lemma\", \"diff\"],\n",
    "            table_name_avg=f\"{table_prefix}__{diff_table}__avg__{decade_start}_{decade_end}\",\n",
    "            round_value=False,\n",
    "        )\n",
    "\n",
    "\n",
    "if TEST and RESET_DB:\n",
    "    create_average_diff_tables(create_decades_list(184, 186))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67ad03-2f17-45e2-b129-d4c90d29707e",
   "metadata": {},
   "source": [
    "### load_decade_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825966cc-b7b8-437b-a72e-a7e24c9b7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_decade_from_list(decade_list):\n",
    "    decade_a = decade_list[0]\n",
    "    decade_b = decade_list[1]\n",
    "    decade_c = decade_list[2]\n",
    "    load_decade_pair(decade_a, decade_b, a_is_aligned=False)\n",
    "    for decade in decade_list[3:] + [None]:\n",
    "        load_decade_pair(decade_b, decade_c)\n",
    "        table_name_a = f\"word2vec__{decade_a}\"\n",
    "        table_name_b = f\"word2vec__{decade_b}\"\n",
    "        table_name_c = f\"word2vec__{decade_c}\"\n",
    "        calculate_trajectory_between_tables(table_name_a, table_name_b, table_name_c, f\"word2vec__diff__trajectory__{decade_a}_{decade_c}\")\n",
    "        decade_a = decade_b\n",
    "        decade_b = decade_c\n",
    "        decade_c = decade\n",
    "    create_average_diff_tables(decade_list)\n",
    "\n",
    "if TEST and RESET_DB:\n",
    "    load_decade_from_list(create_decades_list(184, 186))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbe221f-83cc-4bdf-b0ff-57c5e80a2cfd",
   "metadata": {},
   "source": [
    "# load_all (warning: may delete entire DB!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560bc60c-3d29-4bda-ab50-ce2eb9ccbdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_list = create_decades_list()\n",
    "if RESET_DB:\n",
    "    reset_db(decade_list)\n",
    "    load_decade_from_list(decade_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f5ece-d414-40c9-a5b5-da3ba3081abc",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d8dd1-f18c-4d7a-b710-ed3cbd1dd709",
   "metadata": {},
   "source": [
    "## global changes analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db529c95-5fb2-43c1-9565-c61646a1a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_list = create_decades_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a4ee1-9dcb-4add-b0b5-593841e0d325",
   "metadata": {},
   "source": [
    "### average changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d601c9b2-c8f5-44b5-8b70-975003314228",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_diff(decade_list, \"word2vec__diff__cos_sim__avg__156_191\", lemma_min_occurrence=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916b9a3-7a83-4a56-bc04-f138f82d47e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_diff(decade_list, \"word2vec__diff__trajectory__avg__156_191\", lemma_min_occurrence=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8e381-91e1-4e7f-8164-3f1e5deab99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_diff(decade_list, \"word2vec__diff__relative__avg__156_191\", lemma_min_occurrence=10, order_desc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a925b5-0e66-4fdb-8e15-36352221d461",
   "metadata": {},
   "source": [
    "### changes per lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7fed3-404f-4ae1-b883-d80b0cb7260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lemma_diff(decade_list, \"Aktion\", \"word2vec__diff__cos_sim\", yaxis_range=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b65a2-d2c5-4c2b-ab46-0b942446d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lemma_diff(decade_list, \"Aktion\", \"word2vec__diff__trajectory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c605945-4d71-4802-a13e-4ab4e0e012d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lemma_diff(decade_list, \"Zeitung\", \"word2vec__diff__cos_sim\", yaxis_range=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53dda16-7128-42cf-92a3-f8a1b91ae045",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lemma_diff(decade_list, \"d\", \"word2vec__diff__cos_sim\", yaxis_range=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d0716-2c25-450e-9035-d66cc4432662",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lemma_diff(decade_list, \"Adam\", \"word2vec__diff__cos_sim\", yaxis_range=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2099f4d-171a-4132-87fb-0ce9c02a742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lemma_diff(decade_list, \"d\", \"word2vec__diff__trajectory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb5ee6-44c0-4fb4-b2bd-b2c2dc0f21a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lemma_diff(decade_list, \"Adam\", \"word2vec__diff__trajectory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271cd4a8-e438-4f7a-98df-99613694eaa2",
   "metadata": {},
   "source": [
    "### trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887bc48b-ce6d-4341-b56f-77b94faf0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lemma_and_decade(decade_list, [\"Zeitung\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c607e5-cdd9-48c3-bf97-fd0d6444fae9",
   "metadata": {},
   "source": [
    "# DB Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e05fb-0151-4114-9713-16364b31f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.close()\n",
    "# conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
