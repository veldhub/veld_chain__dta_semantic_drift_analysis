{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b395f2c-139d-4563-9eee-492057582cb8",
   "metadata": {},
   "source": [
    "## setup and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1d90b-4a93-4b63-b22d-a20fa107c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import TypeAlias\n",
    "\n",
    "import hnswlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84e8da-97e5-4c15-8d26-4e4ca9e6b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f6dec-d63a-4c18-8806-59186587fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_TEST = True\n",
    "FOLDER_MODELS_WORD2VEC = \"/veld/input/models/\"\n",
    "FOLDER_TEXTS = \"/veld/input/texts/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc305687-3bc1-4e75-9b65-83220404eaee",
   "metadata": {},
   "source": [
    "## tpye aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80f266-a429-4f85-9d63-f7d2b62cc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lemma: TypeAlias = str\n",
    "Word: TypeAlias = str\n",
    "Decade: TypeAlias = int\n",
    "LineNumber: TypeAlias = int\n",
    "WordNumber: TypeAlias = int\n",
    "OccurrenceCount: TypeAlias = int\n",
    "Embedding: TypeAlias = np.ndarray\n",
    "Model: TypeAlias = Word2Vec\n",
    "LineNumberDict: TypeAlias = dict[LineNumber, list[WordNumber]]\n",
    "IdToLemmaDict: TypeAlias = dict[int, Lemma]\n",
    "LemmaToIdDict: TypeAlias = dict[Lemma, int]\n",
    "Index: TypeAlias = list[hnswlib.Index, LemmaToIdDict, IdToLemmaDict]\n",
    "LemmaDict: TypeAlias = dict[Lemma, list[list[Word], Embedding, LineNumberDict, OccurrenceCount]]\n",
    "DecadeDict: TypeAlias = dict[Decade, list[Model, LemmaDict, Index]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58044656-cc17-4f9f-8959-2697f02436ee",
   "metadata": {},
   "source": [
    "## create_decades_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc419e9c-6232-421a-9863-fe087ed40e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decades_dict(folder) -> DecadeDict:\n",
    "    decade_dict: DecadeDict = {}\n",
    "    for model_file in os.listdir(folder):\n",
    "        if model_file.endswith(\".bin\"):\n",
    "            decade = int(model_file.split(\".bin\")[0])\n",
    "            decade_dict[decade] = None\n",
    "    print(\"create_decades_dict: decade_dict:\", decade_dict)\n",
    "    return decade_dict\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    decade_dict = create_decades_dict(FOLDER_MODELS_WORD2VEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39ab93-0e45-43ca-a6dc-e80596674e4f",
   "metadata": {},
   "source": [
    "## load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f0f7b-69bf-4a35-bca8-8ed00501fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path) -> Model:\n",
    "    model = Word2Vec.load(model_path)\n",
    "    print(\"load_model_word2vec: model_path:\", model_path)\n",
    "    print(\"load_model_word2vec: model:\", model)\n",
    "    return model\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    decade_dict[168] = [load_model(FOLDER_MODELS_WORD2VEC + \"168.bin\"), None, None]\n",
    "    decade_dict[169] = [load_model(FOLDER_MODELS_WORD2VEC + \"169.bin\"), None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb75d6-b481-45a9-93d5-51abc7f9b2f0",
   "metadata": {},
   "source": [
    "## create_lemma_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a8a67-0e81-4437-b884-73477a6530bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lemma_dict(decade: Decade, model: Model) -> LemmaDict:\n",
    "    lemma_dict: LemmaDict = {}\n",
    "    word_to_lemma_dict = {}\n",
    "\n",
    "    for word in model.wv.index_to_key:\n",
    "        lemma = nlp(word)[0].lemma_\n",
    "        word_to_lemma_dict[word] = lemma\n",
    "        lemma_dict_value = lemma_dict.get(lemma, [[], None, {}, 0])\n",
    "        word_list = lemma_dict_value[0]\n",
    "        word_list.append(word)\n",
    "        lemma_dict[lemma] = lemma_dict_value\n",
    "\n",
    "    for lemma, lemma_dict_value in lemma_dict.items():\n",
    "        word_list = lemma_dict_value[0]\n",
    "        word_embedding_list = [model.wv[word] for word in word_list]\n",
    "        embedding_average = np.mean(np.array(word_embedding_list), axis=0)\n",
    "        embedding_normalized = embedding_average / np.linalg.norm(embedding_average)\n",
    "        lemma_dict_value[1] = embedding_normalized\n",
    "\n",
    "    with open(FOLDER_TEXTS + str(decade) + \".txt\", \"r\") as f:\n",
    "        for line_number, line in enumerate(f):\n",
    "            for word_number, word in enumerate(line.split(\" \")):\n",
    "                lemma = word_to_lemma_dict.get(word)\n",
    "                if lemma:\n",
    "                    lemma_dict_value = lemma_dict[lemma]\n",
    "                    line_number_dict: LineNumberDict = lemma_dict_value[2]\n",
    "                    word_number_list: list[WordNumber] = line_number_dict.get(line_number, [])\n",
    "                    word_number_list.append(word_number)\n",
    "                    line_number_dict[line_number] = word_number_list\n",
    "                    occurrence_count = lemma_dict_value[3]\n",
    "                    lemma_dict_value[3] = occurrence_count + 1\n",
    "\n",
    "    print(\"create_lemma_dict: len(lemma_dict):\", len(lemma_dict))\n",
    "    return lemma_dict\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    decade_dict[168][1] = create_lemma_dict(168, decade_dict[168][0])\n",
    "    decade_dict[169][1] = create_lemma_dict(169, decade_dict[169][0])\n",
    "    print(decade_dict[168][0])\n",
    "    print(decade_dict[169][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647fd71-62b3-4ff5-8e6f-7d953f3bd5a7",
   "metadata": {},
   "source": [
    "## create_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e2b39a-a13f-4afe-afcd-7100bd3018bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(lemma_dict: LemmaDict) -> Index:\n",
    "\n",
    "    # prepare data\n",
    "    id_to_lemma_dict: IdToLemmaDict = {}\n",
    "    lemma_to_id_dict: LemmaToIdDict = {}\n",
    "    embedding_array = []\n",
    "    for lemma_id, (lemma, lemma_dict_value) in enumerate(lemma_dict.items()):\n",
    "        id_to_lemma_dict[lemma_id] = lemma\n",
    "        lemma_to_id_dict[lemma] = lemma_id\n",
    "        embedding_array.append(lemma_dict_value[1])\n",
    "    embedding_array = np.array(embedding_array)\n",
    "\n",
    "    # create index\n",
    "    max_elements = len(embedding_array)\n",
    "    dim = embedding_array[0].shape[0]\n",
    "    index = hnswlib.Index(space=\"cosine\", dim=dim)\n",
    "    index.init_index(max_elements=max_elements, ef_construction=100, M=16)\n",
    "    index.add_items(embedding_array, ids=list(id_to_lemma_dict.keys()))\n",
    "    return [index, lemma_to_id_dict, id_to_lemma_dict]\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    decade_dict[168][2] = create_index(decade_dict[168][1])\n",
    "    decade_dict[169][2] = create_index(decade_dict[169][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed2196-185b-45eb-9f3e-e356a4027ab4",
   "metadata": {},
   "source": [
    "## query_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77994581-272b-48e6-9c75-7a0ff66871e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_related(index: Index, lemma: Lemma, n=10):\n",
    "    result = None\n",
    "    try:\n",
    "        id_embedding = index[1][lemma]\n",
    "    except:\n",
    "        print(\"not found\")\n",
    "    else:\n",
    "        embedding = index[0].get_items([id_embedding])[0]\n",
    "        ids, distances = index[0].knn_query(embedding.reshape(1, -1), k=n)\n",
    "        result = {}\n",
    "        for id_other, distance in list(zip(ids[0], distances[0]))[1:]:\n",
    "            lemma = index[2][id_other]\n",
    "            result[lemma] = distance\n",
    "    return result\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    print(query_related(decade_dict[168][2], \"gehen\", n=10))\n",
    "    print(query_related(decade_dict[169][2], \"gehen\", n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4df4f8-08ad-4a80-ab77-bdb14fd39b5f",
   "metadata": {},
   "source": [
    "## query_cos_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd76252-2dbe-408a-a571-6df594e5b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_cos_distance(index, lemma_a, lemma_b):\n",
    "    cos_distance = None\n",
    "    try:\n",
    "        id_a = index[1][lemma_a]\n",
    "        id_b = index[1][lemma_b]\n",
    "        embedding_a = index[0].get_items([id_a])[0]\n",
    "        embedding_b = index[0].get_items([id_b])[0]\n",
    "        cos_distance = 1 - np.dot(embedding_a, embedding_b)\n",
    "    except:\n",
    "        pass\n",
    "    return cos_distance\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    print(query_cos_distance(decade_dict[168][2], \"gehen\", \"laufen\"))\n",
    "    print(query_cos_distance(decade_dict[169][2], \"gehen\", \"laufen\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7a697-a6ec-4259-a377-10d6dbf05914",
   "metadata": {},
   "source": [
    "## print_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ae976-660d-4166-9300-9edf60e010ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_occurrence(decade: Decade, lemma_dict: LemmaDict, lemma: Lemma, max_print=5):\n",
    "    line_number_dict = lemma_dict[lemma][2]\n",
    "    with open(FOLDER_TEXTS + str(decade) + \".txt\", \"r\") as f:\n",
    "        num_print = 0\n",
    "        for line_number, line in enumerate(f):\n",
    "            word_number_list = line_number_dict.get(line_number)\n",
    "            if word_number_list:\n",
    "                word_number_set = set(word_number_list)\n",
    "                text = \"\"\n",
    "                for word_number, word in enumerate(line.split(\" \")):\n",
    "                    if word_number in word_number_set:\n",
    "                        text += \" >>> \" + word + \" <<<\"\n",
    "                    else:\n",
    "                        text += \" \" + word\n",
    "                print(text)\n",
    "                num_print += 1\n",
    "                if max_print and num_print == max_print:\n",
    "                    break\n",
    "\n",
    "\n",
    "print_occurrence(168, decade_dict[168][1], \"gehen\", max_print=1)\n",
    "print_occurrence(169, decade_dict[169][1], \"gehen\", max_print=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab5ed1-54c5-44f2-aeff-f24ca178d222",
   "metadata": {},
   "source": [
    "## create_diff_of_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73940986-09cc-44e9-8790-b990f1341e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff_of_lemma(index_a_dict, index_b_dict, lemma):\n",
    "    diff_total = None\n",
    "\n",
    "    # key and dict synchronization\n",
    "    distances_a_dict = query_related(index_a_dict, lemma)\n",
    "    distances_b_dict = query_related(index_b_dict, lemma)\n",
    "    if distances_a_dict and distances_b_dict:\n",
    "        lemma_a_set = set(distances_a_dict.keys())\n",
    "        lemma_b_set = set(distances_b_dict.keys())\n",
    "        lemma_all = set()\n",
    "        for lemma_a in lemma_a_set:\n",
    "            if lemma_a not in lemma_b_set:\n",
    "                distances_b_dict[lemma_a] = query_cos_distance(index_b_dict, lemma, lemma_a)\n",
    "            lemma_all.add(lemma_a)\n",
    "        for lemma_b in lemma_b_set:\n",
    "            if lemma_b not in lemma_a_set:\n",
    "                distances_a_dict[lemma_b] = query_cos_distance(index_a_dict, lemma, lemma_b)\n",
    "            lemma_all.add(lemma_b)\n",
    "\n",
    "        # difference calculation\n",
    "        diff_total = 0\n",
    "        for lemma_related in lemma_all:\n",
    "            distance_a = distances_a_dict[lemma_related]\n",
    "            distance_b = distances_b_dict[lemma_related]\n",
    "            if distance_a and distance_b:\n",
    "                diff_total += abs(distance_a - distance_b)\n",
    "\n",
    "    return diff_total\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    print(create_diff_of_lemma(index_168_dict, index_169_dict, \"gehen\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2902c5-a731-451d-887b-dd07f55929d3",
   "metadata": {},
   "source": [
    "## create_diff_between_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70615ba-1a79-407e-a9b6-52546bfddb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff_between_indices(index_a_dict, index_b_dict):\n",
    "    diff_between_indices = {}\n",
    "    lemma_common = set(index_a_dict[\"lemma_to_id_dict\"].keys()) & set(index_b_dict[\"lemma_to_id_dict\"].keys())\n",
    "    for lemma in lemma_common:\n",
    "        diff = create_diff_of_lemma(index_a_dict, index_b_dict, lemma)\n",
    "        diff_between_indices[lemma] = diff\n",
    "    return diff_between_indices\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    diff_between_indices = create_diff_between_indices(index_168_dict, index_169_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1901039-411b-45ad-8aa0-41eac1a0fd4f",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e78ce-a6bd-42fb-b496-1585096be8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_global_word_set(model_list):\n",
    "    word_set = set()\n",
    "    for m in model_list:\n",
    "        for w in m.wv.index_to_key:\n",
    "            word_set.add(w)\n",
    "    return word_set\n",
    "\n",
    "\n",
    "word_set = create_global_word_set(list(model_dict.values()))\n",
    "len(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564b082-fa77-4339-8c2f-80cda66e5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_set_sample(word_set, model_list, limit, must_be_in_all_model):\n",
    "    word_set_sample = set()\n",
    "    num_found = 0\n",
    "    word_list_shuffled = list(word_set)\n",
    "    random.shuffle(word_list_shuffled)\n",
    "    for w in word_list_shuffled:\n",
    "        if num_found == limit:\n",
    "            break\n",
    "        else:\n",
    "            skip = False\n",
    "            if must_be_in_all_model:\n",
    "                for m in model_list:\n",
    "                    if w not in m.wv:\n",
    "                        skip = True\n",
    "                        break\n",
    "            if not skip:\n",
    "                word_set_sample.add(w)\n",
    "                num_found += 1\n",
    "    return word_set_sample\n",
    "\n",
    "\n",
    "word_set_sample = create_word_set_sample(word_set, list(model_dict.values()), 100, False)\n",
    "print(len(word_set_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dba35c-8a3f-4258-ba8c-b27b2bea334a",
   "metadata": {},
   "source": [
    "# analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51740582-1840-4ca2-b231-82992614c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184f18fa-b6c6-468b-834a-ed1ebc5a6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini_coefficient(x):\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    n = len(x)\n",
    "    x_sorted = np.sort(x)\n",
    "    cum_x = np.cumsum(x_sorted)\n",
    "    gini = (2 * np.sum((np.arange(1, n + 1) * x_sorted))) / (n * np.sum(x_sorted)) - (n + 1) / n\n",
    "    return gini\n",
    "\n",
    "\n",
    "calculate_gini_coefficient([1, 3, 2, 100, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f23f13-f929-4ef5-bac7-e66177abaa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_between_decades(w, model_prev, model_current, debug=False):\n",
    "    try:\n",
    "        v_prev = model_prev.wv[w]\n",
    "        v_current = model_current.wv[w]\n",
    "        word_set_top_10_prev = model_prev.wv.most_similar(w)\n",
    "        word_set_top_10_current = model_current.wv.most_similar(w)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    word_set_both = set()\n",
    "    for w_prev, _ in word_set_top_10_prev:\n",
    "        word_set_both.add(w_prev)\n",
    "    for w_current, _ in word_set_top_10_current:\n",
    "        word_set_both.add(w_current)\n",
    "\n",
    "    diff_per_decade = []\n",
    "    for w_rel in word_set_both:\n",
    "        try:\n",
    "            v_rel_prev = model_prev.wv[w_rel]\n",
    "            v_rel_current = model_current.wv[w_rel]\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            cos_sim_prev = calculate_cosine_similarity(v_prev, v_rel_prev)\n",
    "            cos_sim_current = calculate_cosine_similarity(v_current, v_rel_current)\n",
    "            diff_prev_current = abs(cos_sim_prev - cos_sim_current)\n",
    "            diff_per_decade.append(diff_prev_current)\n",
    "            if debug:\n",
    "                print(\n",
    "                    \"w_rel:\",\n",
    "                    w_rel,\n",
    "                    \"cos_sim_prev:\",\n",
    "                    cos_sim_prev,\n",
    "                    \"cos_sim_current:\",\n",
    "                    cos_sim_current,\n",
    "                    \"diff_prev_current:\",\n",
    "                    diff_prev_current,\n",
    "                )\n",
    "    if diff_per_decade:\n",
    "        diff_per_decade = sum(diff_per_decade) / len(diff_per_decade)\n",
    "\n",
    "        return diff_per_decade\n",
    "\n",
    "\n",
    "get_diff_between_decades(\"gesetze\", model_dict[178], model_dict[179], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e448b-4e30-4bb8-96c0-f1ca20b1cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relative_history(word_set, model_dict, print_progress=False):\n",
    "    len_total = len(word_set)\n",
    "    if print_progress:\n",
    "        len_segment = round(len_total / 100)\n",
    "        print(\"len_total:\", len_total)\n",
    "        print(\"len_segment:\", len_segment)\n",
    "    word_diff_history = {}\n",
    "    for i, w in enumerate(word_set):\n",
    "        if print_progress and i % len_segment == 0:\n",
    "            print(\"i:\", i)\n",
    "        model_prev = None\n",
    "        diff_between_decade_dict = {}\n",
    "        diff_between_decade_total = []\n",
    "        for decade, model_current in model_dict.items():\n",
    "            if model_prev:\n",
    "                diff_between_decade = get_diff_between_decades(w, model_prev, model_current)\n",
    "                if diff_between_decade:\n",
    "                    diff_between_decade_dict[str(decade) + \"0s\"] = diff_between_decade\n",
    "                    if 152 <= decade <= 191:\n",
    "                        diff_between_decade_total.append(diff_between_decade)\n",
    "            model_prev = model_current\n",
    "\n",
    "        if diff_between_decade_total:\n",
    "            diff_between_decade_avg = sum(diff_between_decade_total) / len(diff_between_decade_total)\n",
    "            diff_between_decade_gini = calculate_gini_coefficient(diff_between_decade_total)\n",
    "            word_diff_history[w] = {\n",
    "                \"diff_decade_avg\": diff_between_decade_avg,\n",
    "                \"diff_decade_gini\": diff_between_decade_gini,\n",
    "                \"diff_decade_dict\": diff_between_decade_dict,\n",
    "            }\n",
    "    return word_diff_history\n",
    "\n",
    "\n",
    "# word_diff_history = create_relative_history(word_set, model_dict, True)\n",
    "# word_diff_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000b21e-99ac-4e8b-a223-c3d9c8869ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/veld/output/word_diff_history.pkl\", \"wb\") as f:\n",
    "#    pickle.dump(word_diff_history, f)\n",
    "\n",
    "with open(\"/veld/output/word_diff_history.pkl\", \"rb\") as f:\n",
    "    word_diff_history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5222b91-ecab-4825-aa50-33eecfaa2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_diff_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590bb6e-a681-4370-aea2-182c05ee0e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_word_diff_history(word_diff_history, sort_key):\n",
    "    return dict(sorted(word_diff_history.items(), key=lambda item: -item[1][sort_key]))\n",
    "\n",
    "\n",
    "word_diff_history_sorted_avg = sort_word_diff_history(word_diff_history, \"diff_decade_avg\")\n",
    "word_diff_history_sorted_gini = sort_word_diff_history(word_diff_history, \"diff_decade_gini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f440a1-e142-4aed-8b36-ddd1bb1e9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, w_diff_history in enumerate(word_diff_history.items()):\n",
    "    if i == 3:\n",
    "        break\n",
    "    print(w_diff_history)\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "for i, w_diff_history in enumerate(word_diff_history_sorted_avg.items()):\n",
    "    if i == 3:\n",
    "        break\n",
    "    print(w_diff_history)\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "for i, w_diff_history in enumerate(word_diff_history_sorted_gini.items()):\n",
    "    if i == 3:\n",
    "        break\n",
    "    print(w_diff_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595b688-9587-40bc-ba1e-4b8cb9a27450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(\n",
    "    word_diff_history,\n",
    "    from_top,\n",
    "    min_num_decades,\n",
    "    max_sample,\n",
    "    index_range=None,\n",
    "    word_set=None,\n",
    "):\n",
    "    word_diff_history_sample = {}\n",
    "    if from_top:\n",
    "        direction = 1\n",
    "    else:\n",
    "        direction = -1\n",
    "    if index_range:\n",
    "        if not index_range[0]:\n",
    "            index_range[0] = 0\n",
    "        if not index_range[1]:\n",
    "            index_range[1] = len(word_diff_history)\n",
    "    num_found = 0\n",
    "    for i, w_history in enumerate(list(word_diff_history.items())[::direction]):\n",
    "        w = w_history[0]\n",
    "        w_diff = w_history[1]\n",
    "        if ((word_set and w in word_set) or not word_set) and ((index_range and index_range[0] <= i < index_range[1]) or not index_range):\n",
    "            if num_found == max_sample:\n",
    "                break\n",
    "            if (min_num_decades and len(w_diff[\"diff_decade_dict\"]) >= min_num_decades) or not min_num_decades:\n",
    "                word_diff_history_sample[w] = w_diff\n",
    "                num_found += 1\n",
    "    return word_diff_history_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a6c20-cd26-4e05-9afe-17d182e38e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sample(\n",
    "    word_diff_history_sorted_avg,\n",
    "    from_top=True,\n",
    "    min_num_decades=30,\n",
    "    max_sample=3,\n",
    "    index_range=[None, None],\n",
    "    word_set=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e395b-5458-48b3-a288-f5abe42713d2",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b46b1-6796-4e8c-82e6-2ea092025a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(word_diff_history):\n",
    "    decades = []\n",
    "    for d in range(1470, 1960, 10):\n",
    "        decades.append(str(d) + \"s\")\n",
    "    data = {}\n",
    "    for w, diff_history in word_diff_history.items():\n",
    "        data[w] = diff_history[\"diff_decade_dict\"]\n",
    "    df = pd.DataFrame(data).reindex(decades).reset_index()\n",
    "    df = df.rename(columns={\"index\": \"Decade\"})\n",
    "    fig = go.Figure()\n",
    "    for category in data.keys():\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df[\"Decade\"],\n",
    "                y=df[category],\n",
    "                mode=\"lines+markers\",\n",
    "                name=category,\n",
    "                connectgaps=True,  # Ensures lines are drawn across missing data\n",
    "            )\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        title=\"Data points by decade\",\n",
    "        xaxis_title=\"Decades\",\n",
    "        yaxis_title=\"Value\",\n",
    "        xaxis=dict(categoryorder=\"array\", categoryarray=decades),\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714da9c9-1673-4ad1-8315-b46cc7bb3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot_tsne(vector_dict, title=None):\n",
    "\n",
    "    labels = []\n",
    "    values = []\n",
    "    for w in WORD_LIST:\n",
    "        labels.append(w)\n",
    "        values.append(vector_dict[w])\n",
    "    values = np.array(values)\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "    reduced_vectors_tsne = tsne.fit_transform(values)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(reduced_vectors_tsne[:, 0], reduced_vectors_tsne[:, 1], c=\"blue\", alpha=0.7)\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.text(\n",
    "            reduced_vectors_tsne[i, 0],\n",
    "            reduced_vectors_tsne[i, 1],\n",
    "            label,\n",
    "            fontsize=9,\n",
    "            ha=\"right\",\n",
    "            color=\"black\",\n",
    "        )\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c858e1-4898-4a7b-b5fa-4e03b966180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(\n",
    "    get_sample(\n",
    "        word_diff_history_sorted_avg,\n",
    "        from_top=True,\n",
    "        min_num_decades=30,\n",
    "        max_sample=3,\n",
    "        index_range=[9000, None],\n",
    "        word_set=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22893874-abfe-4ac3-a805-9c8544ce0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(\n",
    "    get_sample(\n",
    "        word_diff_history_sorted_gini,\n",
    "        from_top=True,\n",
    "        min_num_decades=30,\n",
    "        max_sample=3,\n",
    "        index_range=[10000, None],\n",
    "        word_set=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7339f55-73c1-4dc6-9dc3-3c62d0b19644",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=30,\n",
    "        max_sample=3,\n",
    "        index_range=[1200, None],\n",
    "        word_set=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6c72b-9bd5-458b-be99-2ef426b30f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=30,\n",
    "        num_sample=3,\n",
    "        index_range=[2000, None],\n",
    "        word_set=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef058173-696e-4d88-930a-102a89d9ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=30,\n",
    "        num_sample=3,\n",
    "        index_range=[10000, None],\n",
    "        word_set=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e510dd-f95f-4988-ac3e-63d7ca82d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=False,\n",
    "        min_num_decades=30,\n",
    "        num_sample=3,\n",
    "        index_range=[None, None],\n",
    "        word_set=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ebc36-282d-4330-be40-4986fb639d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=False,\n",
    "        min_num_decades=10,\n",
    "        num_sample=3,\n",
    "        index_range=[40000, None],\n",
    "        word_set=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c098a8-7302-41e9-b609-8a3bc141309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in word_relative_history_list:\n",
    "    if w[0] in [\"dar\", \"sollst\"]:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d735b-6ce0-46cf-8e35-ce2d2a032f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=30,\n",
    "        num_sample=3,\n",
    "        index_range=[None, None],\n",
    "        word_set=[\"gesetz\", \"himmel\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a8853-238d-4eaf-b0fa-51c6477736c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=None,\n",
    "        num_sample=3,\n",
    "        index_range=[None, None],\n",
    "        word_set=[\"demokratie\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32565c9-d9c8-4133-be55-8dab3345bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=None,\n",
    "        num_sample=3,\n",
    "        index_range=[None, None],\n",
    "        word_set=[\"frau\", \"mann\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34983f1a-c03a-4f0a-a829-4eeecab676de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=None,\n",
    "        num_sample=3,\n",
    "        index_range=[None, None],\n",
    "        word_set=[\"mutter\", \"vater\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94c1c6-ef35-4ae3-8ea6-bf92928aa931",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=None,\n",
    "        num_sample=3,\n",
    "        index_range=[None, None],\n",
    "        word_set=[\"k√∂nig\", \"kaiser\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1da5f9-e988-47e5-874b-98660d99211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=None,\n",
    "        num_sample=4,\n",
    "        index_range=[None, None],\n",
    "        word_set=[\"wasser\", \"erde\", \"brot\", \"haus\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848ce1e-cf04-4516-9aaa-3329e23cb31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=None,\n",
    "        num_sample=10,\n",
    "        index_range=[None, None],\n",
    "        word_set=[\"haus\", \"kaiser\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897aa4af-abbe-421b-aeb6-a765f5f05486",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list,\n",
    "        from_top=True,\n",
    "        min_num_decades=None,\n",
    "        num_sample=10,\n",
    "        index_range=[None, None],\n",
    "        word_set=[\"mensch\", \"gott\", \"welt\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e3365-6124-4459-8db2-c65658f56026",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    get_cos_sim_sample(\n",
    "        word_relative_history_list_gini,\n",
    "        from_top=True,\n",
    "        min_num_decades=20,\n",
    "        num_sample=5,\n",
    "        index_range=[None, None],\n",
    "        word_set=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6733b0-65d4-40d6-8fc2-5e5c94c5c67f",
   "metadata": {},
   "source": [
    "# various snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2e9d2-7d00-4c5c-b4eb-af255e408422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "import numpy as np\n",
    "\n",
    "# Your data\n",
    "texts = [\"apple\", \"banana\", \"orange\"]\n",
    "vectors = np.random.rand(3, 128).astype(\"float32\")\n",
    "vectors /= np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "\n",
    "# Map text labels to integer IDs\n",
    "text_to_id = {text: i for i, text in enumerate(texts)}\n",
    "id_to_text = {i: text for text, i in text_to_id.items()}\n",
    "\n",
    "# Initialize the index\n",
    "dim = 128\n",
    "index = hnswlib.Index(space=\"cosine\", dim=dim)\n",
    "index.init_index(max_elements=10, ef_construction=100, M=16)\n",
    "index.add_items(vectors, ids=list(text_to_id.values()))\n",
    "\n",
    "# Query\n",
    "query_vector = vectors[0].reshape(1, -1)\n",
    "labels, distances = index.knn_query(query_vector, k=2)\n",
    "\n",
    "# Convert back to text labels\n",
    "results = [(id_to_text[label], dist) for label, dist in zip(labels[0], distances[0])]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306d5e3-0127-4789-8dd2-89718aaa6269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: probably not useful\n",
    "def create_word_cos_sim_history_list(word_set, model_dict):\n",
    "    word_cos_sim_history_list = []\n",
    "    for w in word_set:\n",
    "        cos_sim_history_dict = {}\n",
    "        model_prev = None\n",
    "        w_vec_current = None\n",
    "        w_vec_prev = None\n",
    "        total_diff = 0\n",
    "        for decade, model_current in model_dict.items():\n",
    "            try:\n",
    "                w_vec_current = model_current.wv[w]\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                if w_vec_prev is not None:\n",
    "                    cos_sim = calculate_cosine_similarity(w_vec_prev, w_vec_current)\n",
    "                    total_diff += 2 - (cos_sim + 1)\n",
    "                    cos_sim_history_dict[str(decade) + \"0s\"] = cos_sim\n",
    "                w_vec_prev = w_vec_current\n",
    "        if cos_sim_history_dict:\n",
    "            word_cos_sim_history_list.append((w, total_diff, cos_sim_history_dict))\n",
    "    word_cos_sim_history_list = sorted(word_cos_sim_history_list, key=lambda x: -x[1])\n",
    "    return word_cos_sim_history_list\n",
    "\n",
    "\n",
    "# word_cos_sim_history_list = create_word_cos_sim_history_list(word_set, model_dict)\n",
    "# print(len(word_cos_sim_history_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932a747-0393-4950-8efd-9e99cbe111ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define the full range of decades\n",
    "decades = [f\"{1900+10*i}s\" for i in range(10)]  # 1900s to 2000s\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"a\": {\"1920s\": 0.6, \"1930s\": 0.5, \"1980s\": 0.1},\n",
    "    \"b\": {\"1930s\": 0.2, \"1980s\": 0.4},\n",
    "}\n",
    "\n",
    "# Convert to DataFrame with explicit ordering\n",
    "df = pd.DataFrame(data).reindex(decades).reset_index()\n",
    "df = df.rename(columns={\"index\": \"Decade\"})\n",
    "\n",
    "# Create the plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for category in data.keys():\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[\"Decade\"],\n",
    "            y=df[category],\n",
    "            mode=\"lines+markers\",\n",
    "            name=category,\n",
    "            connectgaps=True,  # Ensures lines are drawn across missing data\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Format the layout\n",
    "fig.update_layout(\n",
    "    title=\"Data points by decade\",\n",
    "    xaxis_title=\"Decades\",\n",
    "    yaxis_title=\"Value\",\n",
    "    xaxis=dict(categoryorder=\"array\", categoryarray=decades),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef6ebb-a05c-418b-83e4-6f0cd2483d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"a\": {\"1920s\": 1, \"1930s\": 0.5, \"1980s\": 0.1},\n",
    "    \"b\": {\"1930s\": 0.2, \"1940s\": 0, \"1950s\": 0.7, \"1980s\": 0.4},\n",
    "}\n",
    "\n",
    "# Define all decades (ensuring consistent x-axis)\n",
    "decades = [f\"{1900 + 10*i}s\" for i in range(10)]\n",
    "\n",
    "# Plot each ID\n",
    "plt.figure(figsize=(10, 5))\n",
    "for identifier, values in data.items():\n",
    "    y_values = [values.get(decade, None) for decade in decades]  # Use None for missing data\n",
    "    plt.plot(decades, y_values, marker=\"o\", label=identifier)\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel(\"Decades\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Data points by decade\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ac837-d39b-4ffd-8df6-39521490dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"a\": {\"1920s\": 1, \"1930s\": 0.5, \"1980s\": 0.1},\n",
    "    \"b\": {\"1930s\": 0.2, \"1950s\": 0.8, \"1980s\": 0.4},\n",
    "}\n",
    "\n",
    "# Define all decades (ensuring consistent x-axis)\n",
    "decades = [f\"{1900 + 10*i}s\" for i in range(10)]\n",
    "\n",
    "# Plot each ID\n",
    "plt.figure(figsize=(10, 5))\n",
    "for identifier, values in data.items():\n",
    "    y_values = [values.get(decade, np.nan) for decade in decades]  # Use np.nan to avoid connecting missing points\n",
    "    plt.plot(decades, y_values, marker=\"o\", label=identifier)\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel(\"Decades\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Data points by decade\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891147e3-7c00-48b7-9a73-791aded94d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"a\": {\"1920s\": 1, \"1930s\": 0.5, \"1980s\": 0.1},\n",
    "    \"b\": {\"1930s\": 0.2, \"1950s\": 0.8, \"1980s\": 0.4},\n",
    "}\n",
    "\n",
    "# Define all decades (ensuring consistent x-axis)\n",
    "decades = [f\"{1900 + 10*i}s\" for i in range(10)]\n",
    "\n",
    "# Convert to a DataFrame for interpolation\n",
    "df = pd.DataFrame({key: {d: data[key].get(d, np.nan) for d in decades} for key in data})\n",
    "\n",
    "# Interpolate missing values (linear interpolation)\n",
    "df.interpolate(method=\"linear\", inplace=True)\n",
    "\n",
    "# Plot each ID\n",
    "plt.figure(figsize=(10, 5))\n",
    "for identifier in df.columns:\n",
    "    plt.plot(decades, df[identifier], marker=\"o\", label=identifier)\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel(\"Decades\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Data points by decade (with interpolation)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0417801-7682-4af3-ba54-e5df6fdbde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3346ed0-7322-4b92-a238-ae0ddbab5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"Decade\": [\"1920s\", \"1930s\", \"1980s\", \"1930s\", \"1950s\", \"1980s\"],\n",
    "    \"Value\": [1, 0.5, 0.1, 0.2, 0.8, None],\n",
    "    \"Category\": [\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plot using Plotly Express\n",
    "fig = px.line(\n",
    "    df,\n",
    "    x=\"Decade\",\n",
    "    y=\"Value\",\n",
    "    color=\"Category\",\n",
    "    markers=True,\n",
    "    title=\"Data points by decade\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fface3c-db05-4dce-a67d-989fa4d5555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_cosine_similarity(model_dict[180].wv[\"mann\"], model_dict[180].wv[\"mann\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8159f0e-3a99-4ef3-9bfa-ea579c339de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[180].wv.most_similar(\"mann\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106baaa6-bc50-4779-b630-081e491fee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[181].wv.most_similar(\"mann\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86932a-4c32-4538-a978-0f5e1288513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract vocabulary and corresponding vectors\n",
    "words = list(model.wv.index_to_key)[:100]  # List of words in vocabulary\n",
    "vectors = np.array([model.wv[word] for word in words])  # Word vectors\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(vectors)\n",
    "\n",
    "# Convert to a dictionary of word pairs (optional)\n",
    "similarity_dict = {(words[i], words[j]): similarity_matrix[i, j] for i in range(len(words)) for j in range(len(words)) if i != j}\n",
    "\n",
    "# Example: Print top 10 most similar word pairs\n",
    "sorted_pairs = sorted(similarity_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for pair, sim in sorted_pairs[:10]:\n",
    "    print(f\"{pair}: {sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9531e0-fa23-42c4-b3af-e45a5f8fd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964175a4-799e-4622-821d-fe82e01db546",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402296b-fcfa-4349-8b16-4759ba466aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a dictionary of word pairs (optional)\n",
    "similarity_dict = {(words[i], words[j]): similarity_matrix[i, j] for i in range(len(words)) for j in range(len(words)) if i != j}\n",
    "\n",
    "# Example: Print top 10 most similar word pairs\n",
    "sorted_pairs = sorted(similarity_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for pair, sim in sorted_pairs:\n",
    "    print(f\"{pair}: {sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e36a4-c2b2-49e3-ae3b-bdc36a4401dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
