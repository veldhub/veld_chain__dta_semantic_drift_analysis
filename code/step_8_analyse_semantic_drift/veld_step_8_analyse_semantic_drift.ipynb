{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a2e1c5-aa05-466b-be11-b422da4f7c25",
   "metadata": {},
   "source": [
    "# modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b395f2c-139d-4563-9eee-492057582cb8",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535e21a-6c2f-44d9-aa28-faa91de14ad7",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1d90b-4a93-4b63-b22d-a20fa107c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "from typing import TypeAlias\n",
    "\n",
    "import hnswlib\n",
    "import hunspell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d4d4c-74af-408e-90e7-431639f319d9",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f6dec-d63a-4c18-8806-59186587fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_TEST = True\n",
    "\n",
    "MODELS_WORD2VEC_FOLDER = \"/veld/input/models/\"\n",
    "TEXTS_FOLDER = \"/veld/input/texts/\"\n",
    "CACHE_FOLDER = \"/veld/storage/cache/\"\n",
    "\n",
    "INDEX_EF_CONSTRUCTION = 100\n",
    "INDEX_M = 16\n",
    "\n",
    "PLOT_SLEEP = 2\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "hunspell_check = hunspell.HunSpell(\"/usr/share/hunspell/de_DE.dic\", \"/usr/share/hunspell/de_DE.aff\")\n",
    "random.seed(42)\n",
    "pio.renderers.default = \"iframe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e02a5-9c4c-49c9-a2a3-260a790b2496",
   "metadata": {},
   "source": [
    "## helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d7ac89-0553-42ea-9b19-b7a7f7210536",
   "metadata": {},
   "source": [
    "### pickle_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db34eb54-8a16-4e59-bfcf-7a9ddab21448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_save(data, file):\n",
    "    pickle_path = CACHE_FOLDER + file + \".pkl\"\n",
    "    with open(pickle_path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "        print(\"pickle_save: persisted into cache at:\", pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a145a7-ead0-40f1-bdc7-9bb3350bc552",
   "metadata": {},
   "source": [
    "### pickle_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c0841-e083-4a20-bce6-b6a15ee1d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_load(file):\n",
    "    pickle_path = CACHE_FOLDER + file + \".pkl\"\n",
    "    with open(pickle_path, \"rb\") as f:\n",
    "        result = pickle.load(f)\n",
    "        print(\"pickle_load: loaded from cache at:\", pickle_path)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8120ca6-8912-4638-a6aa-fe8ff36b5b97",
   "metadata": {},
   "source": [
    "### load_cache_or_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf56699-7b77-4460-96ad-666717e93840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache_or_run(func):\n",
    "    pickle_file = func.__name__\n",
    "    if os.path.exists(CACHE_FOLDER + pickle_file + \".pkl\"):\n",
    "        result = pickle_load(pickle_file)\n",
    "    else:\n",
    "        result = func()\n",
    "        pickle_save(result, pickle_file)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520512ab-dc8f-44cc-adf0-ddc4dcf8e5cd",
   "metadata": {},
   "source": [
    "### is_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243c2ea-3957-459e-8f14-c71742bef448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word(word):\n",
    "    try:\n",
    "        _ = int(word)\n",
    "    except:\n",
    "        if len(word) == 1:\n",
    "            return False\n",
    "        else:\n",
    "            return hunspell_check.spell(word)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13721081-b7d7-44c9-ab0e-bb2c07f649bd",
   "metadata": {},
   "source": [
    "## data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc305687-3bc1-4e75-9b65-83220404eaee",
   "metadata": {},
   "source": [
    "### tpye aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80f266-a429-4f85-9d63-f7d2b62cc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lemma: TypeAlias = str\n",
    "Word: TypeAlias = str\n",
    "Decade: TypeAlias = int\n",
    "LineNumber: TypeAlias = int\n",
    "WordNumber: TypeAlias = int\n",
    "OccurrenceCount: TypeAlias = int\n",
    "Diff: TypeAlias = float\n",
    "Trajectory: TypeAlias = float\n",
    "CosSim: TypeAlias = float\n",
    "DecadesStr: TypeAlias = str  # spans three decades, e.g. \"174-176\"\n",
    "Embedding: TypeAlias = np.ndarray\n",
    "Model: TypeAlias = Word2Vec\n",
    "DecadeList: TypeAlias = list[Decade]\n",
    "\n",
    "# lemma data structures\n",
    "LemmaDiffDict: TypeAlias = dict[Lemma, Diff]\n",
    "LemmaTrajectoryDict: TypeAlias = dict[Lemma, Trajectory]\n",
    "LineNumberDict: TypeAlias = dict[LineNumber, list[WordNumber]]\n",
    "LemmaOccurrencePositionDict: TypeAlias = dict[Lemma, LineNumberDict]\n",
    "LemmaOccurrenceCountDict: TypeAlias = dict[Lemma, OccurrenceCount]\n",
    "LemmaWordDict: TypeAlias = dict[Lemma, list[Word]]\n",
    "WordLemmaDict: TypeAlias = dict[Word, Lemma]\n",
    "\n",
    "# index data structure\n",
    "IdToLemmaDict: TypeAlias = dict[int, Lemma]\n",
    "LemmaToIdDict: TypeAlias = dict[Lemma, int]\n",
    "Index: TypeAlias = tuple[hnswlib.Index, LemmaToIdDict, IdToLemmaDict]\n",
    "\n",
    "DecadeData: TypeAlias = list[Index, WordLemmaDict, LemmaWordDict, LemmaOccurrenceCountDict, LemmaOccurrencePositionDict, Decade]\n",
    "DecadeDict: TypeAlias = dict[Decade, DecadeData]\n",
    "LemmaDecadeDiffDict: TypeAlias = dict[Lemma, dict[DecadesStr, Diff]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58044656-cc17-4f9f-8959-2697f02436ee",
   "metadata": {},
   "source": [
    "### create_decades_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc419e9c-6232-421a-9863-fe087ed40e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decades_list(decade_start: int = 155, decade_end: int = 191) -> DecadeList:\n",
    "    decade_list = []\n",
    "    for model_file in os.listdir(MODELS_WORD2VEC_FOLDER):\n",
    "        if model_file.endswith(\".bin\"):\n",
    "            decade = int(model_file.split(\".bin\")[0])\n",
    "            decade_list.append(decade)\n",
    "    decade_list = sorted(decade_list)\n",
    "    i_start = 0\n",
    "    i_end = len(decade_list)\n",
    "    for i, decade in enumerate(decade_list):\n",
    "        if decade_start and decade_start == decade:\n",
    "            i_start = i\n",
    "        if decade_end and decade_end == decade:\n",
    "            i_end = i + 1\n",
    "    decade_list = decade_list[i_start:i_end]\n",
    "    print(\"create_decades_list: decade_list:\", decade_list)\n",
    "    return decade_list\n",
    "\n",
    "\n",
    "def create_decades_list_test():\n",
    "    return create_decades_list(decade_start=165, decade_end=175)\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    decade_list = load_cache_or_run(create_decades_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39ab93-0e45-43ca-a6dc-e80596674e4f",
   "metadata": {},
   "source": [
    "### load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f0f7b-69bf-4a35-bca8-8ed00501fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(decade: Decade) -> Model:\n",
    "    model_path = MODELS_WORD2VEC_FOLDER + str(decade) + \".bin\"\n",
    "    model = Word2Vec.load(model_path)\n",
    "    print(\"load_model_word2vec: model_path:\", model_path)\n",
    "    print(\"load_model_word2vec: model:\", model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_test():\n",
    "    model_174 = load_model(174)\n",
    "    model_175 = load_model(175)\n",
    "    model_176 = load_model(176)\n",
    "    return model_174, model_175, model_176\n",
    "\n",
    "\n",
    "model_174, model_175, model_176 = load_cache_or_run(load_model_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb75d6-b481-45a9-93d5-51abc7f9b2f0",
   "metadata": {},
   "source": [
    "### create_lemma_word_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c04cb-9e25-4933-95da-597525cc92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lemma_word_dicts(model: Model) -> tuple[LemmaWordDict, WordLemmaDict]:\n",
    "    word_lemma_dict = {}\n",
    "    lemma_word_dict = {}\n",
    "    for word in model.wv.index_to_key:\n",
    "        lemma = nlp(word)[0].lemma_\n",
    "        word_list = lemma_word_dict.get(lemma, [])\n",
    "        word_list.append(word)\n",
    "        lemma_word_dict[lemma] = word_list\n",
    "        word_lemma_dict[word] = lemma\n",
    "    print(\"create_lemma_word_dicts: len(lemma_word_dict):\", len(lemma_word_dict))\n",
    "    return lemma_word_dict, word_lemma_dict\n",
    "\n",
    "\n",
    "def create_lemma_word_dicts_test():\n",
    "    lemma_word_dict_174, word_lemma_dict_174 = create_lemma_word_dicts(model_174)\n",
    "    lemma_word_dict_175, word_lemma_dict_175 = create_lemma_word_dicts(model_175)\n",
    "    lemma_word_dict_176, word_lemma_dict_176 = create_lemma_word_dicts(model_176)\n",
    "    return lemma_word_dict_174, word_lemma_dict_174, lemma_word_dict_175, word_lemma_dict_175, lemma_word_dict_176, word_lemma_dict_176\n",
    "\n",
    "\n",
    "lemma_word_dict_174, word_lemma_dict_174, lemma_word_dict_175, word_lemma_dict_175, lemma_word_dict_176, word_lemma_dict_176 = (\n",
    "    load_cache_or_run(create_lemma_word_dicts_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf229bb-96cd-432a-9b93-f5558adf263e",
   "metadata": {},
   "source": [
    "### create_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a8a67-0e81-4437-b884-73477a6530bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(lemma_word_dict: LemmaWordDict, model: Model) -> Index:\n",
    "    id_to_lemma_dict: IdToLemmaDict = {}\n",
    "    lemma_to_id_dict: LemmaToIdDict = {}\n",
    "    embedding_array = []\n",
    "    for lemma_id, (lemma, word_list) in enumerate(lemma_word_dict.items()):\n",
    "        id_to_lemma_dict[lemma_id] = lemma\n",
    "        lemma_to_id_dict[lemma] = lemma_id\n",
    "        word_embedding_list = [model.wv[word] for word in word_list]\n",
    "        embedding_average = np.mean(np.array(word_embedding_list), axis=0)\n",
    "        embedding_normalized = embedding_average / np.linalg.norm(embedding_average)\n",
    "        embedding_array.append(embedding_normalized)\n",
    "    embedding_array = np.array(embedding_array)\n",
    "    max_elements = len(embedding_array)\n",
    "    dim = embedding_array[0].shape[0]\n",
    "    hnsw_index = hnswlib.Index(space=\"cosine\", dim=dim)\n",
    "    hnsw_index.init_index(max_elements=max_elements, ef_construction=INDEX_EF_CONSTRUCTION, M=INDEX_M)\n",
    "    hnsw_index.add_items(embedding_array, ids=list(id_to_lemma_dict.keys()))\n",
    "    index = (hnsw_index, lemma_to_id_dict, id_to_lemma_dict)\n",
    "    print(\"create_lemma_dict_and_index: hnsw_index.get_current_count:\", hnsw_index.get_current_count())\n",
    "    return index\n",
    "\n",
    "\n",
    "def create_index_test():\n",
    "    index_174 = create_index(lemma_word_dict_174, model_174)\n",
    "    index_175 = create_index(lemma_word_dict_175, model_175)\n",
    "    index_176 = create_index(lemma_word_dict_176, model_176)\n",
    "    return index_174, index_175, index_176\n",
    "\n",
    "\n",
    "index_174, index_175, index_176 = load_cache_or_run(create_index_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744e237-c5e4-4e89-aa23-97bc1c9fedb8",
   "metadata": {},
   "source": [
    "### create_occurrence_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cce9fe-b5c7-46f9-af1e-249438285932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_occurrence_dicts(decade: Decade, word_lemma_dict: WordLemmaDict) -> tuple[LemmaOccurrencePositionDict, LemmaOccurrenceCountDict]:\n",
    "    lemma_occurrence_position_dict = {}\n",
    "    lemma_occurrence_count_dict = {}\n",
    "    total_occurrence_count = 0\n",
    "    with open(TEXTS_FOLDER + str(decade) + \".txt\", \"r\") as f:\n",
    "        for line_number, line in enumerate(f):\n",
    "            for word_number, word in enumerate(line.rstrip(\"\\n\").split(\" \")):\n",
    "                lemma = word_lemma_dict.get(word)\n",
    "                if lemma:\n",
    "                    line_number_dict: LineNumberDict = lemma_occurrence_position_dict.get(lemma, {})\n",
    "                    word_number_list: list[WordNumber] = line_number_dict.get(line_number, [])\n",
    "                    word_number_list.append(word_number)\n",
    "                    line_number_dict[line_number] = word_number_list\n",
    "                    lemma_occurrence_position_dict[lemma] = line_number_dict\n",
    "                    occurrence_count = lemma_occurrence_count_dict.get(lemma, 0)\n",
    "                    lemma_occurrence_count_dict[lemma] = occurrence_count + 1\n",
    "                    total_occurrence_count += 1\n",
    "    lemma_count = len(lemma_occurrence_count_dict)\n",
    "    occurrence_avg = total_occurrence_count / lemma_count\n",
    "    median_pos = int(lemma_count / 2)\n",
    "    occurrence_median = list(lemma_occurrence_count_dict.values())[median_pos]\n",
    "    print(\"create_occurrence_dicts: lemma_count:\", lemma_count)\n",
    "    print(\"create_occurrence_dicts: total_occurrence_count:\", total_occurrence_count)\n",
    "    print(\"create_occurrence_dicts: occurrence_avg:\", occurrence_avg)\n",
    "    print(\"create_occurrence_dicts: occurrence_median:\", occurrence_median)\n",
    "    return lemma_occurrence_position_dict, lemma_occurrence_count_dict\n",
    "\n",
    "\n",
    "def create_occurrence_dicts_test():\n",
    "    lemma_occurrence_position_dict_174, lemma_occurrence_count_dict_174 = create_occurrence_dicts(174, word_lemma_dict_174)\n",
    "    lemma_occurrence_position_dict_175, lemma_occurrence_count_dict_175 = create_occurrence_dicts(175, word_lemma_dict_175)\n",
    "    lemma_occurrence_position_dict_176, lemma_occurrence_count_dict_176 = create_occurrence_dicts(176, word_lemma_dict_176)\n",
    "    return (\n",
    "        lemma_occurrence_position_dict_174,\n",
    "        lemma_occurrence_count_dict_174,\n",
    "        lemma_occurrence_position_dict_175,\n",
    "        lemma_occurrence_count_dict_175,\n",
    "        lemma_occurrence_position_dict_176,\n",
    "        lemma_occurrence_count_dict_176,\n",
    "    )\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    (\n",
    "        lemma_occurrence_position_dict_174,\n",
    "        lemma_occurrence_count_dict_174,\n",
    "        lemma_occurrence_position_dict_175,\n",
    "        lemma_occurrence_count_dict_175,\n",
    "        lemma_occurrence_position_dict_176,\n",
    "        lemma_occurrence_count_dict_176,\n",
    "    ) = load_cache_or_run(create_occurrence_dicts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec0c8c-8531-49fe-9661-62bd389e96df",
   "metadata": {},
   "source": [
    "### sort_lemma_dict_by_value_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe2804-6089-40f0-a78c-8bba6225eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_lemma_dict_by_value_to_list(lemma_dict: dict[Lemma, int | float], desc=True) -> list[Lemma]:\n",
    "    if desc:\n",
    "        sort_mod = -1\n",
    "    else:\n",
    "        sort_mod = 1\n",
    "    lemma_list_sorted = [(lemma, value) for lemma, value in lemma_dict.items()]\n",
    "    lemma_list_sorted = [l[0] for l in sorted(lemma_list_sorted, key=lambda x: sort_mod * x[1])]\n",
    "    print(\"sort_lemma_occurrence_count_dict: len(lemma_list_sorted):\", len(lemma_list_sorted))\n",
    "    return lemma_list_sorted\n",
    "\n",
    "\n",
    "def sort_lemma_dict_by_value_to_list_test():\n",
    "    lemma_list_sorted_174 = sort_lemma_dict_by_value_to_list(lemma_occurrence_count_dict_174)\n",
    "    lemma_list_sorted_175 = sort_lemma_dict_by_value_to_list(lemma_occurrence_count_dict_175)\n",
    "    lemma_list_sorted_176 = sort_lemma_dict_by_value_to_list(lemma_occurrence_count_dict_176)\n",
    "    return lemma_list_sorted_174, lemma_list_sorted_175, lemma_list_sorted_176\n",
    "\n",
    "\n",
    "lemma_list_sorted_174, lemma_list_sorted_175, lemma_list_sorted_176 = load_cache_or_run(sort_lemma_dict_by_value_to_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6990ae4-568c-4dcf-a24d-436cf14d0015",
   "metadata": {},
   "source": [
    "### sort_lemma_dict_by_value_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f66d94-438d-48ef-88a0-b7e97a42a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_lemma_dict_by_value_to_dict(lemma_dict: dict[Lemma, int | float], desc=True) -> dict:\n",
    "    lemma_list_sorted = sort_lemma_dict_by_value_to_list(lemma_dict, desc)\n",
    "    lemma_dict_new = {}\n",
    "    for lemma in lemma_list_sorted:\n",
    "        lemma_dict_new[lemma] = lemma_dict[lemma]\n",
    "    return lemma_dict_new\n",
    "\n",
    "\n",
    "def sort_lemma_dict_by_value_to_dict_test():\n",
    "    global lemma_occurrence_count_dict_174\n",
    "    global lemma_occurrence_count_dict_175\n",
    "    global lemma_occurrence_count_dict_176\n",
    "    lemma_occurrence_count_dict_174 = sort_lemma_dict_by_value_to_dict(lemma_occurrence_count_dict_174)\n",
    "    lemma_occurrence_count_dict_175 = sort_lemma_dict_by_value_to_dict(lemma_occurrence_count_dict_175)\n",
    "    lemma_occurrence_count_dict_176 = sort_lemma_dict_by_value_to_dict(lemma_occurrence_count_dict_176)\n",
    "    return lemma_occurrence_count_dict_174, lemma_occurrence_count_dict_175, lemma_occurrence_count_dict_176\n",
    "\n",
    "\n",
    "lemma_occurrence_count_dict_174, lemma_occurrence_count_dict_175, lemma_occurrence_count_dict_176 = load_cache_or_run(\n",
    "    sort_lemma_dict_by_value_to_dict_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc95c7-4a21-4758-9d1c-bbdc946476c4",
   "metadata": {},
   "source": [
    "### sort_by_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b87c75-7995-4772-8b3d-bb6ae707844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_occurrence(lemma_list_sorted: list[Lemma], sortable_lemma_dict: dict) -> dict:\n",
    "    sortable_lemma_dict_new = {}\n",
    "    for lemma in lemma_list_sorted:\n",
    "        sortable_lemma_dict_new[lemma] = sortable_lemma_dict[lemma]\n",
    "    print(\"sort_by_occurrence: len(sortable_lemma_dict_new):\", len(sortable_lemma_dict_new))\n",
    "    return sortable_lemma_dict_new\n",
    "\n",
    "\n",
    "def sort_by_occurrence_test():\n",
    "    global lemma_occurrence_position_dict_174\n",
    "    global lemma_occurrence_position_dict_175\n",
    "    global lemma_occurrence_position_dict_176\n",
    "    global lemma_word_dict_174\n",
    "    global lemma_word_dict_175\n",
    "    global lemma_word_dict_176\n",
    "    lemma_occurrence_position_dict_174 = sort_by_occurrence(lemma_list_sorted_174, lemma_occurrence_position_dict_174)\n",
    "    lemma_occurrence_position_dict_175 = sort_by_occurrence(lemma_list_sorted_175, lemma_occurrence_position_dict_175)\n",
    "    lemma_occurrence_position_dict_176 = sort_by_occurrence(lemma_list_sorted_176, lemma_occurrence_position_dict_176)\n",
    "    lemma_word_dict_174 = sort_by_occurrence(lemma_list_sorted_174, lemma_word_dict_174)\n",
    "    lemma_word_dict_175 = sort_by_occurrence(lemma_list_sorted_175, lemma_word_dict_175)\n",
    "    lemma_word_dict_176 = sort_by_occurrence(lemma_list_sorted_176, lemma_word_dict_176)\n",
    "    return (\n",
    "        lemma_occurrence_position_dict_174,\n",
    "        lemma_occurrence_position_dict_175,\n",
    "        lemma_occurrence_position_dict_176,\n",
    "        lemma_word_dict_174,\n",
    "        lemma_word_dict_175,\n",
    "        lemma_word_dict_176,\n",
    "    )\n",
    "\n",
    "\n",
    "(\n",
    "    lemma_occurrence_position_dict_174,\n",
    "    lemma_occurrence_position_dict_175,\n",
    "    lemma_occurrence_position_dict_176,\n",
    "    lemma_word_dict_174,\n",
    "    lemma_word_dict_175,\n",
    "    lemma_word_dict_176,\n",
    ") = load_cache_or_run(sort_by_occurrence_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bef6a1-10d1-425e-9dd1-9ff8acc78734",
   "metadata": {},
   "source": [
    "### get_common_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5a1dd-70ac-4a5e-848a-d3dc3d496d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_lemma(*lemma_dict_list):\n",
    "    lemma_set_list = []\n",
    "    for lemma_dict in lemma_dict_list:\n",
    "        lemma_set_list.append(set(lemma_dict.keys()))\n",
    "    return set.intersection(*lemma_set_list)\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    print(get_common_lemma({\"a\": 1, \"b\": 2}, {\"a\": 1, \"c\": 3}, {\"a\": 1, \"b\": 2, \"c\": 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7a697-a6ec-4259-a377-10d6dbf05914",
   "metadata": {},
   "source": [
    "### get_occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ae976-660d-4166-9300-9edf60e010ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurrences(\n",
    "    decade: Decade,\n",
    "    line_number_dict: LineNumberDict,\n",
    "    max_elem: int = None,\n",
    "    highlight_lemma: bool = True,\n",
    "    keep_lemma: bool = True,\n",
    ") -> list[str]:\n",
    "    text_list = []\n",
    "    with open(TEXTS_FOLDER + str(decade) + \".txt\", \"r\") as f:\n",
    "        num_print = 0\n",
    "        for line_number, line in enumerate(f):\n",
    "            word_number_list = line_number_dict.get(line_number)\n",
    "            if word_number_list:\n",
    "                word_number_set = set(word_number_list)\n",
    "                text = \"\"\n",
    "                for word_number, word in enumerate(line.rstrip(\"\\n\").split(\" \")):\n",
    "                    if word_number in word_number_set and highlight_lemma and keep_lemma:\n",
    "                        text += \" ### \" + word + \" ###\"\n",
    "                    elif word_number not in word_number_set or (not highlight_lemma and keep_lemma):\n",
    "                        text += \" \" + word\n",
    "                    else:\n",
    "                        pass\n",
    "                text_list.append(text)\n",
    "                num_print += 1\n",
    "                if max_elem and num_print == max_elem:\n",
    "                    break\n",
    "    return text_list\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    print(get_occurrences(175, lemma_occurrence_position_dict_175[\"gehen\"], max_elem=1))\n",
    "    print(get_occurrences(175, lemma_occurrence_position_dict_175[\"gehen\"], max_elem=1, highlight_lemma=False))\n",
    "    print(get_occurrences(175, lemma_occurrence_position_dict_175[\"gehen\"], max_elem=1, keep_lemma=False))\n",
    "    print(len(get_occurrences(175, lemma_occurrence_position_dict_175[\"gehen\"], max_elem=None, highlight_lemma=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f5031-bf4e-4658-9f0a-6d32e1de8f26",
   "metadata": {},
   "source": [
    "### merge_count_occurrences_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933136b4-01bd-4148-b3d0-85f773d74eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_count_occurrences_dict(lemma_occurrence_count_dict_a, lemma_occurrence_count_dict_b):\n",
    "    lemma_occurrence_count_dict_merged = {}\n",
    "    for lemma in get_common_lemma(lemma_occurrence_count_dict_a, lemma_occurrence_count_dict_b):\n",
    "        lemma_occurrence_count_dict_merged[lemma] = lemma_occurrence_count_dict_a[lemma] + lemma_occurrence_count_dict_b[lemma]\n",
    "    print(\"merge_count_occurrences_dict: len(lemma_occurrence_count_dict_merged):\", len(lemma_occurrence_count_dict_merged))\n",
    "    return lemma_occurrence_count_dict_merged\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_occurrence_count_dict_174_175_merged = merge_count_occurrences_dict(\n",
    "        lemma_occurrence_count_dict_174, lemma_occurrence_count_dict_175\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa846d34-4e4a-4000-a3a1-582524cfe7f0",
   "metadata": {},
   "source": [
    "### filter_on_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec1894-d4d1-4c15-8b55-d36c294e1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_values(key_value_dict, limit_min=None, limit_max=None):\n",
    "    key_value_dict_new = {}\n",
    "    for lemma, value in key_value_dict.items():\n",
    "        if limit_min and limit_max:\n",
    "            if limit_min <= value <= limit_max:\n",
    "                key_value_dict_new[lemma] = value\n",
    "        elif limit_min:\n",
    "            if limit_min <= value:\n",
    "                key_value_dict_new[lemma] = value\n",
    "        elif limit_max:\n",
    "            if value <= limit_max:\n",
    "                key_value_dict_new[lemma] = value\n",
    "    return key_value_dict_new\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    print(filter_on_values({\"gehen\": 0.9, \"laufen\": 0.5, \"wandern\": 0.7}, limit_min=0.6, limit_max=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4294a-1b34-404e-bfc5-6a2ac3c3971f",
   "metadata": {},
   "source": [
    "## vector and index functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797b6e1-33f3-45e0-a711-86d51d547d7c",
   "metadata": {},
   "source": [
    "### calculate_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f02bef-6c1c-47b2-ba0e-ca03eea28722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_sim(embedding_a: np.ndarray, embedding_b: np.ndarray) -> float:\n",
    "    return np.dot(embedding_a, embedding_b) / (np.linalg.norm(embedding_a) * np.linalg.norm(embedding_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d60524-a615-4213-bc2a-d05edfa78180",
   "metadata": {},
   "source": [
    "### calculate_cos_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c26e6-cf9a-4fed-bb75-be68aaa67d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_distance(embedding_a: np.ndarray, embedding_b: np.ndarray) -> float:\n",
    "    return 1 - calculate_cos_sim(embedding_a, embedding_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130c89ec-42ce-4083-bef9-526ac4e0b1fb",
   "metadata": {},
   "source": [
    "### query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895f1fa-41ed-4b9c-855c-722c1c79bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_embedding(index: Index, lemma: Lemma) -> float:\n",
    "    lemma_id = index[1].get(lemma)\n",
    "    if lemma_id is not None:\n",
    "        embedding = index[0].get_items([lemma_id])[0]\n",
    "    else:\n",
    "        embedding = None\n",
    "    return embedding\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    embedding = query_embedding(index_175, \"gehen\")\n",
    "    print(embedding.shape)\n",
    "    embedding = query_embedding(index_175, \"kljwklerjas\")\n",
    "    print(embedding is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed2196-185b-45eb-9f3e-e356a4027ab4",
   "metadata": {},
   "source": [
    "### query_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77994581-272b-48e6-9c75-7a0ff66871e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_related(\n",
    "    index: Index,\n",
    "    lemma: Lemma,\n",
    "    n: int = 10,\n",
    "    return_as_dict: bool = True,\n",
    "    keep_search: bool = False,\n",
    ") -> dict[str, float] | list[str]:\n",
    "    result = None\n",
    "    try:\n",
    "        id_embedding = index[1][lemma]\n",
    "    except:\n",
    "        print(\"not found\")\n",
    "    else:\n",
    "        if keep_search:\n",
    "            distances_start = 0\n",
    "        else:\n",
    "            n += 1\n",
    "            distances_start = 1\n",
    "        embedding = index[0].get_items([id_embedding])[0]\n",
    "        ids, distances = index[0].knn_query(embedding.reshape(1, -1), k=n)\n",
    "        if return_as_dict:\n",
    "            result = {}\n",
    "        else:\n",
    "            result = []\n",
    "        for id_other, distance in list(zip(ids[0], distances[0]))[distances_start:]:\n",
    "            lemma_related = index[2][id_other]\n",
    "            if return_as_dict:\n",
    "                result[lemma_related] = distance\n",
    "            else:\n",
    "                result.append(lemma_related)\n",
    "    return result\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    print(query_related(index_175, \"gehen\", n=10))\n",
    "    print(query_related(index_176, \"gehen\", n=10))\n",
    "    print(query_related(index_176, \"gehen\", n=10, return_as_dict=False, keep_search=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9c5f7-d9ca-45c1-b01a-c062c6362f6c",
   "metadata": {},
   "source": [
    "### calculate_average_sentence_embedding_from_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1293c-30d5-4155-9ae4-91a0bd8c99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_sentence_embedding_from_sentence(\n",
    "    sentence: str,\n",
    "    index: Index,\n",
    "    word_lemma_dict: WordLemmaDict,\n",
    "    show_exception: bool = False,\n",
    ") -> np.ndarray:\n",
    "    embedding_list = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        try:\n",
    "            embedding = query_embedding(index, word_lemma_dict[word])\n",
    "            if embedding is not None:\n",
    "                embedding_list.append(embedding)\n",
    "        except Exception as ex:\n",
    "            if show_exception:\n",
    "                print(ex, word)\n",
    "    embedding_avg = np.mean(np.array(embedding_list), axis=0)\n",
    "    return embedding_avg\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    v1 = calculate_average_sentence_embedding_from_sentence(\n",
    "        \"der mensch ist in dem haus\", index_175, word_lemma_dict_174, show_exception=True\n",
    "    )\n",
    "    v2 = calculate_average_sentence_embedding_from_sentence(\n",
    "        \"der mann ist in der hütte\", index_175, word_lemma_dict_175, show_exception=True\n",
    "    )\n",
    "    v3 = calculate_average_sentence_embedding_from_sentence(\n",
    "        \"die ziege ist auf dem feld\", index_175, word_lemma_dict_175, show_exception=True\n",
    "    )\n",
    "    print(calculate_cos_sim(v1, v2))\n",
    "    print(calculate_cos_sim(v2, v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e3151-5932-4f04-ae8a-e39e33eefc55",
   "metadata": {},
   "source": [
    "### calculate_average_sentence_embedding_from_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2fa6e-5174-4ef8-b72f-5a39696e2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_sentence_embedding_from_lemma(\n",
    "    decade: Decade,\n",
    "    line_number_dict: LineNumberDict,\n",
    "    index: Index,\n",
    "    word_lemma_dict: WordLemmaDict,\n",
    "    max_sentences: int = 2,\n",
    ") -> np.ndarray:\n",
    "    sentence_list = get_occurrences(decade, line_number_dict, max_elem=max_sentences, highlight_lemma=False)\n",
    "    sentence_embedding_dict = {}\n",
    "    for sentence in sentence_list:\n",
    "        sentence_embedding_dict[sentence] = calculate_average_sentence_embedding_from_sentence(sentence, index, word_lemma_dict)\n",
    "    return sentence_embedding_dict\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    sentence_embedding_dict = calculate_average_sentence_embedding_from_lemma(\n",
    "        175,\n",
    "        lemma_occurrence_position_dict_175[\"gehen\"],\n",
    "        index_175,\n",
    "        word_lemma_dict_175,\n",
    "        max_sentences=1,\n",
    "    )\n",
    "    for sentence, embedding in sentence_embedding_dict.items():\n",
    "        print(sentence)\n",
    "        print(embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908ad80-d33c-4bde-a049-e42f89136c02",
   "metadata": {},
   "source": [
    "### create_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54291d-0139-468a-9668-6aad14749cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tsne(embeddings, perplexity=None):\n",
    "    if perplexity is None:\n",
    "        perplexity = 5\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "    embeddings_reduced = tsne.fit_transform(np.array(embeddings))\n",
    "    return embeddings_reduced\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    embeddings_reduced = create_tsne([query_embedding(index_175, \"gehen\"), query_embedding(index_175, \"laufen\")], perplexity=1)\n",
    "    print(embeddings_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e6a87-dcb9-4f90-831d-192ee2366d19",
   "metadata": {},
   "source": [
    "## difference analysis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8bc7c-b178-4723-a0d9-090faa075350",
   "metadata": {},
   "source": [
    "### create_procrustes_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30da27-a2cf-4826-904c-d80c26ec68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_procrustes_alignment(\n",
    "    index_a: Index,\n",
    "    index_b: Index,\n",
    "    lemma_occurrence_count_dict_a: LemmaOccurrenceCountDict,\n",
    "    lemma_occurrence_count_dict_b: LemmaOccurrenceCountDict,\n",
    "):\n",
    "\n",
    "    # create overlap matrices with embeddings weighted by count of occurrence\n",
    "    common_lemma = get_common_lemma(lemma_occurrence_count_dict_a, lemma_occurrence_count_dict_b)\n",
    "    overlap_matrix_a = []\n",
    "    overlap_matrix_b = []\n",
    "    print(\"create_procrustes_alignment: len(common_lemma):\", len(common_lemma))\n",
    "    for lemma in common_lemma:\n",
    "        occurrence_count_sqrt = np.sqrt((lemma_occurrence_count_dict_a[lemma] + lemma_occurrence_count_dict_b[lemma]) / 2)\n",
    "        embedding_a = query_embedding(index_a, lemma) * occurrence_count_sqrt\n",
    "        embedding_b = query_embedding(index_b, lemma) * occurrence_count_sqrt\n",
    "        overlap_matrix_a.append(embedding_a)\n",
    "        overlap_matrix_b.append(embedding_b)\n",
    "    overlap_matrix_a = np.stack(overlap_matrix_a)\n",
    "    overlap_matrix_b = np.stack(overlap_matrix_b)\n",
    "\n",
    "    # do procrustes transformation\n",
    "    r, _ = orthogonal_procrustes(overlap_matrix_b, overlap_matrix_a)\n",
    "    matrix_b = []\n",
    "    index_b_hnsw, lemma_to_id_b, id_to_lemma_b = index_b\n",
    "    index_b_id_to_lemma_keys = list(id_to_lemma_b.keys())\n",
    "    for i in index_b_id_to_lemma_keys:\n",
    "        embedding_b = index_b_hnsw.get_items([i])[0]\n",
    "        matrix_b.append(embedding_b)\n",
    "    matrix_b = np.stack(matrix_b)\n",
    "    matrix_b_aligned = matrix_b @ r\n",
    "    matrix_b_aligned_normalized = matrix_b_aligned / np.linalg.norm(matrix_b_aligned, axis=1, keepdims=True)\n",
    "    print(\"create_procrustes_alignment: matrix_b_aligned.shape:\", matrix_b_aligned.shape)\n",
    "\n",
    "    # create new index data structure\n",
    "    index_b_aligned = hnswlib.Index(space=\"cosine\", dim=index_b[0].dim)\n",
    "    index_b_aligned.init_index(max_elements=index_b[0].get_max_elements(), ef_construction=INDEX_EF_CONSTRUCTION, M=INDEX_M)\n",
    "    index_b_aligned.add_items(matrix_b_aligned_normalized, index_b_id_to_lemma_keys)\n",
    "\n",
    "    return (index_b_aligned, index_b[1], index_b[2])\n",
    "\n",
    "\n",
    "def create_procrustes_alignment_test():\n",
    "    index_aligned_175 = create_procrustes_alignment(\n",
    "        index_174,\n",
    "        index_175,\n",
    "        lemma_occurrence_count_dict_174,\n",
    "        lemma_occurrence_count_dict_175,\n",
    "    )\n",
    "    index_aligned_176 = create_procrustes_alignment(\n",
    "        index_aligned_175,\n",
    "        index_176,\n",
    "        lemma_occurrence_count_dict_175,\n",
    "        lemma_occurrence_count_dict_176,\n",
    "    )\n",
    "    return index_aligned_175, index_aligned_176\n",
    "\n",
    "\n",
    "index_aligned_175, index_aligned_176 = load_cache_or_run(create_procrustes_alignment_test)\n",
    "if ENABLE_TEST:\n",
    "    for lemma in [\"gehen\", \"und\", \"wohnen\", \"brauen\", \"Fürst\"]:\n",
    "        print(\"create_procrustes_alignment: lemma:\", lemma)\n",
    "        embedding_174 = query_embedding(index_174, lemma)\n",
    "        embedding_175 = query_embedding(index_175, lemma)\n",
    "        embedding_176 = query_embedding(index_176, lemma)\n",
    "        embedding_aligned_175 = query_embedding(index_aligned_175, lemma)\n",
    "        embedding_aligned_176 = query_embedding(index_aligned_176, lemma)\n",
    "        cos_sim_174_175 = calculate_cos_sim(embedding_174, embedding_175)\n",
    "        cos_sim_175_176 = calculate_cos_sim(embedding_175, embedding_176)\n",
    "        cos_sim_aligned_174_175 = calculate_cos_sim(embedding_174, embedding_aligned_175)\n",
    "        cos_sim_aligned_175_176 = calculate_cos_sim(embedding_aligned_175, embedding_aligned_176)\n",
    "        print(\"create_procrustes_alignment:\", \"cos_sim_174_175:\", cos_sim_174_175)\n",
    "        print(\"create_procrustes_alignment:\", \"cos_sim_175_176:\", cos_sim_175_176)\n",
    "        print(\"create_procrustes_alignment:\", \"cos_sim_aligned_174_175:\", cos_sim_aligned_174_175)\n",
    "        print(\"create_procrustes_alignment:\", \"cos_sim_aligned_175_176:\", cos_sim_aligned_175_176)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6071c8b-73fe-465f-8d1a-acf6b3402632",
   "metadata": {},
   "source": [
    "### calculate_cos_sim_between_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2fb62d-9303-4469-8ea9-5af2f556dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_sim_between_indices(index_a, index_b):\n",
    "    common_lemma = get_common_lemma(index_a[1], index_b[1])\n",
    "    lemma_cos_sim_dict = {}\n",
    "    for lemma in common_lemma:\n",
    "        lemma_cos_sim_dict[lemma] = calculate_cos_sim(query_embedding(index_a, lemma), query_embedding(index_b, lemma))\n",
    "    lemma_cos_sim_dict = sort_lemma_dict_by_value_to_dict(lemma_cos_sim_dict)\n",
    "    print(\"calculcate_cos_sim_between_indices: len(lemma_cos_sim_dict):\", len(lemma_cos_sim_dict))\n",
    "    return lemma_cos_sim_dict\n",
    "\n",
    "\n",
    "def calculate_cos_sim_between_indices_test():\n",
    "    lemma_cos_sim_dict_174_175 = calculate_cos_sim_between_indices(index_174, index_aligned_175)\n",
    "    return lemma_cos_sim_dict_174_175\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_cos_sim_dict_174_175 = load_cache_or_run(calculate_cos_sim_between_indices_test)\n",
    "    for lemma in [\"gehen\", \"und\", \"wohnen\", \"brauen\", \"Fürst\"]:\n",
    "        print(\"calculcate_cos_sim_between_indices: lemma:\", lemma)\n",
    "        print(lemma_cos_sim_dict_174_175[lemma])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3199d241-072e-44ae-9e89-ddc37792a4ab",
   "metadata": {},
   "source": [
    "### weight_and_filter_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad1d66-a69e-4c14-a96f-b610ba675ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_and_filter_lemmas(lemma_value_dict, lemma_occurrence_count_dict, filter_threshold=100):\n",
    "    lemma_value_dict_weighted = {}\n",
    "    for lemma, value in lemma_value_dict.items():\n",
    "        if filter_threshold and lemma_occurrence_count_dict[lemma] >= filter_threshold:\n",
    "            lemma_value_dict_weighted[lemma] = value * np.log1p(np.sqrt(lemma_occurrence_count_dict[lemma]))\n",
    "    lemma_value_dict_weighted = sort_lemma_dict_by_value_to_dict(lemma_value_dict_weighted)\n",
    "    print(\"weight_and_filter_lemmas: len(lemma_value_dict_weighted)\", len(lemma_value_dict_weighted))\n",
    "    return lemma_value_dict_weighted\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_cos_sim_dict_174_175_weighted = weight_and_filter_lemmas(lemma_cos_sim_dict_174_175, lemma_occurrence_count_dict_174_175_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26b65a-15b9-4b23-9c80-32052b9a829d",
   "metadata": {},
   "source": [
    "### calculate_trajectory_from_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca5fc5-3503-4750-815e-45641b675a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trajectory_from_lemma(index_a: Index, index_b: Index, index_c: Index, lemma: Lemma) -> Trajectory:\n",
    "    a = query_embedding(index_a, lemma)\n",
    "    b = query_embedding(index_b, lemma)\n",
    "    c = query_embedding(index_c, lemma)\n",
    "    ab = a - b\n",
    "    bc = b - c\n",
    "    ab_bc_trajectory = np.dot(ab, bc)\n",
    "    return ab_bc_trajectory\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    for lemma in [\"gehen\", \"und\", \"wohnen\", \"brauen\", \"Fürst\"]:\n",
    "        ab_bc_trajectory = calculate_trajectory_from_lemma(index_174, index_aligned_175, index_aligned_176, lemma)\n",
    "        print(\"calculate_trajectory_from_diff_per_lemma:\", lemma, ab_bc_trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efd97f-f201-47e1-920b-df23a56fbd72",
   "metadata": {},
   "source": [
    "### calculate_trajectory_dict_from_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38130a60-c9d9-415a-9b0d-5d5163f2bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trajectory_dict_from_index(index_a: Index, index_b: Index, index_c: Index) -> LemmaTrajectoryDict:\n",
    "    lemma_trajectory_diff_list = []\n",
    "    common_lemma = get_common_lemma(index_a[1], index_b[1], index_c[1])\n",
    "    for lemma in common_lemma:\n",
    "        lemma_trajectory_diff = calculate_trajectory_from_lemma(index_a, index_b, index_c, lemma)\n",
    "        lemma_trajectory_diff_list.append((lemma, lemma_trajectory_diff))\n",
    "    lemma_trajectory_diff_list = sorted(lemma_trajectory_diff_list, key=lambda x: -x[1])\n",
    "    lemma_trajectory_dict = {l: d for l, d in lemma_trajectory_diff_list}\n",
    "    return lemma_trajectory_dict\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_trajectory_dict_174_175_176 = calculate_trajectory_dict_from_index(index_174, index_aligned_175, index_aligned_176)\n",
    "    print(\"len(lemma_trajectory_diff_dict_174_175_176)\", len(lemma_trajectory_dict_174_175_176))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab5ed1-54c5-44f2-aeff-f24ca178d222",
   "metadata": {},
   "source": [
    "### calculate_relative_diff_from_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73940986-09cc-44e9-8790-b990f1341e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_diff_from_lemma(\n",
    "    index_a: Index,\n",
    "    index_b: Index,\n",
    "    lemma_occurrence_count_dict_a: LemmaOccurrenceCountDict,\n",
    "    lemma_occurrence_count_dict_b: LemmaOccurrenceCountDict,\n",
    "    lemma: Lemma,\n",
    ") -> float:\n",
    "    diff = None\n",
    "\n",
    "    # key and dict synchronization\n",
    "    distances_a_dict = query_related(index_a, lemma, n=100)\n",
    "    distances_b_dict = query_related(index_b, lemma, n=100)\n",
    "    embedding_index_a_lemma = query_embedding(index_a, lemma)\n",
    "    embedding_index_b_lemma = query_embedding(index_b, lemma)\n",
    "    if embedding_index_a_lemma is not None and embedding_index_b_lemma is not None:\n",
    "        distances_a_lemma_set = set(distances_a_dict.keys())\n",
    "        distances_b_lemma_set = set(distances_b_dict.keys())\n",
    "        lemma_all = set()\n",
    "        for lemma_a in distances_a_lemma_set:\n",
    "            is_in_both = True\n",
    "            if lemma_a not in distances_b_lemma_set:\n",
    "                embedding_index_b_lemma_a = query_embedding(index_b, lemma_a)\n",
    "                if embedding_index_b_lemma_a is not None:\n",
    "                    distances_b_dict[lemma_a] = calculate_cos_distance(embedding_index_a_lemma, embedding_index_b_lemma_a)\n",
    "                else:\n",
    "                    is_in_both = False\n",
    "            if is_in_both:\n",
    "                lemma_all.add(lemma_a)\n",
    "        for lemma_b in distances_b_lemma_set:\n",
    "            is_in_both = True\n",
    "            if lemma_b not in distances_a_lemma_set:\n",
    "                embedding_index_a_lemma_b = query_embedding(index_a, lemma_b)\n",
    "                if embedding_index_a_lemma_b is not None:\n",
    "                    distances_a_dict[lemma_b] = calculate_cos_distance(embedding_index_b_lemma, embedding_index_a_lemma_b)\n",
    "                else:\n",
    "                    is_in_both = False\n",
    "            if is_in_both:\n",
    "                lemma_all.add(lemma_b)\n",
    "\n",
    "        # difference calculation\n",
    "        diff = 0\n",
    "        for lemma_related in lemma_all:\n",
    "            distance_a = distances_a_dict[lemma_related]\n",
    "            distance_b = distances_b_dict[lemma_related]\n",
    "            occurrence_count_avg = (lemma_occurrence_count_dict_a[lemma_related] + lemma_occurrence_count_dict_b[lemma_related]) / 2\n",
    "            # diff += abs(distance_a - distance_b) * np.log1p(occurrence_count_avg)\n",
    "            diff += (abs(distance_a - distance_b) / np.sqrt(occurrence_count_avg)) * occurrence_count_avg\n",
    "        diff /= len(lemma_all)\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    print(\n",
    "        calculate_relative_diff_from_lemma(index_174, index_175, lemma_occurrence_count_dict_174, lemma_occurrence_count_dict_175, \"gehen\")\n",
    "    )\n",
    "    print(\n",
    "        calculate_relative_diff_from_lemma(index_175, index_176, lemma_occurrence_count_dict_175, lemma_occurrence_count_dict_176, \"brauen\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2902c5-a731-451d-887b-dd07f55929d3",
   "metadata": {},
   "source": [
    "### calculate_relative_diff_dict_from_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70615ba-1a79-407e-a9b6-52546bfddb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_diff_dict_from_index(\n",
    "    index_a: Index,\n",
    "    index_b: Index,\n",
    "    lemma_occurrence_count_dict_a: LemmaOccurrenceCountDict,\n",
    "    lemma_occurrence_count_dict_b: LemmaOccurrenceCountDict,\n",
    "    min_occurrence: int = None,\n",
    "    max_occurrence: int = None,\n",
    ") -> LemmaDiffDict:\n",
    "    lemma_diff_dict = {}\n",
    "    lemma_common = get_common_lemma(index_a[1], index_b[1])\n",
    "    for lemma in lemma_common:\n",
    "        count_a = lemma_occurrence_count_dict_a[lemma]\n",
    "        count_b = lemma_occurrence_count_dict_b[lemma]\n",
    "        if (min_occurrence is None or (count_a >= min_occurrence and count_b >= min_occurrence)) and (\n",
    "            max_occurrence is None or (count_a <= max_occurrence and count_b <= max_occurrence)\n",
    "        ):\n",
    "            diff = calculate_relative_diff_from_lemma(index_a, index_b, lemma_occurrence_count_dict_a, lemma_occurrence_count_dict_b, lemma)\n",
    "            # diff_list.append((lemma, diff))\n",
    "            lemma_diff_dict[lemma] = diff\n",
    "    # diff_list = sorted(diff_list, key=lambda x: -x[1])\n",
    "    # lemma_diff_dict = {lemma: diff for lemma, diff in diff_list}\n",
    "    lemma_diff_dict = sort_lemma_dict_by_value_to_dict(lemma_diff_dict, desc=False)\n",
    "    print(\"create_diff_dict_from_index: len(lemma_diff_dict):\", len(lemma_diff_dict))\n",
    "    return lemma_diff_dict\n",
    "\n",
    "\n",
    "def create_relative_diff_dict_from_index_test():\n",
    "    lemma_diff_174_175_dict = calculate_relative_diff_dict_from_index(\n",
    "        index_174,\n",
    "        index_175,\n",
    "        lemma_occurrence_count_dict_174,\n",
    "        lemma_occurrence_count_dict_175,\n",
    "    )\n",
    "    lemma_diff_175_176_dict = calculate_relative_diff_dict_from_index(\n",
    "        index_175,\n",
    "        index_176,\n",
    "        lemma_occurrence_count_dict_175,\n",
    "        lemma_occurrence_count_dict_176,\n",
    "    )\n",
    "    return lemma_diff_174_175_dict, lemma_diff_175_176_dict\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_relative_diff_174_175_dict, lemma_diff_175_176_dict = load_cache_or_run(create_relative_diff_dict_from_index_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19e538-e239-4a5c-95c4-d0aacdea5108",
   "metadata": {},
   "source": [
    "### normalize_lemma_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9749408-008f-4a06-bb7f-f579006fdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lemma_value_dict(lemma_value_dict, enable_inversion=False):\n",
    "    move = min(lemma_value_dict.values())\n",
    "    lemma_value_dict_normalized = {lemma: diff - move for lemma, diff in lemma_value_dict.items()}\n",
    "    scale = 2 / max(lemma_value_dict_normalized.values())\n",
    "    lemma_value_dict_normalized = {lemma: diff * scale for lemma, diff in lemma_value_dict_normalized.items()}\n",
    "    lemma_value_dict_normalized = {lemma: diff - 1 for lemma, diff in lemma_value_dict_normalized.items()}\n",
    "    if enable_inversion:\n",
    "        lemma_value_dict_normalized = {lemma: diff * -1 for lemma, diff in lemma_value_dict_normalized.items()}\n",
    "    print(\"normalize_lemma_value_dict: len(lemma_value_dict_normalized):\", len(lemma_value_dict_normalized))\n",
    "    return lemma_value_dict_normalized\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_cos_sim_dict_174_175_normalized = normalize_lemma_value_dict(lemma_cos_sim_dict_174_175)\n",
    "    lemma_trajectory_dict_174_175_176_normalized = normalize_lemma_value_dict(lemma_trajectory_dict_174_175_176)\n",
    "    lemma_relative_diff_174_175_dict_normalized = normalize_lemma_value_dict(lemma_relative_diff_174_175_dict, enable_inversion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b7feac-604b-4b5d-a8e7-623b68a88a36",
   "metadata": {},
   "source": [
    "### create_random_lemma_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1004eed-1fbe-4095-b392-f4ba28ddbebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_lemma_value_dict(lemma_value_dict, range_min=-1, range_max=1):\n",
    "    range_min *= 1000\n",
    "    range_max *= 1000\n",
    "    random_lemma_value_dict = {}\n",
    "    for lemma in lemma_value_dict.keys():\n",
    "        random_lemma_value_dict[lemma] = random.randint(range_min, range_max) / 1000\n",
    "    return random_lemma_value_dict\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_random_cos_sim_dict = create_random_lemma_value_dict(lemma_relative_diff_174_175_dict_normalized)\n",
    "    lemma_random_trajectory_dict = create_random_lemma_value_dict(lemma_trajectory_dict_174_175_176_normalized)\n",
    "    random_relative_diff_dict = create_random_lemma_value_dict(lemma_relative_diff_174_175_dict_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b538097-d3e0-41cd-8c42-0c5d1d5ec592",
   "metadata": {},
   "source": [
    "### create_lemma_diff_diff_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e212a08a-70a9-4a6b-a397-caa0133b064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lemma_diff_diff_dicts(*lemma_value_dict_list):\n",
    "    lemma_value_dict_list\n",
    "    common_lemma = get_common_lemma(*lemma_value_dict_list)\n",
    "    lemma_diff_dict = {}\n",
    "    for lemma in common_lemma:\n",
    "        l = len(lemma_value_dict_list)\n",
    "        for i_a in range(0, l):\n",
    "            for i_b in range(i_a + 1, l):\n",
    "                lemma_value_dict_a = lemma_value_dict_list[i_a]\n",
    "                lemma_value_dict_b = lemma_value_dict_list[i_b]\n",
    "                diff = lemma_diff_dict.get(lemma, 0)\n",
    "                diff += abs(lemma_value_dict_a[lemma] - lemma_value_dict_b[lemma])\n",
    "                lemma_diff_dict[lemma] = diff\n",
    "    lemma_diff_dict = sort_lemma_dict_by_value_to_dict(lemma_diff_dict, desc=False)\n",
    "    diff_avg = sum(lemma_diff_dict.values()) / len(lemma_diff_dict)\n",
    "    diff_median = list(lemma_diff_dict.values())[int(len(lemma_diff_dict) / 2)]\n",
    "    print(\"create_lemma_diff_diff_dicts: avg_diff:\", diff_avg)\n",
    "    print(\"create_lemma_diff_diff_dicts: diff_median:\", diff_median)\n",
    "    return lemma_diff_dict\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_diff_cos_sim_trajectory_dict_174_176 = create_lemma_diff_diff_dicts(\n",
    "        lemma_cos_sim_dict_174_175_normalized,\n",
    "        lemma_trajectory_dict_174_175_176_normalized,\n",
    "    )\n",
    "    lemma_diff_cos_sim_relative_diff_dict_174_176 = create_lemma_diff_diff_dicts(\n",
    "        lemma_cos_sim_dict_174_175_normalized,\n",
    "        lemma_relative_diff_174_175_dict_normalized,\n",
    "    )\n",
    "    lemma_diff_trajectory_relative_diff_dict_174_176 = create_lemma_diff_diff_dicts(\n",
    "        lemma_trajectory_dict_174_175_176_normalized,\n",
    "        lemma_relative_diff_174_175_dict_normalized,\n",
    "    )\n",
    "    lemma_diff_random_cos_sim_trajectory_dict = create_lemma_diff_diff_dicts(\n",
    "        lemma_random_cos_sim_dict,\n",
    "        lemma_random_trajectory_dict,\n",
    "    )\n",
    "    random_diff_cos_sim_relative_diff_dict = create_lemma_diff_diff_dicts(\n",
    "        lemma_random_cos_sim_dict,\n",
    "        random_relative_diff_dict,\n",
    "    )\n",
    "    random_diff_trajectory_relative_diff_dict = create_lemma_diff_diff_dicts(\n",
    "        lemma_random_trajectory_dict,\n",
    "        random_relative_diff_dict,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9afa27-0ded-4d3a-b199-dd8a9b591cda",
   "metadata": {},
   "source": [
    "### merge_lemma_diff_diff_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841b416-2870-4277-918e-27aed216a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lemma_diff_diff_dict(lemma_diff_diff_dict, lemma_diff_dict_a, lemma_diff_dict_b):\n",
    "    lemma_diff_merged_dict = {}\n",
    "    for lemma in lemma_diff_diff_dict.keys():\n",
    "        lemma_diff_merged_dict[\"1:\" + lemma] = lemma_diff_dict_a[lemma]\n",
    "        lemma_diff_merged_dict[\"2:\" + lemma] = lemma_diff_dict_b[lemma]\n",
    "    print(\"merge_lemma_diff_diff_dict: len(lemma_diff_merged_dict):\", len(lemma_diff_merged_dict))\n",
    "    return lemma_diff_merged_dict\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_merged_cos_sim_trajectory_dict_174_176 = merge_lemma_diff_diff_dict(\n",
    "        lemma_diff_cos_sim_trajectory_dict_174_176,\n",
    "        lemma_cos_sim_dict_174_175_normalized,\n",
    "        lemma_trajectory_dict_174_175_176_normalized,\n",
    "    )\n",
    "    lemma_merged_cos_sim_relative_diff_dict_174_176 = merge_lemma_diff_diff_dict(\n",
    "        lemma_diff_cos_sim_relative_diff_dict_174_176,\n",
    "        lemma_cos_sim_dict_174_175_normalized,\n",
    "        lemma_relative_diff_174_175_dict_normalized,\n",
    "    )\n",
    "    lemma_merged_trajectory_relative_diff_dict_174_176 = merge_lemma_diff_diff_dict(\n",
    "        lemma_diff_trajectory_relative_diff_dict_174_176,\n",
    "        lemma_trajectory_dict_174_175_176_normalized,\n",
    "        lemma_relative_diff_174_175_dict_normalized,\n",
    "    )\n",
    "    lemma_merged_random_diff_dict = merge_lemma_diff_diff_dict(\n",
    "        lemma_diff_random_cos_sim_trajectory_dict,\n",
    "        lemma_random_cos_sim_dict,\n",
    "        lemma_random_trajectory_dict,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea1bdb-2d4d-4442-9f5a-9a4e047d7370",
   "metadata": {},
   "source": [
    "### calculate_average_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883eb57c-87af-4274-9144-42468a2d6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_diff(global_diff_dict):\n",
    "    decade_average_diff_dict = {}\n",
    "    for lemma, diff in global_diff_dict.items():\n",
    "        for decade, cos_sim in diff.items():\n",
    "            diff_per_decade_list = decade_average_diff_dict.get(decade, [])\n",
    "            diff_per_decade_list.append(cos_sim)\n",
    "            decade_average_diff_dict[decade] = diff_per_decade_list\n",
    "    decade_average_diff_dict_new = {}\n",
    "    for lemma, diff_per_decade_list in decade_average_diff_dict.items():\n",
    "        decade_average_diff_dict_new[lemma] = sum(diff_per_decade_list) / len(diff_per_decade_list)\n",
    "    decade_average_diff_dict = decade_average_diff_dict_new\n",
    "    return decade_average_diff_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73d210a-6f57-4f0e-97eb-5aae67d32ee4",
   "metadata": {},
   "source": [
    "## aggregate functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f87f77-eef2-4781-9e6b-59757058b48d",
   "metadata": {},
   "source": [
    "### create_decade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18c73b-06aa-4412-833a-fa1c912b0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decade_data(decade: Decade) -> DecadeData:\n",
    "    model = load_model(decade)\n",
    "    lemma_word_dict, word_lemma_dict = create_lemma_word_dicts(model)\n",
    "    index = create_index(lemma_word_dict, model)\n",
    "    lemma_occurrence_position_dict, lemma_occurrence_count_dict = create_occurrence_dicts(decade, word_lemma_dict)\n",
    "    lemma_list_sorted = sort_lemma_dict_by_value_to_list(lemma_occurrence_count_dict)\n",
    "    lemma_occurrence_count_dict = sort_by_occurrence(lemma_list_sorted, lemma_occurrence_count_dict)\n",
    "    lemma_occurrence_position_dict = sort_by_occurrence(lemma_list_sorted, lemma_occurrence_position_dict)\n",
    "    lemma_word_dict = sort_by_occurrence(lemma_list_sorted, lemma_word_dict)\n",
    "    return [index, word_lemma_dict, lemma_word_dict, lemma_occurrence_count_dict, lemma_occurrence_position_dict, decade]\n",
    "\n",
    "\n",
    "def create_decade_data_test():\n",
    "    return create_decade_data(174), create_decade_data(175), create_decade_data(176)\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    decade_data_174, decade_data_175, decade_data_176 = load_cache_or_run(create_decade_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799cc116-fc60-4bf6-aa08-166c09f34a30",
   "metadata": {},
   "source": [
    "### align_decade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed779808-07fa-407a-baab-9b93ecb4b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_decade_data(decade_data_a: DecadeData, decade_data_b: DecadeData) -> DecadeData:\n",
    "    index_a = decade_data_a[0]\n",
    "    index_b = decade_data_b[0]\n",
    "    lemma_occurrence_count_dict_a = decade_data_a[3]\n",
    "    lemma_occurrence_count_dict_b = decade_data_b[3]\n",
    "    index_b = create_procrustes_alignment(index_a, index_b, lemma_occurrence_count_dict_a, lemma_occurrence_count_dict_b)\n",
    "    decade_data_b[0] = index_b\n",
    "    return decade_data_b\n",
    "\n",
    "\n",
    "def align_decade_data_test():\n",
    "    global decade_data_175\n",
    "    global decade_data_176\n",
    "    decade_data_175 = align_decade_data(decade_data_174, decade_data_175)\n",
    "    decade_data_176 = align_decade_data(decade_data_175, decade_data_176)\n",
    "    return decade_data_175, decade_data_176\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    decade_data_175, decade_data_176 = load_cache_or_run(align_decade_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4bfe5b-d655-4b3f-86b2-0c333c8b45e4",
   "metadata": {},
   "source": [
    "### preprocess_and_persist_decade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807bf63d-36db-4079-aa58-1caa2fbc991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_persist_decade_data(decade_list):\n",
    "\n",
    "    def does_exist(decade):\n",
    "        return os.path.exists(f\"{CACHE_FOLDER}preprocess_and_persist_decade_data__{decade}.pkl\")\n",
    "\n",
    "    decade = decade_list[0]\n",
    "    if not does_exist(decade):\n",
    "        decade_data_a = create_decade_data(decade)\n",
    "        pickle_save(decade_data_a, f\"preprocess_and_persist_decade_data__{decade_list[0]}\")\n",
    "    for decade in decade_list[1:]:\n",
    "        if not does_exist(decade):\n",
    "            decade_data_b = create_decade_data(decade)\n",
    "            decade_data_b = align_decade_data(decade_data_a, decade_data_b)\n",
    "            pickle_save(decade_data_b, f\"preprocess_and_persist_decade_data__{decade}\")\n",
    "            decade_data_a = decade_data_b\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    decade_list = create_decades_list(decade_start=165, decade_end=175)\n",
    "    preprocess_and_persist_decade_data(decade_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b494a-4720-4248-9144-079f2b66a5fd",
   "metadata": {},
   "source": [
    "### load_persisted_decade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d73a3-cc43-4590-8cb0-b6c66f44f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_persisted_decade_data(decade):\n",
    "    return pickle_load(f\"preprocess_and_persist_decade_data__{decade}\")\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    decade_data_175 = load_persisted_decade_data(175)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120c77e-feeb-4d5e-bc14-0670c53e6117",
   "metadata": {},
   "source": [
    "### load_embeddings_from_persisted_decade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f5bfb-b307-48a3-9104-63486efe3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_from_persisted_decade_data(decade_list, lemma_list):\n",
    "    lemma_decade_embdding_list_tmp = []\n",
    "    for decade in decade_list:\n",
    "        decade_data = load_persisted_decade_data(decade)\n",
    "        for lemma in lemma_list:\n",
    "            index = decade_data[0]\n",
    "            embedding = query_embedding(index, lemma)\n",
    "            if embedding is not None:\n",
    "                lemma_decade_embdding_list_tmp.append((lemma, decade, embedding))\n",
    "    lemma_decade_embdding_dict = {}\n",
    "    for lemma, decade, embedding in lemma_decade_embdding_list_tmp:\n",
    "        decade_dict = lemma_decade_embdding_dict.get(lemma, {})\n",
    "        decade_dict[decade] = embedding\n",
    "        lemma_decade_embdding_dict[lemma] = decade_dict\n",
    "    print(\"load_embeddings_from_persisted_decade_data: len(lemma_decade_embdding_dict):\", len(lemma_decade_embdding_dict))\n",
    "    return lemma_decade_embdding_dict\n",
    "\n",
    "\n",
    "def load_embeddings_from_persisted_decade_data_test():\n",
    "    lemma_decade_embdding_dict = load_embeddings_from_persisted_decade_data(\n",
    "        decade_list, [\"gehen\", \"laufen\", \"Spiritus\", \"Prätention\", \"jkljasdjal\"]\n",
    "    )\n",
    "    return lemma_decade_embdding_dict\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_decade_embdding_dict = load_cache_or_run(load_embeddings_from_persisted_decade_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481350da-6136-476b-ac7a-16cfba9567bd",
   "metadata": {},
   "source": [
    "### merge_global_lemma_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0fd2c6-e459-4237-82b2-b722ddd7d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_global_lemma_dict(global_lemma_decade_dict: LemmaDecadeDiffDict, enable_avg=True) -> dict[Lemma, float]:\n",
    "    global_lemma_decade_dict_merged = {}\n",
    "    for lemma, decades_dict in global_lemma_decade_dict.items():\n",
    "        decades_merged = sum(decades_dict.values())\n",
    "        if enable_avg:\n",
    "            decades_merged /= len(decades_dict)\n",
    "        global_lemma_decade_dict_merged[lemma] = decades_merged\n",
    "    global_lemma_decade_dict_merged = sort_lemma_dict_by_value_to_dict(global_lemma_decade_dict_merged)\n",
    "    print(\"merge_global_lemma_dict: len(global_lemma_decade_dict_merged):\", len(global_lemma_decade_dict_merged))\n",
    "    return global_lemma_decade_dict_merged\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_decade_dict_test = {\n",
    "        \"gehen\": {\n",
    "            174: 0.2,\n",
    "            175: 0.3,\n",
    "            176: 0.1,\n",
    "        },\n",
    "        \"laufen\": {\n",
    "            174: 0.4,\n",
    "            175: 0.6,\n",
    "            176: 0.1,\n",
    "        },\n",
    "    }\n",
    "    print(merge_global_lemma_dict(lemma_decade_dict_test))\n",
    "    print(merge_global_lemma_dict(lemma_decade_dict_test, enable_avg=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a5fe8-d85b-4952-a646-09982a6136aa",
   "metadata": {},
   "source": [
    "### calculate_cos_sim_between_decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950900e-32de-42d9-903d-73483379e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cos_sim_between_decades(decade_list, threshold=1000) -> LemmaDecadeDiffDict:\n",
    "    decade_data_a = load_persisted_decade_data(decade_list[0])\n",
    "    global_lemma_cos_sim_dict = {}\n",
    "    for decade in decade_list[1:]:\n",
    "        decade_data_b = load_persisted_decade_data(decade)\n",
    "        cos_sim_decade_str = str(decade_data_a[5]) + \"-\" + str(decade_data_b[5])\n",
    "        lemma_cos_sim_dict = calculate_cos_sim_between_indices(decade_data_a[0], decade_data_b[0])\n",
    "        lemma_occurrence_count_merged = merge_count_occurrences_dict(decade_data_a[3], decade_data_b[3])\n",
    "        lemma_cos_sim_dict_filtered = {}\n",
    "        for lemma, occurrence_count in lemma_occurrence_count_merged.items():\n",
    "            if threshold and occurrence_count >= threshold:\n",
    "                lemma_cos_sim_dict_filtered[lemma] = lemma_cos_sim_dict[lemma]\n",
    "        lemma_cos_sim_dict = lemma_cos_sim_dict_filtered\n",
    "        for lemma, cos_sim in lemma_cos_sim_dict.items():\n",
    "            decade_cos_sim_dict = global_lemma_cos_sim_dict.get(lemma, {})\n",
    "            decade_cos_sim_dict[cos_sim_decade_str] = cos_sim\n",
    "            global_lemma_cos_sim_dict[lemma] = decade_cos_sim_dict\n",
    "        decade_data_a = decade_data_b\n",
    "    print(\"calculate_cos_sim_between_decades: len(global_lemma_cos_sim_dict):\", len(global_lemma_cos_sim_dict))\n",
    "    return global_lemma_cos_sim_dict\n",
    "\n",
    "\n",
    "def calculate_cos_sim_between_decades_test():\n",
    "    return calculate_cos_sim_between_decades(decade_list)\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    print(decade_list)\n",
    "    global_lemma_cos_sim_dict = load_cache_or_run(calculate_cos_sim_between_decades_test)\n",
    "    global_lemma_cos_sim_dict_merged = merge_global_lemma_dict(global_lemma_cos_sim_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f259275-2e5c-4611-88d1-04ae82a21ffe",
   "metadata": {},
   "source": [
    "### calculate_trajectories_between_decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f6b65-5dec-4988-bcf0-f93bb0b7f9e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_trajectories_between_decades(decade_list: DecadeList) -> LemmaDecadeDiffDict:\n",
    "    decade_data_a = load_persisted_decade_data(decade_list[0])\n",
    "    decade_data_b = load_persisted_decade_data(decade_list[1])\n",
    "    global_lemma_trajectory_dict = {}\n",
    "    for decade in decade_list[2:]:\n",
    "        decade_data_c = load_persisted_decade_data(decade)\n",
    "        print(\"calculate_trajectories_between_decades: calculating trajectories between\", decade_data_a[5], \"and\", decade_data_c[5])\n",
    "        index_a = decade_data_a[0]\n",
    "        index_b = decade_data_b[0]\n",
    "        index_c = decade_data_c[0]\n",
    "        lemma_trajectory_dict_abc = calculate_trajectory_dict_from_index(index_a, index_b, index_c)\n",
    "        for lemma, trajectory in lemma_trajectory_dict_abc.items():\n",
    "            trajectory_lemma_dict = global_lemma_trajectory_dict.get(lemma, {})\n",
    "            trajectory_decades_str = str(decade_data_a[5]) + \"-\" + str(decade_data_c[5])\n",
    "            trajectory_lemma_dict[trajectory_decades_str] = trajectory\n",
    "            global_lemma_trajectory_dict[lemma] = trajectory_lemma_dict\n",
    "        decade_data_a = decade_data_b\n",
    "        decade_data_b = decade_data_c\n",
    "    return global_lemma_trajectory_dict\n",
    "\n",
    "\n",
    "def calculate_trajectories_between_decades_test():\n",
    "    decade_list = create_decades_list(decade_start=165, decade_end=175)\n",
    "    return calculate_trajectories_between_decades(decade_list)\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    global_lemma_trajectory_dict = load_cache_or_run(calculate_trajectories_between_decades_test)\n",
    "    global_lemma_trajectory_dict_merged = merge_global_lemma_dict(global_lemma_trajectory_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b72157-37fc-43ac-823d-b1f9f641b14f",
   "metadata": {},
   "source": [
    "### calculate_relative_diff_between_decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45613a-7893-48d5-9b88-69dcdcd3e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_diff_between_decades(decade_list: DecadeList) -> LemmaDecadeDiffDict:\n",
    "    decade_data_a = load_persisted_decade_data(decade_list[0])\n",
    "    global_lemma_relative_diff_dict = {}\n",
    "    for decade in decade_list[1:]:\n",
    "        decade_data_b = load_persisted_decade_data(decade)\n",
    "        decade_str = str(decade_data_a[5]) + \"-\" + str(decade_data_b[5])\n",
    "        lemma_relative_diff_dict = calculate_relative_diff_dict_from_index(\n",
    "            decade_data_a[0],\n",
    "            decade_data_b[0],\n",
    "            decade_data_a[3],\n",
    "            decade_data_b[3],\n",
    "        )\n",
    "        lemma_relative_diff_dict_merged = merge_count_occurrences_dict(decade_data_a[3], decade_data_b[3])\n",
    "        lemma_relative_diff_dict_filtered = {}\n",
    "        for lemma, occurrence_count in lemma_relative_diff_dict_merged.items():\n",
    "            lemma_relative_diff_dict_filtered[lemma] = lemma_relative_diff_dict[lemma]\n",
    "        lemma_relative_diff_dict = lemma_relative_diff_dict_filtered\n",
    "        for lemma, relative_diff in lemma_relative_diff_dict.items():\n",
    "            decade_relative_diff_dict = global_lemma_relative_diff_dict.get(lemma, {})\n",
    "            decade_relative_diff_dict[decade_str] = relative_diff\n",
    "            global_lemma_relative_diff_dict[lemma] = decade_relative_diff_dict\n",
    "        decade_data_a = decade_data_b\n",
    "    print(\"calculate_relative_diff_between_decades: len(global_lemma_relative_diff_dict):\", len(global_lemma_relative_diff_dict))\n",
    "    return global_lemma_relative_diff_dict\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    decade_list = create_decades_list(decade_start=165, decade_end=175)\n",
    "    global_lemma_relative_diff_dict = calculate_relative_diff_between_decades(decade_list)\n",
    "    global_lemma_relative_diff_dict_merged = merge_global_lemma_dict(global_lemma_relative_diff_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acd79d-0484-47d3-984c-718bc0b8e307",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e523ce57-2502-4fcc-bd36-6bbd87d369a3",
   "metadata": {},
   "source": [
    "### plot_tsne_from_labels_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7e74a-c798-48c8-850c-e61abea2fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_from_labels_embeddings(\n",
    "    labels: list[str],\n",
    "    embeddings: list[np.ndarray],\n",
    "    title: str = None,\n",
    "    height: int = None,\n",
    "    width: int = None,\n",
    "    rotation_degree: int = None,\n",
    "    perplexity: int = None,\n",
    "):\n",
    "    reduced_vectors_tsne = create_tsne(embeddings, perplexity)\n",
    "\n",
    "    if rotation_degree:\n",
    "        angle_rad = np.deg2rad(-rotation_degree)\n",
    "        rotation_matrix = np.array([[np.cos(angle_rad), -np.sin(angle_rad)], [np.sin(angle_rad), np.cos(angle_rad)]])\n",
    "        reduced_vectors_tsne = reduced_vectors_tsne @ rotation_matrix.T\n",
    "\n",
    "    if height is None:\n",
    "        height = 800\n",
    "    if width is None:\n",
    "        width = 800\n",
    "    fig = px.scatter(\n",
    "        x=reduced_vectors_tsne[:, 0],\n",
    "        y=reduced_vectors_tsne[:, 1],\n",
    "        text=labels,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        title=title,\n",
    "    )\n",
    "    fig.update_layout(xaxis=dict(title=None, showticklabels=False), yaxis=dict(title=None, showticklabels=False))\n",
    "    fig.update_traces(\n",
    "        marker=dict(size=10),\n",
    "        textposition=\"bottom center\",\n",
    "        textfont=dict(size=12),\n",
    "    )\n",
    "    fig.show()\n",
    "    time.sleep(PLOT_SLEEP)\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_list = query_related(index_175, \"gehen\", keep_search=True, n=20, return_as_dict=False)\n",
    "    embedding_list = []\n",
    "    for lemma in lemma_list:\n",
    "        embedding_list.append(query_embedding(index_175, lemma))\n",
    "    plot_tsne_from_labels_embeddings(lemma_list, embedding_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef5750-3378-4d81-a89a-4c0b38c16339",
   "metadata": {},
   "source": [
    "### plot_tsne_from_lemma_and_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ab989-c2ac-499d-99f1-de8a7302c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_from_lemma_and_related(\n",
    "    index: Index,\n",
    "    lemma: str = None,\n",
    "    n: int = 100,\n",
    "    title: str = None,\n",
    "    height: int = None,\n",
    "    width: int = None,\n",
    "    rotation_degree: int = None,\n",
    "):\n",
    "    lemma_list = query_related(index, lemma, n=n, keep_search=True, return_as_dict=False)\n",
    "    embedding_list = []\n",
    "    for lemma in lemma_list:\n",
    "        embedding_list.append(query_embedding(index_175, lemma))\n",
    "    plot_tsne_from_labels_embeddings(lemma_list, embedding_list)\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    plot_tsne_from_lemma_and_related(index_175, lemma=\"gehen\", n=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5f43a-bf3e-428d-88bd-09ec9b0b7926",
   "metadata": {},
   "source": [
    "### plot_2d_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94128bff-5d4e-471e-b65f-37ad50dba3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_scatter(data: dict | list[list], title: str = None, draw_line=False):\n",
    "    key_list = []\n",
    "    value_list = []\n",
    "    if type(data) is dict:\n",
    "        for key, value in data.items():\n",
    "            key_list.append(key)\n",
    "            value_list.append(value)\n",
    "    else:\n",
    "        for key, value in data:\n",
    "            key_list.append(key)\n",
    "            value_list.append(value)\n",
    "    fig = px.scatter(x=key_list, y=value_list, title=title)\n",
    "    if draw_line:\n",
    "        fig.update_traces(mode=\"lines+markers\")\n",
    "    fig.update_layout(xaxis_title=None, yaxis_title=None)\n",
    "    fig.show()\n",
    "    time.sleep(PLOT_SLEEP)\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "\n",
    "    # general lemma occurrence count\n",
    "    plot_2d_scatter(lemma_occurrence_count_dict_174, \"lemma_occurrence_count_dict_174\")\n",
    "\n",
    "    # base differences\n",
    "    plot_2d_scatter(lemma_cos_sim_dict_174_175, \"lemma_cos_sim_dict_174_175\")\n",
    "    plot_2d_scatter(lemma_trajectory_dict_174_175_176, \"lemma_trajectory_dict_174_175_176\")\n",
    "    plot_2d_scatter(lemma_relative_diff_174_175_dict, \"lemma_relative_diff_174_175_dict\")\n",
    "\n",
    "    # normalized differences\n",
    "    plot_2d_scatter(lemma_cos_sim_dict_174_175_normalized, \"lemma_cos_sim_dict_174_175_normalized\")\n",
    "    plot_2d_scatter(lemma_trajectory_dict_174_175_176_normalized, \"lemma_trajectory_dict_174_175_176_normalized\")\n",
    "    plot_2d_scatter(lemma_relative_diff_174_175_dict_normalized, \"lemma_relative_diff_174_175_dict_normalized\")\n",
    "\n",
    "    # differences of differences\n",
    "    plot_2d_scatter(lemma_diff_cos_sim_trajectory_dict_174_176, \"lemma_diff_cos_sim_trajectory_dict_174_176\")\n",
    "    plot_2d_scatter(lemma_diff_cos_sim_relative_diff_dict_174_176, \"lemma_diff_cos_sim_relative_diff_dict_174_176\")\n",
    "    plot_2d_scatter(lemma_diff_trajectory_relative_diff_dict_174_176, \"lemma_diff_trajectory_relative_diff_dict_174_176\")\n",
    "    plot_2d_scatter(lemma_diff_random_cos_sim_trajectory_dict, \"lemma_diff_random_cos_sim_trajectory_dict\")\n",
    "\n",
    "    # merged differences of differences\n",
    "    plot_2d_scatter(lemma_merged_cos_sim_trajectory_dict_174_176, \"lemma_merged_cos_sim_trajectory_dict_174_176\")\n",
    "    plot_2d_scatter(lemma_merged_cos_sim_relative_diff_dict_174_176, \"lemma_merged_cos_sim_relative_diff_dict_174_176\")\n",
    "    plot_2d_scatter(lemma_merged_trajectory_relative_diff_dict_174_176, \"lemma_merged_trajectory_relative_diff_dict_174_176\")\n",
    "    plot_2d_scatter(lemma_merged_random_diff_dict, \"lemma_merged_random_diff_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe0722-f900-4c39-ae9e-66ef7bdc11d3",
   "metadata": {},
   "source": [
    "### plot_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0cf9f-79c9-43a8-a3cd-b1218e3aabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lemma_and_decade(lemma_decade_embdding_dict: dict[Lemma, dict[Decade, Embedding]], perplexity=None, title=None):\n",
    "\n",
    "    # prepare data\n",
    "    global_labels_list = []\n",
    "    global_embeddings_list = []\n",
    "    group_end_position_list = []\n",
    "    position_count = 0\n",
    "    for lemma, decade_embedding_dict in lemma_decade_embdding_dict.items():\n",
    "        for decade, embedding in decade_embedding_dict.items():\n",
    "            global_labels_list.append(str(decade) + \":\" + lemma)\n",
    "            global_embeddings_list.append(embedding)\n",
    "            position_count += 1\n",
    "        group_end_position_list.append(position_count)\n",
    "    if 1 < len(global_embeddings_list) < 6:\n",
    "        perplexity = len(global_embeddings_list) - 1\n",
    "    else:\n",
    "        perplexity = None\n",
    "    lemma_embeddings_reduced_array = create_tsne(global_embeddings_list, perplexity=perplexity)\n",
    "\n",
    "    # create plot\n",
    "    fig = go.Figure()\n",
    "    group_start_position = 0\n",
    "    for group_end_position in group_end_position_list:\n",
    "        lemma_respective_embeddings = lemma_embeddings_reduced_array[group_start_position:group_end_position]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=lemma_respective_embeddings[:, 0],\n",
    "                y=lemma_respective_embeddings[:, 1],\n",
    "                mode=\"lines\",\n",
    "            )\n",
    "        )\n",
    "        group_start_position = group_end_position\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=lemma_embeddings_reduced_array[:, 0],\n",
    "            y=lemma_embeddings_reduced_array[:, 1],\n",
    "            mode=\"markers+text\",\n",
    "            text=global_labels_list,\n",
    "            textposition=\"top center\",\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=title if title is not None else \"\",\n",
    "        showlegend=False,\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "    fig.show()\n",
    "    time.sleep(PLOT_SLEEP)\n",
    "\n",
    "\n",
    "if ENABLE_TEST:\n",
    "    lemma_list = [\"der\", \"gefunden\", \"Nachmittag\"]\n",
    "    lemma_decade_embdding_dict = {}\n",
    "    print(\"trajectories:\")\n",
    "    for lemma in lemma_list:\n",
    "        print(lemma, lemma_trajectory_dict_174_175_176[lemma])\n",
    "        lemma_decade_embdding_dict[lemma] = {\n",
    "            174: query_embedding(index_174, lemma),\n",
    "            175: query_embedding(index_aligned_175, lemma),\n",
    "            176: query_embedding(index_aligned_176, lemma),\n",
    "        }\n",
    "    plot_lemma_and_decade(lemma_decade_embdding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177a6edd-dde5-4534-b715-8afe108a8b4c",
   "metadata": {},
   "source": [
    "### plot_trajectory_from_lemma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623aa31-5564-44a1-b56a-531f1e0cd41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lemma_and_decade_from_lemma_list(lemma_list, title=None):\n",
    "    lemma_decade_embdding_dict = load_embeddings_from_persisted_decade_data(decade_list, lemma_list)\n",
    "    plot_lemma_and_decade(lemma_decade_embdding_dict, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a5a39-3f03-4eed-8802-d8547e9706c2",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b000e-97eb-48c7-b884-807abf483fce",
   "metadata": {},
   "source": [
    "## prepare_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5abfbd-ac28-4fe5-8640-3cfe26706ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all():\n",
    "    decade_list = create_decades_list(decade_start=180, decade_end=185)\n",
    "    preprocess_and_persist_decade_data(decade_list)\n",
    "    global_lemma_cos_sim_dict = calculate_cos_sim_between_decades(decade_list)\n",
    "    global_lemma_cos_sim_dict_merged = merge_global_lemma_dict(global_lemma_cos_sim_dict)\n",
    "    global_lemma_trajectory_dict = calculate_trajectories_between_decades(decade_list)\n",
    "    global_lemma_trajectory_dict_merged = merge_global_lemma_dict(global_lemma_trajectory_dict)\n",
    "    global_lemma_relative_diff_dict = calculate_relative_diff_between_decades(decade_list)\n",
    "    global_lemma_relative_diff_dict_merged = merge_global_lemma_dict(global_lemma_relative_diff_dict)\n",
    "    return (\n",
    "        decade_list,\n",
    "        global_lemma_cos_sim_dict,\n",
    "        global_lemma_cos_sim_dict_merged,\n",
    "        global_lemma_trajectory_dict,\n",
    "        global_lemma_trajectory_dict_merged,\n",
    "        global_lemma_relative_diff_dict,\n",
    "        global_lemma_relative_diff_dict_merged,\n",
    "    )\n",
    "\n",
    "\n",
    "(\n",
    "    decade_list,\n",
    "    global_lemma_cos_sim_dict,\n",
    "    global_lemma_cos_sim_dict_merged,\n",
    "    global_lemma_trajectory_dict,\n",
    "    global_lemma_trajectory_dict_merged,\n",
    "    global_lemma_relative_diff_dict,\n",
    "    global_lemma_relative_diff_dict_merged,\n",
    ") = load_cache_or_run(prepare_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d8dd1-f18c-4d7a-b710-ed3cbd1dd709",
   "metadata": {},
   "source": [
    "## global changes analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a4ee1-9dcb-4add-b0b5-593841e0d325",
   "metadata": {},
   "source": [
    "### global cosine similarity changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa27b2-8a30-4a14-bcbf-307bbcb61066",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_scatter(global_lemma_cos_sim_dict_merged, \"global average change between decades regarding cosine similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77acda-de6e-4c2f-ba6f-d16a8a1b05d6",
   "metadata": {},
   "source": [
    "### global trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939ac9c-30c5-44e6-b798-a3c837c9767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_scatter(global_lemma_trajectory_dict_merged, \"global average change between decades regarding trajectory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291e935-db06-4acb-a15d-8fd70fc149f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_scatter(global_lemma_relative_diff_dict_merged, \"global average change between decades regarding relative differences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251a4a6-9485-423e-98e7-209cefc94da3",
   "metadata": {},
   "source": [
    "### filter_on_decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26748a-75ff-4e61-8ee7-b3982c9970e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_decades(global_lemma_dict, num_decades=25):\n",
    "    global_lemma_dict_filtered = {}\n",
    "    for lemma, decade_dict in global_lemma_dict.items():\n",
    "        if len(decade_dict) > num_decades:\n",
    "            global_lemma_dict_filtered[lemma] = decade_dict\n",
    "    return global_lemma_dict_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed077e-98dd-46d5-9a01-149cf41d0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lemma_cos_sim_dict_filtered = filter_on_decades(global_lemma_cos_sim_dict)\n",
    "global_lemma_cos_sim_dict_filtered_merged = merge_global_lemma_dict(global_lemma_cos_sim_dict_filtered)\n",
    "plot_2d_scatter(global_lemma_cos_sim_dict_filtered_merged, \"global filtered average change between decades regarding cosine similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2d811-b089-400f-a21b-70d1b3842be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lemma_trajectory_dict_filtered = filter_on_decades(global_lemma_trajectory_dict)\n",
    "global_lemma_trajectory_dict_filtered_merged = merge_global_lemma_dict(global_lemma_trajectory_dict_filtered)\n",
    "plot_2d_scatter(global_lemma_trajectory_dict_filtered_merged, \"global filtered average change between decades regarding trajectory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619649b1-9e5e-477d-aeb4-7d89c6a5bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lemma_relative_diff_dict_filtered = filter_on_decades(global_lemma_relative_diff_dict, num_decades=3)\n",
    "global_lemma_relative_diff_dict_filtered_merged = merge_global_lemma_dict(global_lemma_relative_diff_dict_filtered)\n",
    "plot_2d_scatter(\n",
    "    global_lemma_relative_diff_dict_filtered_merged, \"global filtered average change between decades regarding relative differences\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495a29b-e701-4e16-b6e5-d8d7d21ec670",
   "metadata": {},
   "source": [
    "### compare cos sim and trajectories differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b4630-e8c7-46dc-8fd2-8956afd69dd9",
   "metadata": {},
   "source": [
    "### normalize global diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c191c-8ff4-4e3e-8085-c47164c2e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lemma_cos_sim_dict_filtered_merged_normalized = normalize_lemma_value_dict(global_lemma_cos_sim_dict_filtered_merged)\n",
    "plot_2d_scatter(\n",
    "    global_lemma_cos_sim_dict_filtered_merged_normalized,\n",
    "    \"global normalized filtered average change between decades regarding cosine similarity\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1965759-84ed-4091-82d7-d68a1a4afef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lemma_trajectory_dict_filtered_merged_normalized = normalize_lemma_value_dict(global_lemma_trajectory_dict_filtered_merged)\n",
    "plot_2d_scatter(\n",
    "    global_lemma_trajectory_dict_filtered_merged_normalized,\n",
    "    \"global normalized filtered average change between decades regarding trajectory\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986a1e2-635f-41ab-b75a-cd68197fb411",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lemma_relative_diff_dict_filtered_merged_normalized = normalize_lemma_value_dict(\n",
    "    global_lemma_relative_diff_dict_filtered_merged,\n",
    "    enable_inversion=True,\n",
    ")\n",
    "plot_2d_scatter(\n",
    "    global_lemma_relative_diff_dict_filtered_merged_normalized,\n",
    "    \"global normalized filtered average change between decades regarding trajectory\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b3a63-3bf0-44c0-a529-be755eaaed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lemma_diffs_compared = create_lemma_diff_diff_dicts(\n",
    "    global_lemma_cos_sim_dict_filtered_merged_normalized, global_lemma_trajectory_dict_filtered_merged_normalized\n",
    ")\n",
    "plot_2d_scatter(global_lemma_diffs_compared, \"difference between normalized cos sim and trajectories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8045b8d-a5d7-4f44-9e38-5b828b5124ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lemma_diffs_compared_merged = merge_lemma_diff_diff_dict(\n",
    "    global_lemma_diffs_compared,\n",
    "    global_lemma_cos_sim_dict_filtered_merged_normalized,\n",
    "    global_lemma_trajectory_dict_filtered_merged_normalized,\n",
    ")\n",
    "plot_2d_scatter(global_lemma_diffs_compared_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694d7de-bd4d-42b2-b47c-30ca97761b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dict_a = create_random_lemma_value_dict(global_lemma_cos_sim_dict_filtered_merged_normalized)\n",
    "random_dict_b = create_random_lemma_value_dict(global_lemma_trajectory_dict_filtered_merged_normalized)\n",
    "random_lemma_diff_diff_dict = create_lemma_diff_diff_dicts(random_dict_a, random_dict_b)\n",
    "global_lemma_diffs_compared_merged_random = merge_lemma_diff_diff_dict(random_lemma_diff_diff_dict, random_dict_a, random_dict_b)\n",
    "plot_2d_scatter(global_lemma_diffs_compared_merged_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6adc114-536f-45d2-a87c-b71a93334224",
   "metadata": {},
   "source": [
    "### compare cos sim and relative diff differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ad1e8-4d46-4509-b702-242d6b17dfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4424c204-4b50-4123-95f7-78ccaded7af8",
   "metadata": {},
   "source": [
    "### average differences per decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c6df1-b4a1-4433-9792-a2df33d80808",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cos_sim_per_decade_dict = calculate_average_diff(global_lemma_cos_sim_dict)\n",
    "plot_2d_scatter(average_cos_sim_per_decade_dict, draw_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31281295-5c3e-4837-bd29-7b8341feca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_trajectory_per_decade_dict = calculate_average_diff(global_lemma_trajectory_dict)\n",
    "plot_2d_scatter(average_trajectory_per_decade_dict, draw_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05cb213-3124-4fa4-96de-da0f21f61f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_relative_diff_per_decade_dict = calculate_average_diff(global_lemma_relative_diff_dict)\n",
    "plot_2d_scatter(average_relative_diff_per_decade_dict, draw_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0a174-a32f-41d1-b1c3-39af728f617f",
   "metadata": {},
   "source": [
    "## sample analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c4841-c1b1-46a8-b348-a17605d5dafd",
   "metadata": {},
   "source": [
    "### get_lemma_by_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45440e2-4ae4-41d1-a03e-20f52d8ad29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_by_position(lemma_dict, index_start=0, n=10, direction_forward=True, index_start_is_percent=False):\n",
    "    lemma_dict_selected = {}\n",
    "    key_value_list = []\n",
    "    if direction_forward:\n",
    "        for key, value in lemma_dict.items():\n",
    "            if is_word(key):\n",
    "                key_value_list.append((key, value))\n",
    "    else:\n",
    "        for key, value in list(lemma_dict.items())[::-1]:\n",
    "            if is_word(key):\n",
    "                key_value_list.append((key, value))\n",
    "    if index_start_is_percent:\n",
    "        index_start = int((len(key_value_list) / 100) * index_start)\n",
    "    index_end = index_start + n\n",
    "    for i, (key, value) in enumerate(key_value_list):\n",
    "        if index_start <= i:\n",
    "            if i < index_end:\n",
    "                lemma_dict_selected[key] = value\n",
    "            else:\n",
    "                break\n",
    "    return lemma_dict_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d30c3-54ce-4961-91a5-ce74f456b95b",
   "metadata": {},
   "source": [
    "### sample_and_plot_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77a9b6-b8c9-4e9e-986e-20802c99fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_plot_lemmas(\n",
    "    global_lemma_cos_sim_dict,\n",
    "    global_lemma_cos_sim_dict_merged,\n",
    "    global_lemma_trajectory_dict,\n",
    "    global_lemma_trajectory_dict_merged,\n",
    "    index_start,\n",
    "    n=10,\n",
    "    direction_forward=True,\n",
    "    index_start_is_percent=False,\n",
    "    plot_limit=3,\n",
    "):\n",
    "\n",
    "    def sample_and_plot_lemmas_internal(\n",
    "        lemma_diff_dict,\n",
    "        lemma_diff_dict_merged,\n",
    "        title,\n",
    "    ):\n",
    "        lemma_diff_dict_sampled = get_lemma_by_position(\n",
    "            lemma_diff_dict_merged,\n",
    "            index_start=index_start,\n",
    "            n=n,\n",
    "            direction_forward=direction_forward,\n",
    "            index_start_is_percent=index_start_is_percent,\n",
    "        )\n",
    "        print(lemma_diff_dict_sampled)\n",
    "        lemma_diff_list_sampled = list(lemma_diff_dict_sampled.keys())[:plot_limit]\n",
    "        for lemma in lemma_diff_list_sampled:\n",
    "            plot_2d_scatter(lemma_diff_dict[lemma], draw_line=True, title=title + \": \" + lemma)\n",
    "        return lemma_diff_list_sampled\n",
    "\n",
    "    lemma_diff_list_sampled = sample_and_plot_lemmas_internal(\n",
    "        global_lemma_cos_sim_dict, global_lemma_cos_sim_dict_merged, \"cosine similarity\"\n",
    "    )\n",
    "    lemma_diff_list_sampled += sample_and_plot_lemmas_internal(\n",
    "        global_lemma_trajectory_dict, global_lemma_trajectory_dict_merged, \"trajectory\"\n",
    "    )\n",
    "    lemma_diff_list_sampled = list(set(lemma_diff_list_sampled))\n",
    "    plot_lemma_and_decade_from_lemma_list(lemma_diff_list_sampled, \"embeddings samples regarding cosine similarity and trajectory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f0329-26c8-4f0d-96b0-620067cb2e4c",
   "metadata": {},
   "source": [
    "### top lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5f9bc-daad-4929-bbbc-ef63754c9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_and_plot_lemmas(\n",
    "    global_lemma_cos_sim_dict,\n",
    "    global_lemma_cos_sim_dict_filtered_merged,\n",
    "    global_lemma_trajectory_dict,\n",
    "    global_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=0,\n",
    "    n=10,\n",
    "    plot_limit=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473b961-2181-4657-9194-6353a1e23b79",
   "metadata": {},
   "source": [
    "### middle lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d998f-2bb2-4472-91c0-100f264bf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_and_plot_lemmas(\n",
    "    global_lemma_cos_sim_dict,\n",
    "    global_lemma_cos_sim_dict_filtered_merged,\n",
    "    global_lemma_trajectory_dict,\n",
    "    global_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=50,\n",
    "    n=10,\n",
    "    plot_limit=3,\n",
    "    index_start_is_percent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45023571-43d7-4179-a6dc-a57c2d71b298",
   "metadata": {},
   "source": [
    "### bottom lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4607e02-df59-412e-8f96-f323c1656fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_and_plot_lemmas(\n",
    "    global_lemma_cos_sim_dict,\n",
    "    global_lemma_cos_sim_dict_filtered_merged,\n",
    "    global_lemma_trajectory_dict,\n",
    "    global_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=0,\n",
    "    n=10,\n",
    "    plot_limit=3,\n",
    "    direction_forward=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54933c79-1604-41a9-9027-3eaa578af406",
   "metadata": {},
   "source": [
    "### together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbca0cd-2747-4bf6-aeb5-be6899241e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top\n",
    "global_top_cos_sim = sample_diff_dict = get_lemma_by_position(\n",
    "    global_lemma_cos_sim_dict_filtered_merged,\n",
    "    index_start=0,\n",
    "    n=2,\n",
    ")\n",
    "global_top_cos_sim = list(global_top_cos_sim.keys())\n",
    "\n",
    "# middle\n",
    "global_middle_cos_sim = sample_diff_dict = get_lemma_by_position(\n",
    "    global_lemma_cos_sim_dict_filtered_merged,\n",
    "    index_start=50,\n",
    "    n=2,\n",
    "    index_start_is_percent=True,\n",
    ")\n",
    "global_middle_cos_sim = list(global_middle_cos_sim.keys())\n",
    "\n",
    "# bottom\n",
    "global_bottom_cos_sim = sample_diff_dict = get_lemma_by_position(\n",
    "    global_lemma_cos_sim_dict_filtered_merged,\n",
    "    index_start=0,\n",
    "    n=2,\n",
    "    direction_forward=False,\n",
    ")\n",
    "global_bottom_cos_sim = list(global_bottom_cos_sim.keys())\n",
    "\n",
    "# together\n",
    "global_together_cos_sim = global_top_cos_sim + global_middle_cos_sim + global_bottom_cos_sim\n",
    "plot_lemma_and_decade_from_lemma_list(global_together_cos_sim, \"sampled via cosine similarity: \" + str(global_together_cos_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c673c-6425-4e06-b787-baf0f3ca2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top\n",
    "global_top_trajectory = sample_diff_dict = get_lemma_by_position(\n",
    "    global_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=0,\n",
    "    n=2,\n",
    ")\n",
    "global_top_trajectory = list(global_top_trajectory.keys())\n",
    "\n",
    "# middle\n",
    "global_middle_trajectory = sample_diff_dict = get_lemma_by_position(\n",
    "    global_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=50,\n",
    "    n=2,\n",
    "    index_start_is_percent=True,\n",
    ")\n",
    "global_middle_trajectory = list(global_middle_trajectory.keys())\n",
    "\n",
    "# bottom\n",
    "global_bottom_trajectory = sample_diff_dict = get_lemma_by_position(\n",
    "    global_lemma_trajectory_dict_filtered_merged,\n",
    "    index_start=0,\n",
    "    n=2,\n",
    "    direction_forward=False,\n",
    ")\n",
    "global_bottom_trajectory = list(global_bottom_trajectory.keys())\n",
    "\n",
    "# together\n",
    "global_together_trajectory = global_top_trajectory + global_middle_trajectory + global_bottom_trajectory\n",
    "plot_lemma_and_decade_from_lemma_list(global_together_trajectory, \"sampled via trajectory: \" + str(global_together_trajectory))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
